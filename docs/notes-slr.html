<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.517">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Regression - 1&nbsp; Simple linear regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./notes-inference.html" rel="next">
<link href="./part1-slr.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="site_libs/kePrint-0.0.1/kePrint.js"></script><link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part1-slr.html">Simple linear regression</a></li><li class="breadcrumb-item"><a href="./notes-slr.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><header id="title-block-header" class="quarto-title-block default page-columns page-full"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part1-slr.html">Simple linear regression</a></li><li class="breadcrumb-item"><a href="./notes-slr.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression</span></a></li></ol></nav><div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><span id="sec-slr" class="quarto-section-identifier"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Regression</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part1-slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple linear regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-slr.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-diagnostics-and-remedial-measures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Diagnostics and remedial measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-matrix-slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Matrix approach to SLR</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part2-mlr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple linear regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./placeholder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Placeholder</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#regression-overview" id="toc-regression-overview" class="nav-link active" data-scroll-target="#regression-overview"><span class="header-section-number">1.1</span> Regression overview</a>
  <ul class="collapse">
<li><a href="#simple-linear-regression-model-slr" id="toc-simple-linear-regression-model-slr" class="nav-link" data-scroll-target="#simple-linear-regression-model-slr"><span class="header-section-number">1.1.1</span> Simple linear regression model (SLR)</a></li>
  <li><a href="#estimation-of-the-regression-function" id="toc-estimation-of-the-regression-function" class="nav-link" data-scroll-target="#estimation-of-the-regression-function"><span class="header-section-number">1.1.2</span> Estimation of the regression function</a></li>
  <li><a href="#method-of-least-squares" id="toc-method-of-least-squares" class="nav-link" data-scroll-target="#method-of-least-squares"><span class="header-section-number">1.1.3</span> Method of least squares</a></li>
  <li><a href="#point-estimation-of-the-mean-response" id="toc-point-estimation-of-the-mean-response" class="nav-link" data-scroll-target="#point-estimation-of-the-mean-response"><span class="header-section-number">1.1.4</span> Point estimation of the mean response</a></li>
  <li><a href="#residuals-and-model-errors" id="toc-residuals-and-model-errors" class="nav-link" data-scroll-target="#residuals-and-model-errors"><span class="header-section-number">1.1.5</span> Residuals and model errors</a></li>
  </ul>
</li>
  <li><a href="#estimation-of-error-terms-variance" id="toc-estimation-of-error-terms-variance" class="nav-link" data-scroll-target="#estimation-of-error-terms-variance"><span class="header-section-number">1.2</span> Estimation of error terms variance</a></li>
  <li>
<a href="#normal-error-regression-model" id="toc-normal-error-regression-model" class="nav-link" data-scroll-target="#normal-error-regression-model"><span class="header-section-number">1.3</span> Normal error regression model</a>
  <ul class="collapse">
<li><a href="#estimation-of-paramters-by-method-of-maximum-likelihood" id="toc-estimation-of-paramters-by-method-of-maximum-likelihood" class="nav-link" data-scroll-target="#estimation-of-paramters-by-method-of-maximum-likelihood"><span class="header-section-number">1.3.1</span> Estimation of paramters by method of maximum likelihood</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content"><!-- % define LaTeX macros (/shortcuts) --><!-- % define vector (without parentheses, so when writing out in like a definition) of the form X_1, ..., X_n, where X and n are variable. NOTE: to call use $\vecn{X}{n}$ --><!-- % shortcut for ~ 'Named dist ' in normal font with space before parameters would go --><!-- % (followsp is short for 'follow special') shortcut that can be used for iid or ind ~ 'Named dist ' in normal font with space before parameters would go --><!-- % define independence symbol (it basically makes two orthogonal symbols very close to each other. The number of \! controls the space between each of the orthogonal symbols) --><!-- % shortcut for Cov(X,Y) with formatting for Cov --><!-- % shortcut for Corr(X,Y) with formatting for Corr --><!-- % shortcut for non-italic e in math mode --><section id="regression-overview" class="level2" data-number="1.1"><h2 data-number="1.1" class="anchored" data-anchor-id="regression-overview">
<span class="header-section-number">1.1</span> Regression overview</h2>
<p>Regression overview</p>
<ul>
<li><p>Goal is to determine <strong>if</strong> and <strong>how</strong> one variable is related to a set of other variables.</p></li>
<li>
<p>Variables</p>
<ul>
<li><p>Response variable, denoted <span class="math inline">\(Y\)</span>, represents an outcome whose variation is being studied.</p></li>
<li><p>Explanatory variable, denoted <span class="math inline">\(X\)</span>, represents the causes (i.e.&nbsp;potential reasons for variation).</p></li>
</ul>
</li>
<li>
<p>Two types of relationships</p>
<ul>
<li><p>Functional (deterministic) → There is an exact relation between two variables (have the form <span class="math inline">\(y = ax+ b\)</span>).</p></li>
<li><p>Statistical (probabilistic) → There is not an exact relation because there are other variables that affect the relationship (have the form <span class="math inline">\(y = ax + b + \epsilon\)</span>).</p></li>
</ul>
</li>
</ul>
<p>Regression models and their uses</p>
<ul>
<li><p>Statistical models quantify the relationship between a response variable (i.e.&nbsp;a random variable) and explanatory variables, which are usually assumed to be deterministic (i.e.&nbsp;known exactly).</p></li>
<li>
<p>Elements of a statistical regression model</p>
<ul>
<li>
<p>In general, observations do not fall directly on the curve of a relationship.</p>
<ul>
<li><p><span class="math inline">\(Y \mid X\)</span> has a probability distribution.</p></li>
<li><p><span class="math inline">\(E(Y \mid X)\)</span> varies deterministically with <span class="math inline">\(X\)</span>.</p></li>
</ul>
<p><img src="files/images/regression-curve.png" class="img-fluid" style="width:50.0%"></p>
</li>
<li>
<p>So the statistical model is:</p>
<p><span class="math display">\[
\begin{align*}
  Y &amp;= E(Y \mid X) + \epsilon \\
    &amp;= f(X) + \epsilon, \hspace{20pt} \text{where $\epsilon$ has some distribution}
\end{align*}
\]</span></p>
</li>
</ul>
</li>
<li>
<p>Two components of a statistical model:</p>
<ol type="1">
<li><p><span class="math inline">\(f(X) = E(Y \mid X)\)</span> → Defines relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>; explains the average behavior of the response.</p></li>
<li><p><span class="math inline">\(\epsilon\)</span> → An element of randomness (i.e.&nbsp;error). This contains the variation that <span class="math inline">\(f(X)\)</span> cannot explain and/or that is of no interest.</p></li>
</ol>
</li>
<li><p>This means <span class="math inline">\(f(X) = E(Y \mid X)\)</span> will be the same for all samples with the same <span class="math inline">\(X\)</span> values. The only thing that changes is the random error <span class="math inline">\(\epsilon\)</span> and as a result <span class="math inline">\(Y\)</span>. Example <span class="math inline">\(Y = 3 + 1X + \epsilon\)</span>:</p></li>
</ul>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># create regression data frame to show different the deterministic and statistical relationships (assuming SLR normal error model for demonstration so can visualize)</span></span>
<span><span class="co"># generate</span></span>
<span><span class="co"># -&gt; X values (not from a random dist)</span></span>
<span><span class="co"># -&gt; f(X) = E(Y | X) = beta_0 + beta_1 X demonstration</span></span>
<span><span class="co"># -&gt; random error = epsilon ~ N(0,1)</span></span>
<span><span class="co"># -&gt; Y = f(X) + epsilon</span></span>
<span><span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span><span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">data_ships</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>X <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">10</span>, to <span class="op">=</span> <span class="fl">19</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>f_X <span class="op">=</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">X</span>,</span>
<span>         epsilon <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>         Y <span class="op">=</span> <span class="va">f_X</span> <span class="op">+</span> <span class="va">epsilon</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display data</span></span>
<span><span class="va">data_ships</span> <span class="op">%&gt;%</span> <span class="fu">display_nice</span><span class="op">(</span>col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="st">"f(X) = E(Y | X)"</span>, <span class="st">"$epsilon ~ N(0,1)"</span>, <span class="st">"Y = f(X) + epsilon"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<table data-quarto-disable-processing="true" class="table table-striped" style="width: auto !important; ">
<thead><tr>
<th style="text-align:right;"> X </th>
   <th style="text-align:right;"> f(X) = E(Y | X) </th>
   <th style="text-align:right;"> $epsilon ~ N(0,1) </th>
   <th style="text-align:right;"> Y = f(X) + epsilon </th>
  </tr></thead>
<tbody>
<tr>
<td style="text-align:right;"> 10 </td>
   <td style="text-align:right;"> 13 </td>
   <td style="text-align:right;"> -0.568 </td>
   <td style="text-align:right;"> 12.432 </td>
  </tr>
<tr>
<td style="text-align:right;"> 11 </td>
   <td style="text-align:right;"> 14 </td>
   <td style="text-align:right;"> -0.664 </td>
   <td style="text-align:right;"> 13.336 </td>
  </tr>
<tr>
<td style="text-align:right;"> 12 </td>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> -0.301 </td>
   <td style="text-align:right;"> 14.699 </td>
  </tr>
<tr>
<td style="text-align:right;"> 13 </td>
   <td style="text-align:right;"> 16 </td>
   <td style="text-align:right;"> -0.480 </td>
   <td style="text-align:right;"> 15.520 </td>
  </tr>
<tr>
<td style="text-align:right;"> 14 </td>
   <td style="text-align:right;"> 17 </td>
   <td style="text-align:right;"> -0.975 </td>
   <td style="text-align:right;"> 16.025 </td>
  </tr>
<tr>
<td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 18 </td>
   <td style="text-align:right;"> -1.170 </td>
   <td style="text-align:right;"> 16.830 </td>
  </tr>
<tr>
<td style="text-align:right;"> 16 </td>
   <td style="text-align:right;"> 19 </td>
   <td style="text-align:right;"> 0.275 </td>
   <td style="text-align:right;"> 19.275 </td>
  </tr>
<tr>
<td style="text-align:right;"> 17 </td>
   <td style="text-align:right;"> 20 </td>
   <td style="text-align:right;"> 0.017 </td>
   <td style="text-align:right;"> 20.017 </td>
  </tr>
<tr>
<td style="text-align:right;"> 18 </td>
   <td style="text-align:right;"> 21 </td>
   <td style="text-align:right;"> -0.258 </td>
   <td style="text-align:right;"> 20.742 </td>
  </tr>
<tr>
<td style="text-align:right;"> 19 </td>
   <td style="text-align:right;"> 22 </td>
   <td style="text-align:right;"> 1.642 </td>
   <td style="text-align:right;"> 23.642 </td>
  </tr>
</tbody>
</table>
</div>
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot (X, Y)</span></span>
<span><span class="co"># -&gt; and add points and line for E(Y | X)</span></span>
<span><span class="co"># --&gt; population E(Y | X)) because using known betas (not estimating from sample data)</span></span>
<span><span class="va">data_ships</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">Y</span>, type <span class="op">=</span> <span class="st">"p"</span>, main <span class="op">=</span> <span class="st">"Deterministic vs statistical relationship"</span><span class="op">)</span></span>
<span><span class="va">data_ships</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">f_X</span>, col <span class="op">=</span> <span class="st">"red"</span>, pch <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">data_ships</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">f_X</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">18.5</span>, y <span class="op">=</span> <span class="fl">20</span>, labels <span class="op">=</span> <span class="st">"f(X) = E(Y|X)"</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-slr_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Construction of statistical regression models</p>
<ol type="1">
<li>
<p>Selection of predictor variables (how to decide which ones?).</p>
<ul>
<li><p>Use of outside information, historical knowledge, and/or experience.</p></li>
<li><p>Exploratory data analysis.</p></li>
<li><p>Variable selection techniques → Find a subset of important variables (i.e.&nbsp;practical and easy to find).</p></li>
</ul>
</li>
<li>
<p>Functional form of the regression relation (what is form of <span class="math inline">\(f(X)\)</span>?).</p>
<ul>
<li><p>&lt; based on same info as (1) &gt;</p></li>
<li><p>If there is an abundance of data, maybe start with more complex models and then simplify.</p></li>
</ul>
</li>
<li>
<p>Scope of model (when is the model useful?).</p>
<ul>
<li>When the model best predicts or describes the relationship between response and predictor variables.</li>
</ul>
</li>
</ol>
<p>Uses of statistical regression models</p>
<ol type="1">
<li><p>Determining whether an <span class="math inline">\(X\)</span> “affects” <span class="math inline">\(Y\)</span> or not.</p></li>
<li><p>Estimation of impact of a given <span class="math inline">\(X\)</span> on the <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Estimation of the mean of <span class="math inline">\(Y\)</span> for a given <span class="math inline">\(X\)</span> value.</p></li>
<li><p>Prediction of a single value of <span class="math inline">\(Y\)</span> for a given <span class="math inline">\(X\)</span> value.</p></li>
</ol>
<p>Typical strategy for regression analysis</p>
<p><img src="files/images/regression-flow-chart.png" class="img-fluid" style="width:25.0%"></p>
<section id="simple-linear-regression-model-slr" class="level3" data-number="1.1.1"><h3 data-number="1.1.1" class="anchored" data-anchor-id="simple-linear-regression-model-slr">
<span class="header-section-number">1.1.1</span> Simple linear regression model (SLR)</h3>
<p>Goal of SLR</p>
<ul>
<li><p>Investigate the relationship between <span class="math inline">\(Y\)</span> and a single numeric independent variable <span class="math inline">\(X\)</span>, assuming that, in the population, the mean of <span class="math inline">\(Y\)</span> is linearly related to the value of <span class="math inline">\(X\)</span>.</p></li>
<li><p>Population relationship → <span class="math inline">\(Y = \beta_0 + \beta_1 X + \epsilon\)</span>.</p></li>
<li><p>Sample relationship → <span class="math inline">\(\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X\)</span>.</p></li>
</ul>
<p>Data structure</p>
<ul>
<li><p>Both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> on a random sample of <span class="math inline">\(n\)</span> individuals are collected from the population of interest.</p></li>
<li><p>The resulting data has the form <span class="math inline">\((X_1, Y_1), \ldots, (X_n, Y_n)\)</span>.</p></li>
</ul>
<p>Model statement → <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)</span></p>
<ul>
<li><p>Holds for all <span class="math inline">\(n\)</span> values in the random sample of <span class="math inline">\(n\)</span> pairs of values, <span class="math inline">\((X_i, Y_i), \, i = 1, \ldots, n\)</span>.</p></li>
<li><p><span class="math inline">\(Y_i\)</span> → Dependent (or response) variable value. These are independent, but not identically distributed.</p></li>
<li><p><span class="math inline">\(X_i\)</span> → Independent (or predictor) variable value. These are <strong>not random variables</strong>, rather <strong>known constants</strong>.</p></li>
<li><p><span class="math inline">\(\epsilon_i\)</span> → Random error term, <strong>assumed</strong> to have mean zero and variance <span class="math inline">\(\sigma^2\)</span>. <span class="math inline">\(\mathrm{Cov}(\epsilon_i, \epsilon_j) = \mathrm{Corr}(\epsilon_i, \epsilon_j) = 0\)</span> for all <span class="math inline">\(i,j : i \ne j\)</span>. Often, the <span class="math inline">\(\epsilon_i\)</span> are assumed to be independent and identically distributed <span class="math inline">\((iid)\)</span>, i.e.&nbsp;all have the same distribution with the same mean and variance.</p></li>
<li><p><span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> → <strong>Fixed</strong> but <strong>unknown</strong> regression parameters that need to be estimated.</p></li>
<li><p><span class="math inline">\(\sigma^2\)</span> → Another parameter that needs estimated, but it is technically <strong>not</strong> a “regression” parameter since it does not determine the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> (i.e.&nbsp;it only deals with randomness).</p></li>
<li><p>Note that <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(\epsilon_i\)</span> are random variables and therefore have distributions. Thus, discussing their mean and variances are appropriate.</p></li>
<li><p>Alternate (equivalent) version of regression model</p></li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>Model statement</p>
<ul>
<li>Can use the deviation <span class="math inline">\(X_i - \bar{X}\)</span> as the predictor instead of <span class="math inline">\(X_i\)</span>. This leads to:</li>
</ul>
<p><span class="math display">\[
Y_i = \beta_0^* + \beta_1 (X_i - \bar{X}) + \epsilon_i, \hspace{20pt} \text{where} \hspace{10pt} \beta_0^* = \beta_0 + \beta_1 \bar{X}
\]</span></p>
<ul>
<li>This model can be useful in some derivations.</li>
</ul>
<p>Later results (jumping ahead)</p>
<ul>
<li>
<p>Estimated coefficients</p>
<ul>
<li><p>LSE for <span class="math inline">\(\beta_1\)</span> is the same as before.</p></li>
<li><p>Now the LSE for <span class="math inline">\(\beta_0^*\)</span> can be found using <span class="math inline">\(\hat{\beta}_0\)</span> :</p></li>
</ul>
</li>
</ul>
<p><span class="math display">\[
\hat{\beta}_0^* = \hat{\beta}_0 + \hat{\beta}_1 \bar{X} = (\bar{Y} - \hat{\beta}_1 \bar{X}) + \hat{\beta}_1 \bar{X} = \bar{Y}
\]</span></p>
<ul>
<li>Estimated regression function</li>
</ul>
<p><span class="math display">\[
\hat{Y} = \bar{Y} - \hat{\beta}_1 (X - \bar{X})
\]</span></p>
<ul>
<li>
<p>Property of all regression functions</p>
<ul>
<li>Using this alternative model, it is easy to see that all regression functions pass through the point <span class="math inline">\((\bar{X}, \bar{Y})\)</span>.</li>
</ul>
</li>
</ul>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p><img src="files/images/alternate-regression-model.png" class="img-fluid" style="width:50.0%"></p>
</div>
</div>
</div>
<p>Some implications of above</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<ul>
<li><p>Mean of <span class="math inline">\(Y_i\)</span> for given <span class="math inline">\(X_i\)</span> → <span class="math inline">\(E(Y_i) = \beta_0 + \beta_1 X_i\)</span></p></li>
<li><p>Variance of <span class="math inline">\(Y_i\)</span> for given <span class="math inline">\(X_i\)</span> → <span class="math inline">\(V(Y_i) = \sigma^2\)</span></p></li>
</ul>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p><img src="files/images/mean-var-y.png" class="img-fluid" style="width:50.0%"></p>
</div>
</div>
</div>
<p>Interpretation of regression parameters <span class="math inline">\((\beta_0, \beta_1)\)</span></p>
<ul>
<li>
<p><span class="math inline">\(\beta_0\)</span></p>
<ul>
<li><p><span class="math inline">\(Y\)</span>-intercept of the regression line and gives <span class="math inline">\(Y\)</span>’s mean when <span class="math inline">\(X = 0\)</span> → <span class="math inline">\(E(Y \mid X = 0) = \beta_0 + \beta_1 \cdot 0 = \beta_0\)</span></p></li>
<li>
<p>Only makes sense to interpret when <span class="math inline">\(X=0\)</span> is within the scope of the model. So, ask two questions when deciding whether or not to interpret:</p>
<ol type="1">
<li><p>Does it make sense to interpret in context?</p></li>
<li><p>Do we have data in the proximity of zero?</p></li>
</ol>
</li>
<li><p>If answer “no” to either of these, then no need to interpret the intercept.</p></li>
</ul>
</li>
<li>
<p><span class="math inline">\(\beta_1\)</span></p>
<ul>
<li><p>Slope of the regression line and indicates the change in <span class="math inline">\(Y\)</span>’s <strong>mean</strong> when <span class="math inline">\(X\)</span> increases by one unit → <span class="math inline">\(E(Y \mid X = x^* + 1) - E(Y \mid X = x^*) = [\beta_0 + \beta_1 (x^* + 1)] - [\beta_0 + \beta_1 x^*] = \beta_1\)</span></p></li>
<li><p>Determines whether a relationship exists between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</p></li>
<li><p>Note that regression <strong>does not</strong> substantiate or prove a <strong>cause-effect</strong> relationship. Rather it gives evidence that <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are related (but not that <span class="math inline">\(X\)</span> “causes” the value of <span class="math inline">\(Y\)</span>).</p></li>
</ul>
</li>
</ul>
<p>Model scope (and the dangers of extrapolation)</p>
<ul>
<li><p>The structural form of the relationship may not be the same as you move away from the observed predictor space. Therefore, using <span class="math inline">\(\hat{Y}\)</span> for estimation / prediction at <span class="math inline">\(X\)</span> values outside of model scope would be extrapolation and results are not reliable.</p></li>
<li><p>Should collect data from the entire region of predictor values of research interest.</p></li>
</ul>
<p><img src="files/images/extrapolation.png" class="img-fluid" style="width:30.0%"></p>
<p>Estimators</p>
<ul>
<li>
<p>Purpose</p>
<ul>
<li><p>Estimators help us make inferences about population parameters.</p></li>
<li><p>Each estimator corresponds to a population parameter (e.g.&nbsp;<span class="math inline">\(\hat{\beta}_1 \rightarrow \beta_1\)</span>).</p></li>
</ul>
</li>
<li>
<p>Estimator / estimate distinction</p>
<ul>
<li><p>Estimators are based on formulas (e.g.&nbsp;<span class="math inline">\(\bar{X} = \frac{1}{n} \sum X_i\)</span>).</p></li>
<li><p>Estimates are values computed from estimators.</p></li>
</ul>
</li>
<li>
<p>Good estimators</p>
<ul>
<li><p><strong>Bias</strong> of an estimator is the difference between the estimator’s expected value and the true value of the parameter being estimated:</p></li>
<li>
<p>If the <strong>bias equals zero</strong>, the estimator is said to be <strong>unbiased</strong>. <span class="math display">\[\text{Bias} = E(\hat{\theta}) - \theta\]</span></p>
<ul>
<li><p>e.g.&nbsp;<span class="math inline">\(\bar{X}\)</span> and <span class="math inline">\(\mu\)</span> → <span class="math inline">\(E(\bar{X}) \overset{\surd} = \mu\)</span>.</p></li>
<li><p>Another way to think about it → <span class="math inline">\(E(\bar{X})\)</span> will be the center of the sampling distribution of <span class="math inline">\(\bar{X}\)</span> (which will be approximately normal because of the central limit theorem), and we want this to equal <span class="math inline">\(\mu\)</span>.</p></li>
</ul>
</li>
<li>
<p>The standard deviation of an estimator is referred to as the <strong>standard error</strong> of said estimator.</p>
<ul>
<li>Ideally, estimators will have relatively small standard deviations, in which case they are said to be <strong>efficient</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul></section><section id="estimation-of-the-regression-function" class="level3" data-number="1.1.2"><h3 data-number="1.1.2" class="anchored" data-anchor-id="estimation-of-the-regression-function">
<span class="header-section-number">1.1.2</span> Estimation of the regression function</h3>
<p>Setup</p>
<ul>
<li><p>For each point we have an observed value <span class="math inline">\(Y_i\)</span>, a fitted value <span class="math inline">\(\hat{Y}_i\)</span> and a residual <span class="math inline">\(\hat{\epsilon}_i\)</span>.</p></li>
<li><p>Fitted regression function → <span class="math inline">\(\hat{Y_i} = \hat{\beta}_0 + \hat{\beta}_1 X_i\)</span>, where <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span> are estimators of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, respectively.</p></li>
</ul>
<p>Goal</p>
<ul>
<li><p>Goal is to estimate the two “regression” parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>There are several methods to do this.</p></li>
</ul></section><section id="method-of-least-squares" class="level3" data-number="1.1.3"><h3 data-number="1.1.3" class="anchored" data-anchor-id="method-of-least-squares">
<span class="header-section-number">1.1.3</span> Method of least squares</h3>
<p>Overview</p>
<ul>
<li><p>The method of least squares is one way to find “good” estimators of the regression parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>For each observation <span class="math inline">\((X_i, Y_i)\)</span>, this method considers the model error term, which is the deviation of <span class="math inline">\(Y_i\)</span> from its expected value:</p></li>
</ul>
<p><span class="math display">\[
\epsilon_i = Y_i - E(Y_i) = Y_i - (\beta_0 + \beta_1 X_i)
\]</span></p>
<ul>
<li>Then we minimize the sum of some function of these errors:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  Q &amp;= \sum_{i = 1}^n \text{function of } \epsilon_i \\
    &amp;= \sum_{i = 1}^n \text{function of } \big(Y_i - E(Y_i)\big) \\
    &amp;= \sum_{i = 1}^n \text{function of } \big(Y_i - (\beta_0 + \beta_1 X_i)\big) \quad\quad \text{&lt; for SLR &gt;}
\end{align*}
\]</span></p>
<ul>
<li>For least squares method specifically, we consider the sum of the <span class="math inline">\(n\)</span> squared errors (deviations). Thus we have:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  Q &amp;= \sum_{i = 1}^n \epsilon_i^2 \\
    &amp;= \sum_{i = 1}^n (Y_i - \beta_0 - \beta_1 X_i)^2
\end{align*}
\]</span></p>
<!-- discussion that this is a loss function, squared loss. there are others??? from theory -->
<ul>
<li><p>According to the method of least squares, the <strong>point estimators</strong> (functions of the random sample that estimate population quantities) of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are those values <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span>, respectively, that minimize the criterion <span class="math inline">\(Q\)</span> for the sample observations <span class="math inline">\((X_1, Y_1), \ldots, (X_n, Y_n)\)</span>.</p></li>
<li><p>Once data is collected, the <strong>estimates</strong> (realized values) for <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> are calculated based on the observed sample <span class="math inline">\((x_1, y_1), \ldots, (x_n, y_n)\)</span>. (Note: no good notation for this, maybe <span class="math inline">\(\hat{b}_0\)</span> and <span class="math inline">\(\hat{b}_1\)</span>; similar idea for means: <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\bar{X}\)</span> and <span class="math inline">\(\bar{x}\)</span>)</p></li>
</ul>
<p>Least squares estimators</p>
<ul>
<li>
<p>These can be found in two ways.</p>
<ol type="1">
<li><p>Numerical methods (optimization) → Search procedures to systematically evaluate the least squares criterion <span class="math inline">\(Q\)</span> for different estimates <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> until the ones that minimize <span class="math inline">\(Q\)</span> are found.</p></li>
<li><p>Analytical methods → Using calculus. The analytical approach is feasible when the regression model is not mathematically complex.</p></li>
</ol>
</li>
<li>
<p>The general process for deriving the least squares estimators of any model is:</p>
<ol type="1">
<li><p>Write <span class="math inline">\(Q\)</span> as a function of the model error term <span class="math inline">\(\epsilon_i\)</span> as shown above.</p></li>
<li><p>Take derivative with respect to the desired parameter <span class="math inline">\(\beta_i\)</span>.</p></li>
<li><p>Set derivative equal to zero (notation: substituting population term <span class="math inline">\(\beta_i\)</span> for its estimator <span class="math inline">\(\hat{\beta}_i\)</span>) and solve for <span class="math inline">\(\hat{\beta}_i\)</span>.</p></li>
<li><p>Check second derivative test to ensure global minimum (take derivative from result of step 2)</p></li>
</ol>
</li>
<li><p>Using the analytical approach with the SLR model, we have the following results:</p></li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<ul>
<li>The estimators <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> are found by solving the simultaneous equations (called the <strong>normal equations</strong>):</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  \sum Y_i &amp;= \hat{\beta}_0 + \hat{\beta}_1 \sum X_i \\
  \sum X_i Y_i &amp;= \hat{\beta}_0 \sum X_i + \hat{\beta}_1 \sum X_i^2
\end{align*}
\]</span></p>
<ul>
<li>This leads to</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  \text{Intercept} \hspace{10pt} \hat{\beta}_0 \hspace{10pt} &amp;= \hspace{10pt} \frac{1}{n}\sum Y_i + \hat{\beta}_1 \frac{1}{n} \sum X_i \hspace{10pt} = \hspace{10pt} \bar{Y}- \hat{\beta}_1 \bar{X} \\
  \text{Slope} \hspace{10pt} \hat{\beta_1} \hspace{10pt} &amp;= \hspace{10pt} \frac{\sum X_i Y_i -\frac{1}{n} \sum X_i Y_i}{\sum X_i^2 - \frac{1}{n}(\sum X_i)^2} \hspace{10pt} = \hspace{10pt} \frac{\sum(X_i - \bar{X})(Y_i - \bar{Y})}{\sum(X_i - \bar{X})^2} \hspace{10pt} = \hspace{10pt} \frac{S_{XY}}{S_{XX}}
\end{align*}
\]</span></p>
<ul>
<li>Note: We did not have to assume any distribution of the error term. These are the LSE estimators for any SLR model.</li>
</ul>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p><img src="files/images/slr-lse-derivation.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
</div>
<ul>
<li>
<p>Demo:</p>
<ul>
<li>First we can generate the sample data <span class="math inline">\((x_1, y_1), \ldots, (x_n, y_n)\)</span>.</li>
</ul>
</li>
</ul>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># simulate sample regression dataset from population model</span></span>
<span><span class="co"># -&gt; E ~ Uniform(a, b)</span></span>
<span><span class="co"># -&gt; Y = B0 + B1X + E</span></span>
<span><span class="co"># -&gt; Y | X ~ Uniform(B0 + B1*X - a, B0 + B1*X + b)</span></span>
<span></span>
<span><span class="co"># initialize items</span></span>
<span><span class="co"># -&gt; sample size, population parameters and error distribution parameters</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">min</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span></span>
<span><span class="va">max</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span></span>
<span><span class="co"># generate X values</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">5</span>, max <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># generate error terms</span></span>
<span><span class="co"># -&gt; assumption for LSE is E(epsilon) = 0, so symmetric uniform about zero works</span></span>
<span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="va">min</span>, max <span class="op">=</span> <span class="va">max</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate y terms as function of x and error terms</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># display observed sample data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">display_nice</span><span class="op">(</span>col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="st">"y"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<table data-quarto-disable-processing="true" class="table table-striped" style="width: auto !important; ">
<thead><tr>
<th style="text-align:right;"> x </th>
   <th style="text-align:right;"> y </th>
  </tr></thead>
<tbody>
<tr>
<td style="text-align:right;"> 5.856 </td>
   <td style="text-align:right;"> 13.003 </td>
  </tr>
<tr>
<td style="text-align:right;"> 9.381 </td>
   <td style="text-align:right;"> 20.418 </td>
  </tr>
<tr>
<td style="text-align:right;"> 11.378 </td>
   <td style="text-align:right;"> 21.809 </td>
  </tr>
<tr>
<td style="text-align:right;"> 14.599 </td>
   <td style="text-align:right;"> 30.780 </td>
  </tr>
<tr>
<td style="text-align:right;"> 12.035 </td>
   <td style="text-align:right;"> 23.352 </td>
  </tr>
<tr>
<td style="text-align:right;"> 5.750 </td>
   <td style="text-align:right;"> 11.816 </td>
  </tr>
<tr>
<td style="text-align:right;"> 14.154 </td>
   <td style="text-align:right;"> 28.206 </td>
  </tr>
<tr>
<td style="text-align:right;"> 13.423 </td>
   <td style="text-align:right;"> 29.633 </td>
  </tr>
<tr>
<td style="text-align:right;"> 6.322 </td>
   <td style="text-align:right;"> 13.835 </td>
  </tr>
<tr>
<td style="text-align:right;"> 10.506 </td>
   <td style="text-align:right;"> 22.197 </td>
  </tr>
</tbody>
</table>
</div>
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot sample data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-slr_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Then we can fit the model and visualize it on the scatter plot.</li>
</ul>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># add regression line to plot</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">14</span>, y <span class="op">=</span> <span class="fl">22</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span> <span class="op">*</span> <span class="st">" = "</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">beta</span><span class="op">)</span><span class="op">[</span><span class="fl">0</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">beta</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">*</span> <span class="st">"X"</span><span class="op">)</span> , col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-slr_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Finally we can get the estimates of <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span>.</li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R Functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Manual</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false">Matrices</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># fit SLR model</span></span>
<span><span class="co"># -&gt; lm() calls lm.fit() behind the scenes --&gt; this performs a QR decomposition to fit the model, which is a more stable way to solve for LSE</span></span>
<span><span class="va">mod_slr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display estimated coefficients</span></span>
<span><span class="va">mod_slr</span><span class="op">$</span><span class="va">coefficients</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           x 
  0.8453137   2.0064051 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># or can do</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coefficients</a></span><span class="op">(</span><span class="va">mod_slr</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_slr</span><span class="op">)</span> <span class="co"># alias for coefficients()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>These are estimates of the population coefficients, so can compare above values to <span class="math inline">\(\beta_0\)</span> = 1 and <span class="math inline">\(\beta_1\)</span> = 2.</p>
<p><mark><strong>Programming note → Beautiful sites (<a href="https://genomicsclass.github.io/book/pages/qr_and_regression.html">(1)</a> and <a href="https://machinelearningmastery.com/solve-linear-regression-using-linear-algebra/#:~:text=The%20QR%20decomposition%20is%20an,down%20into%20its%20constituent%20elements.&amp;text=Where%20A%20is%20the%20matrix,the%20linear%20least%20squares%20equation.">(2)</a>) explaining QR decomposition and how it relates to LSE; must go through and recreate at some point.</strong></mark></p>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate estimates for B0 and B1 using LSE formulas</span></span>
<span><span class="co"># -&gt; b_1 = S_XY / S_XX</span></span>
<span><span class="co"># -&gt; b_0 = Y-bar - b_1 X-bar</span></span>
<span><span class="va">s_xy</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">s_xx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">b_1</span> <span class="op">&lt;-</span> <span class="va">s_xy</span> <span class="op">/</span> <span class="va">s_xx</span></span>
<span><span class="va">b_0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">-</span> <span class="va">b_1</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare to results from lm()</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">b_0</span>, <span class="va">b_1</span><span class="op">)</span>, <span class="va">mod_slr</span><span class="op">$</span><span class="va">coefficients</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>$comparison
(Intercept)           x 
       TRUE        TRUE 

$`c(b_0, b_1)`
[1] 0.8453137 2.0064051

$`mod_slr$coefficients`
(Intercept)           x 
  0.8453137   2.0064051 </code></pre>
</div>
</div>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate estimated betas using matrix regression formulas:</span></span>
<span><span class="co"># -&gt; beta_hat = (X'X)^-1X'Y</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>intercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>, <span class="va">x</span><span class="op">)</span></span>
<span><span class="va">beta_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">X</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">y</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare to results from lm()</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">beta_hat</span>, <span class="va">mod_slr</span><span class="op">$</span><span class="va">coefficients</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>$comparison
          [,1]
intercept TRUE
x         TRUE

$beta_hat
               [,1]
intercept 0.8453137
x         2.0064051

$`mod_slr$coefficients`
(Intercept)           x 
  0.8453137   2.0064051 </code></pre>
</div>
</div>
</div>
</div>
</div>
<p>LSE for other models</p>
<ul>
<li><p>Can also derive LSE estimators for other models using the same process.</p></li>
<li>
<p>Example 1</p>
<ul>
<li>Regression through the origin: <span class="math inline">\(Y = \beta X + \epsilon\)</span>.</li>
</ul>
</li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Setup and Derivation</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">R Functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-3" role="tab" aria-controls="tabset-5-3" aria-selected="false">Manual</a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># simulate sample regression through the origin dataset from population model</span></span>
<span><span class="co"># -&gt; E ~ Uniform(a, b)</span></span>
<span><span class="co"># -&gt; Y = BX + E</span></span>
<span><span class="co"># -&gt; Y | X ~ Uniform(B*X + a, B*X + b)</span></span>
<span></span>
<span><span class="co"># initialize items</span></span>
<span><span class="co"># -&gt; sample size, population parameters and error distribution parameters</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">beta</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">min</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">3</span></span>
<span><span class="va">max</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span></span>
<span><span class="co"># generate X values</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">5</span>, max <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Y | X ~ Uniform(min = BX + a, max = BX + b)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="va">beta</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">min</span>, max <span class="op">=</span> <span class="va">beta</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">max</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot sample data</span></span>
<span><span class="co"># add regression line to plot and reference line for origin</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"lightgrey"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"lightgrey"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">3</span>, y <span class="op">=</span> <span class="op">-</span><span class="fl">5</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span> <span class="op">*</span> <span class="st">" = "</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">beta</span><span class="op">)</span> <span class="op">*</span> <span class="st">"X"</span><span class="op">)</span> , col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-slr_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Derivation of estimator:</li>
</ul>
<p><img src="files/images/slr-lse-derivation-origin.png" class="img-fluid" style="width:40.0%"></p>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># fit SLR model without intercept</span></span>
<span><span class="va">mod_noint</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="op">-</span><span class="fl">1</span> <span class="op">+</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display estimated coefficient</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coefficients</a></span><span class="op">(</span><span class="va">mod_noint</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       x 
2.041284 </code></pre>
</div>
</div>
</div>
<div id="tabset-5-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-3-tab">
<div class="cell">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate estimate B using LSE formula</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span> <span class="op">*</span> <span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare to results from lm()</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">b</span>, <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coefficients</a></span><span class="op">(</span><span class="va">mod_noint</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>$comparison
   x 
TRUE 

$b
[1] 2.041284

$`coefficients(mod_noint)`
       x 
2.041284 </code></pre>
</div>
</div>
</div>
</div>
</div>
<ul>
<li>
<p>Example 2</p>
<ul>
<li><p>Regression through the origin with squared predictor variable: <span class="math inline">\(Y = \beta_1 X^2 + \epsilon\)</span>.</p></li>
<li><p>Sometimes a transformation can make deriving estimators easier. This way we can get the model in a familiar form and derive like usual (simpler). Then we just have to make the appropriate substitutions at the end in order to get the estimators for the original models.</p></li>
<li><p>This strategy lessens the number of models we have to know how to derive (note this is just for deriving; no need to do it when fitting models because it’s an extra middle step that doesn’t change anything, leads to equivalent results).</p></li>
</ul>
</li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">Setup and Derivation</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">R Functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-3" role="tab" aria-controls="tabset-6-3" aria-selected="false">Manual</a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># simulate sample regression through the origin with squared predictor dataset from population model</span></span>
<span><span class="co"># -&gt; E ~ Uniform(a, b)</span></span>
<span><span class="co"># -&gt; Y = BX + E</span></span>
<span><span class="co"># -&gt; Y | X ~ Uniform(B*X^2 + a, B*X^2 + b)</span></span>
<span></span>
<span><span class="co"># initialize items</span></span>
<span><span class="co"># -&gt; sample size, population parameters and error distribution parameters</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">beta</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">min</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">3</span></span>
<span><span class="va">max</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span></span>
<span><span class="co"># generate X values</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">1</span>, max <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Y | X ~ Uniform(min = BX^2 + a, max = BX^2 + b)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="va">beta</span> <span class="op">*</span> <span class="va">x</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">min</span>, max <span class="op">=</span> <span class="va">beta</span> <span class="op">*</span> <span class="va">x</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">max</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot sample data</span></span>
<span><span class="co"># add regression line to plot and reference line for origin</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"lightgrey"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"lightgrey"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">4</span>, y <span class="op">=</span> <span class="fl">15</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span> <span class="op">*</span> <span class="st">" = "</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">beta</span><span class="op">)</span> <span class="op">*</span> <span class="va">X</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> , col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-slr_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Derivation of estimator:</li>
</ul>
<p><img src="files/images/slr-lse-derivation-origin-squared.png" class="img-fluid" style="width:90.0%"></p>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># fit SLR model with no intercept and squared X</span></span>
<span><span class="co"># -&gt; use asis function I() to treat `^` as an arithmetic operator and not a formula operator</span></span>
<span><span class="co"># -&gt; save design matrix for later demo</span></span>
<span><span class="va">mod_noint_squared</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="op">-</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, x <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display estimated coefficient</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_noint_squared</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> I(x^2) 
1.97955 </code></pre>
</div>
</div>
</div>
<div id="tabset-6-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-3-tab">
<div class="cell">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate estimates B using LSE formula</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare to results from lm()</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">b</span>, <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_noint_squared</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>$comparison
I(x^2) 
  TRUE 

$b
[1] 1.97955

$`coef(mod_noint_squared)`
 I(x^2) 
1.97955 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># demonstrating that transformed model way is equivalent</span></span>
<span><span class="co"># -&gt; square predictor variable</span></span>
<span><span class="va">x_star</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">mod_transformed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="op">-</span><span class="fl">1</span> <span class="op">+</span>  <span class="va">x_star</span>, x <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare design matrices of two models</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">mod_noint_squared</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">mod_transformed</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
  I(x^2)
1   TRUE
2   TRUE
3   TRUE
4   TRUE
5   TRUE
6   TRUE

$`head(mod_noint_squared$x)`
       I(x^2)
1  1.93487073
2  0.02277690
3 11.69274107
4 24.02261072
5  1.25945095
6  0.08004023

$`head(mod_transformed$x)`
       x_star
1  1.93487073
2  0.02277690
3 11.69274107
4 24.02261072
5  1.25945095
6  0.08004023</code></pre>
</div>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate estimates B using LSE formula</span></span>
<span><span class="va">b_star</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x_star</span> <span class="op">*</span> <span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x_star</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare betas from usual method and transformed model way</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">b</span>, <span class="va">b_star</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$b
[1] 1.97955

$b_star
[1] 1.97955</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Properties of least squares estimators</p>
<ul>
<li>
<p><strong>Gauss-Markov theorem</strong>: If the conditions of the SLR model hold (i.e.&nbsp;<span class="math inline">\(Y_i= \beta_0 + \beta_1 X_i + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\)</span> have mean zero, variance <span class="math inline">\(\sigma^2\)</span> and are uncorrelated), then the LSE <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> are the <strong>Best Linear Unbiased Estimators (BLUE)</strong> (note that <span class="math inline">\(\epsilon_i\)</span> do not have to be normal).</p>
<ol type="1">
<li><p>Linear estimators → Through lots of algebra (shown later), <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> can be written as be written as a linear combination of the <span class="math inline">\(Y_i\)</span>: <span class="math inline">\(\sum k_i Y_i\)</span>, where <span class="math inline">\(k_i\)</span> are constant. Thus they are linear estimators.</p></li>
<li><p>Unbiased estimators → Their expected values are <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, respectively. So neither estimator tends to overestimate or underestimate systematically.</p></li>
<li><p>Best → More precise than <em>all other linear unbiased estimators of</em> <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> (smaller variance of the sampling distributions).</p></li>
</ol>
</li>
</ul></section><section id="point-estimation-of-the-mean-response" class="level3" data-number="1.1.4"><h3 data-number="1.1.4" class="anchored" data-anchor-id="point-estimation-of-the-mean-response">
<span class="header-section-number">1.1.4</span> Point estimation of the mean response</h3>
<ul>
<li><p>For the population relationship <span class="math inline">\(Y = \beta_0 + \beta_1 X + \epsilon\)</span>, we have the regression function <span class="math inline">\(E(Y) = \beta_0 + \beta_1 X\)</span> (because <span class="math inline">\(E(\epsilon) = 0\)</span>). This is estimated with <span class="math inline">\(\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X\)</span>.</p></li>
<li>
<p>Terms and what they represent:</p>
<ul>
<li><p><span class="math inline">\(Y\)</span> is a value of the response variable; the observed value.</p></li>
<li><p><span class="math inline">\(E(Y)\)</span> the mean response. So it is the center of the probability distribution of <span class="math inline">\(Y\)</span> corresponding to the level <span class="math inline">\(X\)</span> of the predictor variable (so technically a conditional expected value <span class="math inline">\(E(Y \mid X)\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{Y}\)</span> is a point estimator of the mean response when the level of the predictor variable is <span class="math inline">\(X\)</span>; the fitted value.</p></li>
</ul>
</li>
<li>
<p>Application of Gauss-Markov theorem</p>
<ul>
<li>
<span class="math inline">\(\hat{Y}\)</span> is the BLUE for <span class="math inline">\(E(Y)\)</span> with <span class="math inline">\(V(\hat{Y}) = V(\epsilon) = \sigma^2\)</span>.</li>
</ul>
</li>
</ul></section><section id="residuals-and-model-errors" class="level3" data-number="1.1.5"><h3 data-number="1.1.5" class="anchored" data-anchor-id="residuals-and-model-errors">
<span class="header-section-number">1.1.5</span> Residuals and model errors</h3>
<ul>
<li><p>Model error term <span class="math inline">\(\epsilon_i = Y_i - E(Y_i) = Y_i - (\beta_0 + \beta_1 X_i)\)</span> → Measures the difference between an observation and its expected value (unknown true regression line). It is unknown / unobservable.</p></li>
<li><p>Residual <span class="math inline">\(\hat{\epsilon}_i = e_i = Y_i - \hat{Y}_i\)</span> → This is a known, observable estimate of the unobservable model error. Measures the deviation of the observed value from the fitted regression function.</p></li>
</ul>
<p><img src="files/images/residual.png" class="img-fluid" style="width:40.0%"></p>
<ul>
<li>Residuals are very useful for studying whether the given regression model is appropriate for the data.</li>
</ul>
<!-- - <mark> Independence </mark> &rarr;  Because of how are models are constructed   the sum of the residuals is necessarily zero, and thus the residuals are necessarily not independent. However, the model errors are independent (by assumption), and their is almost surely not zero (???? but we expect them to balance out, expected value equal to zero). --><!-- Properties of fitted regression line: PAGE 23, gives 6 properties, could demonstrate if wanted, not sure why these are useful to know --></section></section><section id="estimation-of-error-terms-variance" class="level2" data-number="1.2"><h2 data-number="1.2" class="anchored" data-anchor-id="estimation-of-error-terms-variance">
<span class="header-section-number">1.2</span> Estimation of error terms variance</h2>
<p>Need to estimate the variance <span class="math inline">\(\sigma^2\)</span> of the error terms <span class="math inline">\(\epsilon_i\)</span> in a regression model to get an indication of the variability of the probability distributions of <span class="math inline">\(Y\)</span>. Also several inferences for models require an estimate of <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Motivation</p>
<ul>
<li>For a single population, the variance <span class="math inline">\(\sigma^2\)</span> is estimated by the sample variance <span class="math inline">\(S^2\)</span>, which is an unbiased estimator. We find <span class="math inline">\(S^2\)</span> by taking the sum of the squared deviations of the observed value and the estimated mean (sum of squares) and then dividing it by the degrees of freedom <span class="math inline">\(n - 1\)</span> (one df is lost when estimating <span class="math inline">\(\mu\)</span>; mean square) .</li>
</ul>
<p><span class="math display">\[
S^2 = \frac{\sum_{i = 1}^n (Y_i - \bar{Y})^2}{n - 1}
\]</span></p>
<p>Regression model</p>
<ul>
<li>Same logic as above, except we use the residuals as the deviations because each <span class="math inline">\(Y_i\)</span> comes from a different probability distribution with different <span class="math inline">\(X\)</span> (depends on the <span class="math inline">\(X_i\)</span> level).</li>
</ul>
<p><span class="math display">\[
\text{Error (residual) sum of squares} \hspace{10pt} SSE = \sum_{i = 1}^n (Y_i - \hat{Y_i})^2 = \sum_{i = 1}^n e_i^2
\]</span></p>
<ul>
<li>Then divide by the <span class="math inline">\(df = n - 2\)</span> to the mean square (two dfs are lost when because <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> need to be estimated when getting the estimated means <span class="math inline">\(\hat{Y_i}\)</span>).</li>
</ul>
<p><span class="math display">\[
\text{Error (residual) mean square} \hspace{10pt} S^2 = MSE = \frac{SSE}{n - 2} = \frac{\sum_{i = 1}^n (Y_i - \hat{Y_i})^2}{n - 2} = \frac{\sum_{i = 1}^n e_i^2}{n - 2}
\]</span></p>
<ul>
<li><p>It will be shown later that <span class="math inline">\(MSE\)</span> is an unbiased estimator for <span class="math inline">\(\sigma^2\)</span> → <span class="math inline">\(E(MSE) = \sigma^2\)</span>.</p></li>
<li><p>An estimator of the standard deviation is simply <span class="math inline">\(S = \sqrt{MSE}\)</span>.</p></li>
</ul>
<p>Demo</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Manual</a></li>
</ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># simulate dataset (using uniform errors)</span></span>
<span><span class="co"># initialize items, generate X values, errors and y values</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span>; <span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">1</span>; <span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="fl">2</span>; <span class="va">min</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span>; <span class="va">max</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">5</span>, max <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span>
<span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="va">min</span>, max <span class="op">=</span> <span class="va">max</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span></span>
<span></span>
<span><span class="co"># fit model</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display model summary -&gt; looking for residual standard error = S = sqrt(MSE)</span></span>
<span><span class="co"># -&gt; save to object to extract it</span></span>
<span><span class="op">(</span><span class="va">summ</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.97571 -0.70591 -0.01242  1.00273  1.87927 

Coefficients:
            Estimate Std. Error t value            Pr(&gt;|t|)    
(Intercept)  0.51805    0.87723   0.591                0.56    
x            2.03637    0.08142  25.010 &lt;0.0000000000000002 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.136 on 28 degrees of freedom
Multiple R-squared:  0.9572,    Adjusted R-squared:  0.9556 
F-statistic: 625.5 on 1 and 28 DF,  p-value: &lt; 0.00000000000000022</code></pre>
</div>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># display S and MSE = S^2</span></span>
<span><span class="va">summ</span><span class="op">$</span><span class="va">sigma</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.135683</code></pre>
</div>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">summ</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.289776</code></pre>
</div>
</div>
<p>These are estimates of population quantities for the error terms, and when simulating the data we assumed <span class="math inline">\(\epsilon_i \sim \text{Uniform}\,(a, b) \Longrightarrow \sigma^2 = V(\epsilon_i) = \frac{(b - a)^2}{12}\)</span>. For <span class="math inline">\(a\)</span> = -2 and <span class="math inline">\(b\)</span> = 2, <span class="math inline">\(V(\epsilon_i)\)</span> = 1.333.</p>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># SIDENOTE -&gt; showing multiple equivalent ways to do the same thing (just keep the last way)</span></span>
<span></span>
<span><span class="co"># get fitted values using functions</span></span>
<span><span class="va">y_hat</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="va">fitted.values</span></span>
<span><span class="va">y_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="va">y_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted.values</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span> <span class="co"># alias for fitted()</span></span>
<span><span class="va">y_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span> <span class="co"># discussed more later</span></span>
<span></span>
<span><span class="co"># extract residuals using functions (or some manual calculations)</span></span>
<span><span class="va">e</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">residuals</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="va">e</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span> <span class="co"># alias for residuals()</span></span>
<span><span class="va">e</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="va">residuals</span></span>
<span><span class="va">e</span> <span class="op">&lt;-</span> <span class="va">y</span> <span class="op">-</span> <span class="va">y_hat</span></span>
<span></span>
<span><span class="co"># calculate SSE and df</span></span>
<span><span class="va">sse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">e</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="va">df.residual</span> <span class="co"># extract from model object</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">summ</span><span class="op">$</span><span class="va">df</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="co"># extract from model summary -&gt; error df is the second item (even if have MLR model)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">n</span> <span class="op">-</span> <span class="fl">2</span> <span class="co"># for SLR (with intercept)</span></span>
<span></span>
<span><span class="co"># calculate MSE</span></span>
<span><span class="va">mse</span> <span class="op">&lt;-</span> <span class="va">sse</span> <span class="op">/</span> <span class="va">df</span></span>
<span></span>
<span><span class="co"># calculate residual standard deviation</span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">mse</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare to results from summary(lm())</span></span>
<span><span class="co"># -&gt; s</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">summ</span><span class="op">$</span><span class="va">sigma</span>, <span class="va">s</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`summ$sigma`
[1] 1.135683

$s
[1] 1.135683</code></pre>
</div>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># -&gt; MSE</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">summ</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span>, <span class="va">mse</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`summ$sigma^2`
[1] 1.289776

$mse
[1] 1.289776</code></pre>
</div>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># -&gt; SSE = MSE * df</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">summ</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="va">summ</span><span class="op">$</span><span class="va">df</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">sse</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`summ$sigma^2 * summ$df[2]`
[1] 36.11373

$sse
[1] 36.11373</code></pre>
</div>
</div>
<!-- alternate formula for sse = syy - beta1-hat sxy: from notes; not sure if needed -->
<section id="matrices-1" class="level3" data-number="1.2.1"><h3 data-number="1.2.1" class="anchored" data-anchor-id="matrices-1">
<span class="header-section-number">1.2.1</span> Matrices</h3>
<div class="cell">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate MSE using quadratic forms</span></span>
<span><span class="co"># SSE = Y'(I -H)Y</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>intercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>, <span class="va">x</span><span class="op">)</span></span>
<span><span class="va">hat_matrix</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">X</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span>
<span><span class="va">sse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="op">(</span><span class="fu">Matrix</span><span class="fu">::</span><span class="fu">diag</span><span class="op">(</span>x <span class="op">=</span> <span class="fl">1</span>, nrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="va">hat_matrix</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">y</span></span>
<span></span>
<span><span class="co"># -&gt; SSE = MSE * df</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">summ</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="va">summ</span><span class="op">$</span><span class="va">df</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">sse</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
     [,1]
[1,] TRUE

$`summ$sigma^2 * summ$df[2]`
[1] 36.11373

$sse
         [,1]
[1,] 36.11373</code></pre>
</div>
</div>
</section>
</div>
</div>
</div>
</section><section id="normal-error-regression-model" class="level2" data-number="1.3"><h2 data-number="1.3" class="anchored" data-anchor-id="normal-error-regression-model">
<span class="header-section-number">1.3</span> Normal error regression model</h2>
<p>Least squares results</p>
<ul>
<li>No matter what may be the form of the distribution of the error terms <span class="math inline">\(\epsilon_i\)</span> (and thus of the <span class="math inline">\(Y_i\)</span>), the LSE provides unbiased point estimators of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, that have minimum variance among all unbiased linear estimators (BLUEs).</li>
</ul>
<p>Assumptions on error term distribution</p>
<ul>
<li><p>These assumptions on <span class="math inline">\(\epsilon_i\)</span> are needed to set up interval estimates and make tests.</p></li>
<li><p>The standard assumption is that the error terms are normally distributed. This greatly simplifies the theory of regression analysis and is justifiable in many real-world situations where regression analysis is applied.</p></li>
</ul>
<p>New regression model</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \hspace{20pt} \text{where} \hspace{10pt} \epsilon_i \overset{iid}\sim \text{Normal}\,(0,\sigma^2)
\]</span></p>
<ul>
<li><p>This is the same regression model as before, just with specified error distribution now (<span class="math inline">\(iid\)</span> = independent and identically distributed).</p></li>
<li><p>Because this model assumes normal errors, the assumption of uncorrelatedness of the original (unspecified error) model now becomes an independence assumption (<span class="math inline">\(\perp \!\!\! \perp\Longrightarrow \mathrm{Corr}(\epsilon_i,\epsilon_j) = 0\)</span>. So the outcome in anyone trial has no effect on the error term for any other trial (in terms of positive or negative, small or large).</p></li>
<li><p>This model means <span class="math inline">\(Y_i \overset{\perp \!\!\! \perp}\sim \text{Normal}\,\)</span> with <span class="math inline">\(E(Y_i) = \beta_0 + \beta_1 X_i\)</span> and <span class="math inline">\(V(Y_i) = \sigma^2\)</span>.</p></li>
</ul>
<p><img src="files/images/normal-error-model.png" class="img-fluid" style="width:50.0%"></p>
<p>Justification of the normality assumption.</p>
<ul>
<li><p>Error terms frequently represent the effects of factors omitted from the model that affect the response to some extent and that vary at random without reference to the variable <span class="math inline">\(X\)</span>.</p></li>
<li><p>These random effects have a degree of mutual independence, the composite error term representing all these factors tends to normal as the number of factors becomes large (by the CLT).</p></li>
<li><p>Also, the estimation and testing procedures shown later are based on the <span class="math inline">\(t\)</span> distribution and are usually only sensitive to large departures from normality. So, unless the departures from normality are serious, particularly with respect to skewness, the actual confidence coefficients and risks of errors will be close to the levels for exact normality.</p></li>
</ul>
<section id="estimation-of-paramters-by-method-of-maximum-likelihood" class="level3" data-number="1.3.1"><h3 data-number="1.3.1" class="anchored" data-anchor-id="estimation-of-paramters-by-method-of-maximum-likelihood">
<span class="header-section-number">1.3.1</span> Estimation of paramters by method of maximum likelihood</h3>
<p>Overview</p>
<ul>
<li>
<p>The method of maximum likelihood chooses as estimates values of the parameters that are most consistent with the sample data. The measure of consistency is the product of densities and is called the <strong>likelihood value</strong> <span class="math inline">\(L(\mu)\)</span>.</p>
<ul>
<li>If the value of <span class="math inline">\(\mu\)</span> is consistent with the sample data <span class="math inline">\(\Longrightarrow\)</span> densities relatively large <span class="math inline">\(\Longrightarrow\)</span> large likelihood value. If not, both will be small.</li>
</ul>
</li>
</ul>
<p><img src="files/images/mle-example.png" class="img-fluid" style="width:70.0%"></p>
<ul>
<li><p>Just like the LSE, there are two ways to find MLEs: a systematic numerical search and by use of an analytical solution.</p></li>
<li>
<p>The product of the densities viewed as a function of the unknown parameters is called the <strong>likelihood function</strong>.</p>
<ul>
<li><p>If the likelihood function is relatively peaked in the neighborhood of the maximum, then the MLE estimate is precise because values of <span class="math inline">\(\mu\)</span> not near the MLE are much less consistent with the data.</p></li>
<li><p>When it is relatively flat in a fairly wide region around the MLE, many values of the parameter are almost as consistent with the sample data as the MLE and therefore the MLE is relatively imprecise.</p></li>
</ul>
</li>
</ul>
<!-- SHOW PLOTS and stuff from MLE DEMO??? --><!-- find example of flat mle maybe --><!-- and where have to numerical maximize to get coefficients? functions for how to do this in R?? Is this where gradient descent comes into play?? --><p>Steps to MLEs</p>
<ol type="1">
<li>
<p>For multivariate parameter vector <span class="math inline">\(\boldsymbol{\theta} = (\theta_1, \ldots, \theta_{k})\)</span>, write the likelihood function (i.e.&nbsp;joint density function) and the log-likelihood function</p>
<!-- !!! add more background about MLEs, like why optimize log... -->
</li>
</ol>
<p><span class="math display">\[
L(\boldsymbol{\theta} \mid \mathbf{y}) = \prod_{i = 1}^n f(\mathbf{y} \mid \boldsymbol{\theta}) \hspace{20pt} \rightarrow \hspace{20pt} \ell(\boldsymbol{\theta}) = \ln[L(\boldsymbol{\theta} \mid \mathbf{y})]
\]</span></p>
<ol start="2" type="1">
<li>Optimize the log-likelihood function by taking the partial derivatives with respect to each parameters of interest <span class="math inline">\(\theta_1, \ldots, \theta_{k}\)</span>.</li>
</ol>
<ul>
<li>Set to zero and solve for each parameter of interest.</li>
</ul>
<p><span class="math display">\[
\text{For } j = 1, \ldots, k \hspace{20pt} \ell'(\boldsymbol{\theta}) = \frac{\partial}{\partial \theta_j} \ell(\boldsymbol{\theta}) = 0 \hspace{20pt} \rightarrow \hspace{20pt} \hat{\boldsymbol{\theta}} = (\hat{\theta}_1, \ldots, \hat{\theta}_{k}) = \text{potential MLE}
\]</span></p>
<ul>
<li><p>Verify that the global maximum of the log-likelihood function occurs at <span class="math inline">\(\boldsymbol{\theta} = \hat{\boldsymbol{\theta}}\)</span>.</p></li>
<li><p>Find the second derivative of the log-likelihood function, then plug in <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> and see if less than zero.</p></li>
</ul>
<!-- Hessian matrix stuff --><p>MLEs for normal error regression model</p>
<ul>
<li>Generally</li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 79%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">Parameter</th>
<th style="text-align: left;">MLE</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\beta_0\)</span></td>
<td style="text-align: left;">
<span class="math inline">\(\hat{\beta}_0 \hspace{10pt}\)</span> Same as LSE</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\beta_1\)</span></td>
<td style="text-align: left;">
<span class="math inline">\(\hat{\beta}_1 \hspace{10pt}\)</span> Same as LSE</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\sigma^2\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\displaystyle \hat{\sigma}^2 = \frac{\sum (Y_i - \hat{Y_i})^2}{n}\)</span></td>
</tr>
</tbody>
</table>
<p>Notes</p>
<ul>
<li>
<p>Properties of estimators</p>
<ul>
<li><p>Since MLEs for <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> are the same as the LSE estimators, they have the same properties: BLUE (unbiased and minimum variance in class of unbiased linear estimators).</p></li>
<li><p>And because they are MLEs, we can also say they are: consistent (<span class="math inline">\(\hat{\beta}_i \overset{p}\rightarrow \beta_i\)</span>, converge in probability to their respective parameters); sufficient (captures all of the information about <span class="math inline">\(\beta_i\)</span> contained in the sample); minimum variance in class of unbiased estimators (linear or otherwise).</p></li>
</ul>
</li>
</ul>
<!-- better explanation of sufficiency; state theorem why best variance for all unbiased estimators --><ul>
<li>
<p>MLE <span class="math inline">\(\hat{\sigma}^2\)</span> and MSE</p>
<ul>
<li><p>Relationship <span class="math inline">\(S^2 = MSE = \frac{n}{n - 2} \hat{\sigma}^2 \hspace{20pt} \Longleftrightarrow \hspace{20pt} \hat{\sigma}^2 = \frac{n - 2}{n} MSE\)</span>. However, for large <span class="math inline">\(n\)</span>, the difference is small.</p></li>
<li><p>MLE <span class="math inline">\(\hat{\sigma}^2\)</span> is biased → <span class="math inline">\(E(\hat{\sigma}^2) = \frac{n - 2}{n} \sigma^2\)</span>, which is an underestimation of <span class="math inline">\(\sigma^2\)</span>. Because of this, MSE is generally used because it is unbiased. However, <span class="math inline">\(\hat{\sigma}^2\)</span> is asymptotically unbiased (as <span class="math inline">\(n \rightarrow \infty\)</span>) and has a smaller variance than MSE, which may be preferred in some scenarios (tradeoff between bias and precision).</p></li>
</ul>
</li>
<li><p>Generally MLE gives the same results as LSE.</p></li>
</ul>
<!-- investigate this, when, why? when is one better? !!!! what about when not normal??-->
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<p><img src="files/images/placeholder.png" class="img-fluid" style="width:50.0%"></p>
<ul>
<li>
<p>Can also derive MLEs for transformed models using the same strategy as with LSE.</p>
<ul>
<li>Example: Suppose we have <span class="math inline">\(\ln(Y_i) = \beta_0 + \beta_1 X_i + \epsilon_i\)</span>. We can transform <span class="math inline">\(Y_i^* = \beta_0^* + \beta_1^* X_i + \epsilon_i\)</span>, derive like usual, then substitute at end to get untransformed estimators.</li>
</ul>
</li>
</ul>
<!-- demo calculating mle sigma2 in r based on residuals and compare to mse -->
</div>
</div>
</div>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./part1-slr.html" class="pagination-link  aria-label=" simple="" linear="" regression="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Simple linear regression</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./notes-inference.html" class="pagination-link" aria-label="<span class='chapter-number'>2</span>&nbsp; <span class='chapter-title'>Inference</span>">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inference</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb46" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Simple linear regression {#sec-slr}</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-prereqs</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="co"># knitr options</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define LaTeX macros (/shortcuts) --&gt;</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define vector (without parentheses, so when writing out in like a definition) of the form X_1, ..., X_n, where X and n are variable. </span><span class="al">NOTE</span><span class="co">: to call use $\vecn{X}{n}$ --&gt;</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>\newcommand{\vecn}<span class="co">[</span><span class="ot">2</span><span class="co">]</span>{#1_1, \ldots, #1_{#2}}</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for ~ 'Named dist ' in normal font with space before parameters would go --&gt;</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>\newcommand{\follow}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\sim \text{#1}\,}</span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % (followsp is short for 'follow special') shortcut that can be used for iid or ind ~ 'Named dist ' in normal font with space before parameters would go --&gt;</span></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>\newcommand{\followsp}<span class="co">[</span><span class="ot">2</span><span class="co">]</span>{\overset{#1}\sim \text{#2}\,}</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define independence symbol (it basically makes two orthogonal symbols very close to each other. The number of \! controls the space between each of the orthogonal symbols) --&gt;</span></span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>\newcommand{\ind}{\perp <span class="sc">\!\!\!</span> \perp}</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for Cov(X,Y) with formatting for Cov --&gt;</span></span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>\newcommand{\cov}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\mathrm{Cov}(#1)}</span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for Corr(X,Y) with formatting for Corr --&gt;</span></span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>\newcommand{\corr}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\mathrm{Corr}(#1)}</span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for non-italic e in math mode --&gt;</span></span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a>\newcommand{\e}{\mathrm{e}}</span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression overview</span></span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a>Regression overview</span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Goal is to determine **if** and **how** one variable is related to a set of other variables.</span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Variables</span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Response variable, denoted $Y$, represents an outcome whose variation is being studied.</span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Explanatory variable, denoted $X$, represents the causes (i.e. potential reasons for variation).</span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Two types of relationships</span>
<span id="cb46-58"><a href="#cb46-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Functional (deterministic) → There is an exact relation between two variables (have the form $y = ax+ b$).</span>
<span id="cb46-60"><a href="#cb46-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-61"><a href="#cb46-61" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Statistical (probabilistic) → There is not an exact relation because there are other variables that affect the relationship (have the form $y = ax + b + \epsilon$).</span>
<span id="cb46-62"><a href="#cb46-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-63"><a href="#cb46-63" aria-hidden="true" tabindex="-1"></a>Regression models and their uses</span>
<span id="cb46-64"><a href="#cb46-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-65"><a href="#cb46-65" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Statistical models quantify the relationship between a response variable (i.e. a random variable) and explanatory variables, which are usually assumed to be deterministic (i.e. known exactly).</span>
<span id="cb46-66"><a href="#cb46-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-67"><a href="#cb46-67" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Elements of a statistical regression model</span>
<span id="cb46-68"><a href="#cb46-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-69"><a href="#cb46-69" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In general, observations do not fall directly on the curve of a relationship.</span>
<span id="cb46-70"><a href="#cb46-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-71"><a href="#cb46-71" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>$Y \mid X$ has a probability distribution.</span>
<span id="cb46-72"><a href="#cb46-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-73"><a href="#cb46-73" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>$E(Y \mid X)$ varies deterministically with $X$.</span>
<span id="cb46-74"><a href="#cb46-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-75"><a href="#cb46-75" aria-hidden="true" tabindex="-1"></a>        <span class="al">![](files/images/regression-curve.png)</span>{width="50%"}</span>
<span id="cb46-76"><a href="#cb46-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-77"><a href="#cb46-77" aria-hidden="true" tabindex="-1"></a><span class="in">    -   So the statistical model is:</span></span>
<span id="cb46-78"><a href="#cb46-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-79"><a href="#cb46-79" aria-hidden="true" tabindex="-1"></a><span class="in">        $$</span></span>
<span id="cb46-80"><a href="#cb46-80" aria-hidden="true" tabindex="-1"></a><span class="in">        \begin{align*}</span></span>
<span id="cb46-81"><a href="#cb46-81" aria-hidden="true" tabindex="-1"></a><span class="in">          Y &amp;= E(Y \mid X) + \epsilon \\</span></span>
<span id="cb46-82"><a href="#cb46-82" aria-hidden="true" tabindex="-1"></a><span class="in">            &amp;= f(X) + \epsilon, \hspace{20pt} \text{where $\epsilon$ has some distribution}</span></span>
<span id="cb46-83"><a href="#cb46-83" aria-hidden="true" tabindex="-1"></a><span class="in">        \end{align*}</span></span>
<span id="cb46-84"><a href="#cb46-84" aria-hidden="true" tabindex="-1"></a><span class="in">        $$</span></span>
<span id="cb46-85"><a href="#cb46-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-86"><a href="#cb46-86" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Two components of a statistical model:</span>
<span id="cb46-87"><a href="#cb46-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-88"><a href="#cb46-88" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>$f(X) = E(Y \mid X)$ → Defines relationship between $Y$ and $X$; explains the average behavior of the response.</span>
<span id="cb46-89"><a href="#cb46-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-90"><a href="#cb46-90" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>$\epsilon$ → An element of randomness (i.e. error). This contains the variation that $f(X)$ cannot explain and/or that is of no interest.</span>
<span id="cb46-91"><a href="#cb46-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-92"><a href="#cb46-92" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This means $f(X) = E(Y \mid X)$ will be the same for all samples with the same $X$ values. The only thing that changes is the random error $\epsilon$ and as a result $Y$. Example $Y = 3 + 1X + \epsilon$:</span>
<span id="cb46-93"><a href="#cb46-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-96"><a href="#cb46-96" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-97"><a href="#cb46-97" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-98"><a href="#cb46-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-99"><a href="#cb46-99" aria-hidden="true" tabindex="-1"></a><span class="co"># create regression data frame to show different the deterministic and statistical relationships (assuming SLR normal error model for demonstration so can visualize)</span></span>
<span id="cb46-100"><a href="#cb46-100" aria-hidden="true" tabindex="-1"></a><span class="co"># generate</span></span>
<span id="cb46-101"><a href="#cb46-101" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; X values (not from a random dist)</span></span>
<span id="cb46-102"><a href="#cb46-102" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; f(X) = E(Y | X) = beta_0 + beta_1 X demonstration</span></span>
<span id="cb46-103"><a href="#cb46-103" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; random error = epsilon ~ N(0,1)</span></span>
<span id="cb46-104"><a href="#cb46-104" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y = f(X) + epsilon</span></span>
<span id="cb46-105"><a href="#cb46-105" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb46-106"><a href="#cb46-106" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb46-107"><a href="#cb46-107" aria-hidden="true" tabindex="-1"></a>data_ships <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">X =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">10</span>, <span class="at">to =</span> <span class="dv">19</span>, <span class="at">by =</span> <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb46-108"><a href="#cb46-108" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">f_X =</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> X,</span>
<span id="cb46-109"><a href="#cb46-109" aria-hidden="true" tabindex="-1"></a>         <span class="at">epsilon =</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="fu">nrow</span>(.), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb46-110"><a href="#cb46-110" aria-hidden="true" tabindex="-1"></a>         <span class="at">Y =</span> f_X <span class="sc">+</span> epsilon)</span>
<span id="cb46-111"><a href="#cb46-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-112"><a href="#cb46-112" aria-hidden="true" tabindex="-1"></a><span class="co"># display data</span></span>
<span id="cb46-113"><a href="#cb46-113" aria-hidden="true" tabindex="-1"></a>data_ships <span class="sc">%&gt;%</span> <span class="fu">display_nice</span>(<span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"X"</span>, <span class="st">"f(X) = E(Y | X)"</span>, <span class="st">"$epsilon ~ N(0,1)"</span>, <span class="st">"Y = f(X) + epsilon"</span>))</span>
<span id="cb46-114"><a href="#cb46-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-115"><a href="#cb46-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-116"><a href="#cb46-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-117"><a href="#cb46-117" aria-hidden="true" tabindex="-1"></a><span class="co"># plot (X, Y)</span></span>
<span id="cb46-118"><a href="#cb46-118" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; and add points and line for E(Y | X)</span></span>
<span id="cb46-119"><a href="#cb46-119" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; population E(Y | X)) because using known betas (not estimating from sample data)</span></span>
<span id="cb46-120"><a href="#cb46-120" aria-hidden="true" tabindex="-1"></a>data_ships <span class="sc">%$%</span> </span>
<span id="cb46-121"><a href="#cb46-121" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">type =</span> <span class="st">"p"</span>, <span class="at">main =</span> <span class="st">"Deterministic vs statistical relationship"</span>)</span>
<span id="cb46-122"><a href="#cb46-122" aria-hidden="true" tabindex="-1"></a>data_ships <span class="sc">%$%</span> </span>
<span id="cb46-123"><a href="#cb46-123" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(<span class="at">x =</span> X, <span class="at">y =</span> f_X, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">pch =</span> <span class="dv">5</span>)</span>
<span id="cb46-124"><a href="#cb46-124" aria-hidden="true" tabindex="-1"></a>data_ships <span class="sc">%$%</span> </span>
<span id="cb46-125"><a href="#cb46-125" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="at">x =</span> X, <span class="at">y =</span> f_X, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb46-126"><a href="#cb46-126" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="fl">18.5</span>, <span class="at">y =</span> <span class="dv">20</span>, <span class="at">labels =</span> <span class="st">"f(X) = E(Y|X)"</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb46-127"><a href="#cb46-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-128"><a href="#cb46-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-129"><a href="#cb46-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-130"><a href="#cb46-130" aria-hidden="true" tabindex="-1"></a>Construction of statistical regression models</span>
<span id="cb46-131"><a href="#cb46-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-132"><a href="#cb46-132" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Selection of predictor variables (how to decide which ones?).</span>
<span id="cb46-133"><a href="#cb46-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-134"><a href="#cb46-134" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Use of outside information, historical knowledge, and/or experience.</span>
<span id="cb46-135"><a href="#cb46-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-136"><a href="#cb46-136" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Exploratory data analysis.</span>
<span id="cb46-137"><a href="#cb46-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-138"><a href="#cb46-138" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Variable selection techniques → Find a subset of important variables (i.e. practical and easy to find).</span>
<span id="cb46-139"><a href="#cb46-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-140"><a href="#cb46-140" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Functional form of the regression relation (what is form of $f(X)$?).</span>
<span id="cb46-141"><a href="#cb46-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-142"><a href="#cb46-142" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="sc">\&lt;</span> based on same info as (1) <span class="sc">\&gt;</span></span>
<span id="cb46-143"><a href="#cb46-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-144"><a href="#cb46-144" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If there is an abundance of data, maybe start with more complex models and then simplify.</span>
<span id="cb46-145"><a href="#cb46-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-146"><a href="#cb46-146" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Scope of model (when is the model useful?).</span>
<span id="cb46-147"><a href="#cb46-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-148"><a href="#cb46-148" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When the model best predicts or describes the relationship between response and predictor variables.</span>
<span id="cb46-149"><a href="#cb46-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-150"><a href="#cb46-150" aria-hidden="true" tabindex="-1"></a>Uses of statistical regression models</span>
<span id="cb46-151"><a href="#cb46-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-152"><a href="#cb46-152" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Determining whether an $X$ "affects" $Y$ or not.</span>
<span id="cb46-153"><a href="#cb46-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-154"><a href="#cb46-154" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Estimation of impact of a given $X$ on the $Y$.</span>
<span id="cb46-155"><a href="#cb46-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-156"><a href="#cb46-156" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Estimation of the mean of $Y$ for a given $X$ value.</span>
<span id="cb46-157"><a href="#cb46-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-158"><a href="#cb46-158" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Prediction of a single value of $Y$ for a given $X$ value.</span>
<span id="cb46-159"><a href="#cb46-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-160"><a href="#cb46-160" aria-hidden="true" tabindex="-1"></a>Typical strategy for regression analysis</span>
<span id="cb46-161"><a href="#cb46-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-162"><a href="#cb46-162" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/regression-flow-chart.png)</span>{width="25%"}</span>
<span id="cb46-163"><a href="#cb46-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-164"><a href="#cb46-164" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simple linear regression model (SLR)</span></span>
<span id="cb46-165"><a href="#cb46-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-166"><a href="#cb46-166" aria-hidden="true" tabindex="-1"></a>Goal of SLR</span>
<span id="cb46-167"><a href="#cb46-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-168"><a href="#cb46-168" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Investigate the relationship between $Y$ and a single numeric independent variable $X$, assuming that, in the population, the mean of $Y$ is linearly related to the value of $X$.</span>
<span id="cb46-169"><a href="#cb46-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-170"><a href="#cb46-170" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Population relationship → $Y = \beta_0 + \beta_1 X + \epsilon$.</span>
<span id="cb46-171"><a href="#cb46-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-172"><a href="#cb46-172" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Sample relationship → $\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X$.</span>
<span id="cb46-173"><a href="#cb46-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-174"><a href="#cb46-174" aria-hidden="true" tabindex="-1"></a>Data structure</span>
<span id="cb46-175"><a href="#cb46-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-176"><a href="#cb46-176" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Both $X$ and $Y$ on a random sample of $n$ individuals are collected from the population of interest.</span>
<span id="cb46-177"><a href="#cb46-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-178"><a href="#cb46-178" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The resulting data has the form $(X_1, Y_1), \ldots, (X_n, Y_n)$.</span>
<span id="cb46-179"><a href="#cb46-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-180"><a href="#cb46-180" aria-hidden="true" tabindex="-1"></a>Model statement → $Y_i = \beta_0 + \beta_1 X_i + \epsilon_i$</span>
<span id="cb46-181"><a href="#cb46-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-182"><a href="#cb46-182" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Holds for all $n$ values in the random sample of $n$ pairs of values, $(X_i, Y_i), \, i = 1, \ldots, n$.</span>
<span id="cb46-183"><a href="#cb46-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-184"><a href="#cb46-184" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$Y_i$ → Dependent (or response) variable value. These are independent, but not identically distributed.</span>
<span id="cb46-185"><a href="#cb46-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-186"><a href="#cb46-186" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$X_i$ → Independent (or predictor) variable value. These are **not random variables**, rather **known constants**.</span>
<span id="cb46-187"><a href="#cb46-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-188"><a href="#cb46-188" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\epsilon_i$ → Random error term, **assumed** to have mean zero and variance $\sigma^2$. $\mathrm{Cov}(\epsilon_i, \epsilon_j) = \mathrm{Corr}(\epsilon_i, \epsilon_j) = 0$ for all $i,j : i \ne j$. Often, the $\epsilon_i$ are assumed to be independent and identically distributed $(iid)$, i.e. all have the same distribution with the same mean and variance.</span>
<span id="cb46-189"><a href="#cb46-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-190"><a href="#cb46-190" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\beta_0$ and $\beta_1$ → **Fixed** but **unknown** regression parameters that need to be estimated.</span>
<span id="cb46-191"><a href="#cb46-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-192"><a href="#cb46-192" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\sigma^2$ → Another parameter that needs estimated, but it is technically **not** a "regression" parameter since it does not determine the relationship between $Y$ and $X$ (i.e. it only deals with randomness).</span>
<span id="cb46-193"><a href="#cb46-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-194"><a href="#cb46-194" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note that $Y_i$ and $\epsilon_i$ are random variables and therefore have distributions. Thus, discussing their mean and variances are appropriate.</span>
<span id="cb46-195"><a href="#cb46-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-196"><a href="#cb46-196" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Alternate (equivalent) version of regression model</span>
<span id="cb46-197"><a href="#cb46-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-198"><a href="#cb46-198" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb46-199"><a href="#cb46-199" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb46-200"><a href="#cb46-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-201"><a href="#cb46-201" aria-hidden="true" tabindex="-1"></a>Model statement</span>
<span id="cb46-202"><a href="#cb46-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-203"><a href="#cb46-203" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Can use the deviation $X_i - \bar{X}$ as the predictor instead of $X_i$. This leads to:</span>
<span id="cb46-204"><a href="#cb46-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-205"><a href="#cb46-205" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-206"><a href="#cb46-206" aria-hidden="true" tabindex="-1"></a>Y_i = \beta_0^* + \beta_1 (X_i - \bar{X}) + \epsilon_i, \hspace{20pt} \text{where} \hspace{10pt} \beta_0^* = \beta_0 + \beta_1 \bar{X}</span>
<span id="cb46-207"><a href="#cb46-207" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-208"><a href="#cb46-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-209"><a href="#cb46-209" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This model can be useful in some derivations.</span>
<span id="cb46-210"><a href="#cb46-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-211"><a href="#cb46-211" aria-hidden="true" tabindex="-1"></a>Later results (jumping ahead)</span>
<span id="cb46-212"><a href="#cb46-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-213"><a href="#cb46-213" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Estimated coefficients</span>
<span id="cb46-214"><a href="#cb46-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-215"><a href="#cb46-215" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>LSE for $\beta_1$ is the same as before.</span>
<span id="cb46-216"><a href="#cb46-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-217"><a href="#cb46-217" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Now the LSE for $\beta_0^*$ can be found using $\hat{\beta}_0$ :</span>
<span id="cb46-218"><a href="#cb46-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-219"><a href="#cb46-219" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-220"><a href="#cb46-220" aria-hidden="true" tabindex="-1"></a>\hat{\beta}_0^* = \hat{\beta}_0 + \hat{\beta}_1 \bar{X} = (\bar{Y} - \hat{\beta}_1 \bar{X}) + \hat{\beta}_1 \bar{X} = \bar{Y}</span>
<span id="cb46-221"><a href="#cb46-221" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-222"><a href="#cb46-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-223"><a href="#cb46-223" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Estimated regression function</span>
<span id="cb46-224"><a href="#cb46-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-225"><a href="#cb46-225" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-226"><a href="#cb46-226" aria-hidden="true" tabindex="-1"></a>\hat{Y} = \bar{Y} - \hat{\beta}_1 (X - \bar{X})</span>
<span id="cb46-227"><a href="#cb46-227" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-228"><a href="#cb46-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-229"><a href="#cb46-229" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Property of all regression functions</span>
<span id="cb46-230"><a href="#cb46-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-231"><a href="#cb46-231" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Using this alternative model, it is easy to see that all regression functions pass through the point $(\bar{X}, \bar{Y})$.</span>
<span id="cb46-232"><a href="#cb46-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-233"><a href="#cb46-233" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb46-234"><a href="#cb46-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-235"><a href="#cb46-235" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/alternate-regression-model.png)</span>{width="50%"}</span>
<span id="cb46-236"><a href="#cb46-236" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-237"><a href="#cb46-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-238"><a href="#cb46-238" aria-hidden="true" tabindex="-1"></a>Some implications of above</span>
<span id="cb46-239"><a href="#cb46-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-240"><a href="#cb46-240" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb46-241"><a href="#cb46-241" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb46-242"><a href="#cb46-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-243"><a href="#cb46-243" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Mean of $Y_i$ for given $X_i$ → $E(Y_i) = \beta_0 + \beta_1 X_i$</span>
<span id="cb46-244"><a href="#cb46-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-245"><a href="#cb46-245" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Variance of $Y_i$ for given $X_i$ → $V(Y_i) = \sigma^2$</span>
<span id="cb46-246"><a href="#cb46-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-247"><a href="#cb46-247" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb46-248"><a href="#cb46-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-249"><a href="#cb46-249" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/mean-var-y.png)</span>{width="50%"}</span>
<span id="cb46-250"><a href="#cb46-250" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-251"><a href="#cb46-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-252"><a href="#cb46-252" aria-hidden="true" tabindex="-1"></a>Interpretation of regression parameters $(\beta_0, \beta_1)$</span>
<span id="cb46-253"><a href="#cb46-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-254"><a href="#cb46-254" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\beta_0$</span>
<span id="cb46-255"><a href="#cb46-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-256"><a href="#cb46-256" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$Y$-intercept of the regression line and gives $Y$'s mean when $X = 0$ → $E(Y \mid X = 0) = \beta_0 + \beta_1 \cdot 0 = \beta_0$</span>
<span id="cb46-257"><a href="#cb46-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-258"><a href="#cb46-258" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Only makes sense to interpret when $X=0$ is within the scope of the model. So, ask two questions when deciding whether or not to interpret:</span>
<span id="cb46-259"><a href="#cb46-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-260"><a href="#cb46-260" aria-hidden="true" tabindex="-1"></a><span class="ss">        1.  </span>Does it make sense to interpret in context?</span>
<span id="cb46-261"><a href="#cb46-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-262"><a href="#cb46-262" aria-hidden="true" tabindex="-1"></a><span class="ss">        2.  </span>Do we have data in the proximity of zero?</span>
<span id="cb46-263"><a href="#cb46-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-264"><a href="#cb46-264" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If answer "no" to either of these, then no need to interpret the intercept.</span>
<span id="cb46-265"><a href="#cb46-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-266"><a href="#cb46-266" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\beta_1$</span>
<span id="cb46-267"><a href="#cb46-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-268"><a href="#cb46-268" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Slope of the regression line and indicates the change in $Y$'s **mean** when $X$ increases by one unit → $E(Y \mid X = x^* + 1) - E(Y \mid X = x^*) = [\beta_0 + \beta_1 (x^* + 1)] - [\beta_0 + \beta_1 x^*] = \beta_1$</span>
<span id="cb46-269"><a href="#cb46-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-270"><a href="#cb46-270" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Determines whether a relationship exists between $Y$ and $X$.</span>
<span id="cb46-271"><a href="#cb46-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-272"><a href="#cb46-272" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Note that regression **does not** substantiate or prove a **cause-effect** relationship. Rather it gives evidence that $Y$ and $X$ are related (but not that $X$ "causes" the value of $Y$).</span>
<span id="cb46-273"><a href="#cb46-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-274"><a href="#cb46-274" aria-hidden="true" tabindex="-1"></a>Model scope (and the dangers of extrapolation)</span>
<span id="cb46-275"><a href="#cb46-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-276"><a href="#cb46-276" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The structural form of the relationship may not be the same as you move away from the observed predictor space. Therefore, using $\hat{Y}$ for estimation / prediction at $X$ values outside of model scope would be extrapolation and results are not reliable.</span>
<span id="cb46-277"><a href="#cb46-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-278"><a href="#cb46-278" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Should collect data from the entire region of predictor values of research interest.</span>
<span id="cb46-279"><a href="#cb46-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-280"><a href="#cb46-280" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/extrapolation.png)</span>{width="30%"}</span>
<span id="cb46-281"><a href="#cb46-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-282"><a href="#cb46-282" aria-hidden="true" tabindex="-1"></a>Estimators</span>
<span id="cb46-283"><a href="#cb46-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-284"><a href="#cb46-284" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Purpose</span>
<span id="cb46-285"><a href="#cb46-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-286"><a href="#cb46-286" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Estimators help us make inferences about population parameters.</span>
<span id="cb46-287"><a href="#cb46-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-288"><a href="#cb46-288" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Each estimator corresponds to a population parameter (e.g. $\hat{\beta}_1 \rightarrow \beta_1$).</span>
<span id="cb46-289"><a href="#cb46-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-290"><a href="#cb46-290" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Estimator / estimate distinction</span>
<span id="cb46-291"><a href="#cb46-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-292"><a href="#cb46-292" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Estimators are based on formulas (e.g. $\bar{X} = \frac{1}{n} \sum X_i$).</span>
<span id="cb46-293"><a href="#cb46-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-294"><a href="#cb46-294" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Estimates are values computed from estimators.</span>
<span id="cb46-295"><a href="#cb46-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-296"><a href="#cb46-296" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Good estimators</span>
<span id="cb46-297"><a href="#cb46-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-298"><a href="#cb46-298" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Bias** of an estimator is the difference between the estimator's expected value and the true value of the parameter being estimated:</span>
<span id="cb46-299"><a href="#cb46-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-300"><a href="#cb46-300" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If the **bias equals zero**, the estimator is said to be **unbiased**. $$\text{Bias} = E(\hat{\theta}) - \theta$$</span>
<span id="cb46-301"><a href="#cb46-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-302"><a href="#cb46-302" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>e.g. $\bar{X}$ and $\mu$ → $E(\bar{X}) \overset{\surd} = \mu$.</span>
<span id="cb46-303"><a href="#cb46-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-304"><a href="#cb46-304" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Another way to think about it → $E(\bar{X})$ will be the center of the sampling distribution of $\bar{X}$ (which will be approximately normal because of the central limit theorem), and we want this to equal $\mu$.</span>
<span id="cb46-305"><a href="#cb46-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-306"><a href="#cb46-306" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The standard deviation of an estimator is referred to as the **standard error** of said estimator.</span>
<span id="cb46-307"><a href="#cb46-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-308"><a href="#cb46-308" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Ideally, estimators will have relatively small standard deviations, in which case they are said to be **efficient**.</span>
<span id="cb46-309"><a href="#cb46-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-310"><a href="#cb46-310" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimation of the regression function</span></span>
<span id="cb46-311"><a href="#cb46-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-312"><a href="#cb46-312" aria-hidden="true" tabindex="-1"></a>Setup</span>
<span id="cb46-313"><a href="#cb46-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-314"><a href="#cb46-314" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For each point we have an observed value $Y_i$, a fitted value $\hat{Y}_i$ and a residual $\hat{\epsilon}_i$.</span>
<span id="cb46-315"><a href="#cb46-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-316"><a href="#cb46-316" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Fitted regression function → $\hat{Y_i} = \hat{\beta}_0 + \hat{\beta}_1 X_i$, where $\hat{\beta}_0$ and $\hat{\beta}_0$ are estimators of $\beta_0$ and $\beta_1$, respectively.</span>
<span id="cb46-317"><a href="#cb46-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-318"><a href="#cb46-318" aria-hidden="true" tabindex="-1"></a>Goal</span>
<span id="cb46-319"><a href="#cb46-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-320"><a href="#cb46-320" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Goal is to estimate the two "regression" parameters $\beta_0$ and $\beta_1$.</span>
<span id="cb46-321"><a href="#cb46-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-322"><a href="#cb46-322" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There are several methods to do this.</span>
<span id="cb46-323"><a href="#cb46-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-324"><a href="#cb46-324" aria-hidden="true" tabindex="-1"></a><span class="fu">### Method of least squares</span></span>
<span id="cb46-325"><a href="#cb46-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-326"><a href="#cb46-326" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb46-327"><a href="#cb46-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-328"><a href="#cb46-328" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The method of least squares is one way to find "good" estimators of the regression parameters $\beta_0$ and $\beta_1$.</span>
<span id="cb46-329"><a href="#cb46-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-330"><a href="#cb46-330" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For each observation $(X_i, Y_i)$, this method considers the model error term, which is the deviation of $Y_i$ from its expected value:</span>
<span id="cb46-331"><a href="#cb46-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-332"><a href="#cb46-332" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-333"><a href="#cb46-333" aria-hidden="true" tabindex="-1"></a>\epsilon_i = Y_i - E(Y_i) = Y_i - (\beta_0 + \beta_1 X_i)</span>
<span id="cb46-334"><a href="#cb46-334" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-335"><a href="#cb46-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-336"><a href="#cb46-336" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Then we minimize the sum of some function of these errors:</span>
<span id="cb46-337"><a href="#cb46-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-338"><a href="#cb46-338" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-339"><a href="#cb46-339" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb46-340"><a href="#cb46-340" aria-hidden="true" tabindex="-1"></a>  Q &amp;= \sum_{i = 1}^n \text{function of } \epsilon_i <span class="sc">\\</span></span>
<span id="cb46-341"><a href="#cb46-341" aria-hidden="true" tabindex="-1"></a>    &amp;= \sum_{i = 1}^n \text{function of } \big(Y_i - E(Y_i)\big) <span class="sc">\\</span></span>
<span id="cb46-342"><a href="#cb46-342" aria-hidden="true" tabindex="-1"></a>    &amp;= \sum_{i = 1}^n \text{function of } \big(Y_i - (\beta_0 + \beta_1 X_i)\big) \quad\quad \text{&lt; for SLR &gt;}</span>
<span id="cb46-343"><a href="#cb46-343" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb46-344"><a href="#cb46-344" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-345"><a href="#cb46-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-346"><a href="#cb46-346" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For least squares method specifically, we consider the sum of the $n$ squared errors (deviations). Thus we have:</span>
<span id="cb46-347"><a href="#cb46-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-348"><a href="#cb46-348" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-349"><a href="#cb46-349" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb46-350"><a href="#cb46-350" aria-hidden="true" tabindex="-1"></a>  Q &amp;= \sum_{i = 1}^n \epsilon_i^2 <span class="sc">\\</span></span>
<span id="cb46-351"><a href="#cb46-351" aria-hidden="true" tabindex="-1"></a>    &amp;= \sum_{i = 1}^n (Y_i - \beta_0 - \beta_1 X_i)^2</span>
<span id="cb46-352"><a href="#cb46-352" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb46-353"><a href="#cb46-353" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-354"><a href="#cb46-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-355"><a href="#cb46-355" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- discussion that this is a loss function, squared loss. there are others??? from theory --&gt;</span></span>
<span id="cb46-356"><a href="#cb46-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-357"><a href="#cb46-357" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>According to the method of least squares, the **point estimators** (functions of the random sample that estimate population quantities) of $\beta_0$ and $\beta_1$ are those values $\hat{\beta}_0$ and $\hat{\beta}_1$, respectively, that minimize the criterion $Q$ for the sample observations $(X_1, Y_1), \ldots, (X_n, Y_n)$.</span>
<span id="cb46-358"><a href="#cb46-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-359"><a href="#cb46-359" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Once data is collected, the **estimates** (realized values) for $\hat{\beta}_0$ and $\hat{\beta}_1$ are calculated based on the observed sample $(x_1, y_1), \ldots, (x_n, y_n)$. (Note: no good notation for this, maybe $\hat{b}_0$ and $\hat{b}_1$; similar idea for means: $\mu$, $\bar{X}$ and $\bar{x}$)</span>
<span id="cb46-360"><a href="#cb46-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-361"><a href="#cb46-361" aria-hidden="true" tabindex="-1"></a>Least squares estimators</span>
<span id="cb46-362"><a href="#cb46-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-363"><a href="#cb46-363" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>These can be found in two ways.</span>
<span id="cb46-364"><a href="#cb46-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-365"><a href="#cb46-365" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>Numerical methods (optimization) → Search procedures to systematically evaluate the least squares criterion $Q$ for different estimates $\hat{\beta}_0$ and $\hat{\beta}_1$ until the ones that minimize $Q$ are found.</span>
<span id="cb46-366"><a href="#cb46-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-367"><a href="#cb46-367" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>Analytical methods → Using calculus. The analytical approach is feasible when the regression model is not mathematically complex.</span>
<span id="cb46-368"><a href="#cb46-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-369"><a href="#cb46-369" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The general process for deriving the least squares estimators of any model is:</span>
<span id="cb46-370"><a href="#cb46-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-371"><a href="#cb46-371" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>Write $Q$ as a function of the model error term $\epsilon_i$ as shown above.</span>
<span id="cb46-372"><a href="#cb46-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-373"><a href="#cb46-373" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>Take derivative with respect to the desired parameter $\beta_i$.</span>
<span id="cb46-374"><a href="#cb46-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-375"><a href="#cb46-375" aria-hidden="true" tabindex="-1"></a><span class="ss">    3.  </span>Set derivative equal to zero (notation: substituting population term $\beta_i$ for its estimator $\hat{\beta}_i$) and solve for $\hat{\beta}_i$.</span>
<span id="cb46-376"><a href="#cb46-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-377"><a href="#cb46-377" aria-hidden="true" tabindex="-1"></a><span class="ss">    4.  </span>Check second derivative test to ensure global minimum (take derivative from result of step 2)</span>
<span id="cb46-378"><a href="#cb46-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-379"><a href="#cb46-379" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Using the analytical approach with the SLR model, we have the following results:</span>
<span id="cb46-380"><a href="#cb46-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-381"><a href="#cb46-381" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb46-382"><a href="#cb46-382" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb46-383"><a href="#cb46-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-384"><a href="#cb46-384" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The estimators $\hat{\beta}_0$ and $\hat{\beta}_1$ are found by solving the simultaneous equations (called the **normal equations**):</span>
<span id="cb46-385"><a href="#cb46-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-386"><a href="#cb46-386" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-387"><a href="#cb46-387" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb46-388"><a href="#cb46-388" aria-hidden="true" tabindex="-1"></a>  \sum Y_i &amp;= \hat{\beta}_0 + \hat{\beta}_1 \sum X_i <span class="sc">\\</span></span>
<span id="cb46-389"><a href="#cb46-389" aria-hidden="true" tabindex="-1"></a>  \sum X_i Y_i &amp;= \hat{\beta}_0 \sum X_i + \hat{\beta}_1 \sum X_i^2</span>
<span id="cb46-390"><a href="#cb46-390" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb46-391"><a href="#cb46-391" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-392"><a href="#cb46-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-393"><a href="#cb46-393" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This leads to</span>
<span id="cb46-394"><a href="#cb46-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-395"><a href="#cb46-395" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-396"><a href="#cb46-396" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb46-397"><a href="#cb46-397" aria-hidden="true" tabindex="-1"></a>  \text{Intercept} \hspace{10pt} \hat{\beta}_0 \hspace{10pt} &amp;= \hspace{10pt} \frac{1}{n}\sum Y_i + \hat{\beta}_1 \frac{1}{n} \sum X_i \hspace{10pt} = \hspace{10pt} \bar{Y}- \hat{\beta}_1 \bar{X} <span class="sc">\\</span></span>
<span id="cb46-398"><a href="#cb46-398" aria-hidden="true" tabindex="-1"></a>  \text{Slope} \hspace{10pt} \hat{\beta_1} \hspace{10pt} &amp;= \hspace{10pt} \frac{\sum X_i Y_i -\frac{1}{n} \sum X_i Y_i}{\sum X_i^2 - \frac{1}{n}(\sum X_i)^2} \hspace{10pt} = \hspace{10pt} \frac{\sum(X_i - \bar{X})(Y_i - \bar{Y})}{\sum(X_i - \bar{X})^2} \hspace{10pt} = \hspace{10pt} \frac{S_{XY}}{S_{XX}}</span>
<span id="cb46-399"><a href="#cb46-399" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb46-400"><a href="#cb46-400" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-401"><a href="#cb46-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-402"><a href="#cb46-402" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note: We did not have to assume any distribution of the error term. These are the LSE estimators for any SLR model.</span>
<span id="cb46-403"><a href="#cb46-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-404"><a href="#cb46-404" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb46-405"><a href="#cb46-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-406"><a href="#cb46-406" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/slr-lse-derivation.png)</span>{width="100%"}</span>
<span id="cb46-407"><a href="#cb46-407" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-408"><a href="#cb46-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-409"><a href="#cb46-409" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Demo:</span>
<span id="cb46-410"><a href="#cb46-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-411"><a href="#cb46-411" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>First we can generate the sample data $(x_1, y_1), \ldots, (x_n, y_n)$.</span>
<span id="cb46-412"><a href="#cb46-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-415"><a href="#cb46-415" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-416"><a href="#cb46-416" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-417"><a href="#cb46-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-418"><a href="#cb46-418" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate sample regression dataset from population model</span></span>
<span id="cb46-419"><a href="#cb46-419" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; E ~ Uniform(a, b)</span></span>
<span id="cb46-420"><a href="#cb46-420" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y = B0 + B1X + E</span></span>
<span id="cb46-421"><a href="#cb46-421" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y | X ~ Uniform(B0 + B1*X - a, B0 + B1*X + b)</span></span>
<span id="cb46-422"><a href="#cb46-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-423"><a href="#cb46-423" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items</span></span>
<span id="cb46-424"><a href="#cb46-424" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sample size, population parameters and error distribution parameters</span></span>
<span id="cb46-425"><a href="#cb46-425" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb46-426"><a href="#cb46-426" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb46-427"><a href="#cb46-427" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb46-428"><a href="#cb46-428" aria-hidden="true" tabindex="-1"></a>min <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span></span>
<span id="cb46-429"><a href="#cb46-429" aria-hidden="true" tabindex="-1"></a>max <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb46-430"><a href="#cb46-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-431"><a href="#cb46-431" aria-hidden="true" tabindex="-1"></a><span class="co"># generate X values</span></span>
<span id="cb46-432"><a href="#cb46-432" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">15</span>)</span>
<span id="cb46-433"><a href="#cb46-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-434"><a href="#cb46-434" aria-hidden="true" tabindex="-1"></a><span class="co"># generate error terms</span></span>
<span id="cb46-435"><a href="#cb46-435" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; assumption for LSE is E(epsilon) = 0, so symmetric uniform about zero works</span></span>
<span id="cb46-436"><a href="#cb46-436" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> min, <span class="at">max =</span> max)</span>
<span id="cb46-437"><a href="#cb46-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-438"><a href="#cb46-438" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate y terms as function of x and error terms</span></span>
<span id="cb46-439"><a href="#cb46-439" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x <span class="sc">+</span> epsilon</span>
<span id="cb46-440"><a href="#cb46-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-441"><a href="#cb46-441" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-442"><a href="#cb46-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-445"><a href="#cb46-445" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-446"><a href="#cb46-446" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-447"><a href="#cb46-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-448"><a href="#cb46-448" aria-hidden="true" tabindex="-1"></a><span class="co"># display observed sample data</span></span>
<span id="cb46-449"><a href="#cb46-449" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(x, y) <span class="sc">%&gt;%</span> </span>
<span id="cb46-450"><a href="#cb46-450" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb46-451"><a href="#cb46-451" aria-hidden="true" tabindex="-1"></a>  <span class="fu">display_nice</span>(<span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"x"</span>, <span class="st">"y"</span>))</span>
<span id="cb46-452"><a href="#cb46-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-453"><a href="#cb46-453" aria-hidden="true" tabindex="-1"></a><span class="co"># plot sample data</span></span>
<span id="cb46-454"><a href="#cb46-454" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb46-455"><a href="#cb46-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-456"><a href="#cb46-456" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-457"><a href="#cb46-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-458"><a href="#cb46-458" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Then we can fit the model and visualize it on the scatter plot.</span>
<span id="cb46-459"><a href="#cb46-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-462"><a href="#cb46-462" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-463"><a href="#cb46-463" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-464"><a href="#cb46-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-465"><a href="#cb46-465" aria-hidden="true" tabindex="-1"></a><span class="co"># add regression line to plot</span></span>
<span id="cb46-466"><a href="#cb46-466" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb46-467"><a href="#cb46-467" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(<span class="at">formula =</span> y <span class="sc">~</span> x), <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb46-468"><a href="#cb46-468" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="dv">14</span>, <span class="at">y =</span> <span class="dv">22</span>, <span class="at">labels =</span> <span class="fu">bquote</span>(<span class="fu">hat</span>(Y) <span class="sc">*</span> <span class="st">" = "</span> <span class="sc">*</span> <span class="fu">hat</span>(beta)[<span class="dv">0</span>] <span class="sc">+</span> <span class="fu">hat</span>(beta)[<span class="dv">1</span>] <span class="sc">*</span> <span class="st">"X"</span>) , <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb46-469"><a href="#cb46-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-470"><a href="#cb46-470" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-471"><a href="#cb46-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-472"><a href="#cb46-472" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Finally we can get the estimates of $\hat{\beta}_0$ and $\hat{\beta}_1$.</span>
<span id="cb46-473"><a href="#cb46-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-474"><a href="#cb46-474" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb46-475"><a href="#cb46-475" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R Functions</span></span>
<span id="cb46-476"><a href="#cb46-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-479"><a href="#cb46-479" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-480"><a href="#cb46-480" aria-hidden="true" tabindex="-1"></a><span class="co"># fit SLR model</span></span>
<span id="cb46-481"><a href="#cb46-481" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; lm() calls lm.fit() behind the scenes --&gt; this performs a QR decomposition to fit the model, which is a more stable way to solve for LSE</span></span>
<span id="cb46-482"><a href="#cb46-482" aria-hidden="true" tabindex="-1"></a>mod_slr <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> y <span class="sc">~</span> x)</span>
<span id="cb46-483"><a href="#cb46-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-484"><a href="#cb46-484" aria-hidden="true" tabindex="-1"></a><span class="co"># display estimated coefficients</span></span>
<span id="cb46-485"><a href="#cb46-485" aria-hidden="true" tabindex="-1"></a>mod_slr<span class="sc">$</span>coefficients</span>
<span id="cb46-486"><a href="#cb46-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-487"><a href="#cb46-487" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-488"><a href="#cb46-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-491"><a href="#cb46-491" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-492"><a href="#cb46-492" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval = FALSE</span></span>
<span id="cb46-493"><a href="#cb46-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-494"><a href="#cb46-494" aria-hidden="true" tabindex="-1"></a><span class="co"># or can do</span></span>
<span id="cb46-495"><a href="#cb46-495" aria-hidden="true" tabindex="-1"></a><span class="fu">coefficients</span>(mod_slr)</span>
<span id="cb46-496"><a href="#cb46-496" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_slr) <span class="co"># alias for coefficients()</span></span>
<span id="cb46-497"><a href="#cb46-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-498"><a href="#cb46-498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-499"><a href="#cb46-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-500"><a href="#cb46-500" aria-hidden="true" tabindex="-1"></a>These are estimates of the population coefficients, so can compare above values to $\beta_0$ = <span class="in">`r beta_0`</span> and $\beta_1$ = <span class="in">`r beta_1`</span>.</span>
<span id="cb46-501"><a href="#cb46-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-502"><a href="#cb46-502" aria-hidden="true" tabindex="-1"></a>&lt;mark&gt;**Programming note → Beautiful sites ([(1)](https://genomicsclass.github.io/book/pages/qr_and_regression.html) and [(2)](https://machinelearningmastery.com/solve-linear-regression-using-linear-algebra/#:~:text=The%20QR%20decomposition%20is%20an,down%20into%20its%20constituent%20elements.&amp;text=Where%20A%20is%20the%20matrix,the%20linear%20least%20squares%20equation.)) explaining QR decomposition and how it relates to LSE; must go through and recreate at some point.**&lt;/mark&gt;</span>
<span id="cb46-503"><a href="#cb46-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-504"><a href="#cb46-504" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb46-505"><a href="#cb46-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-508"><a href="#cb46-508" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-509"><a href="#cb46-509" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate estimates for B0 and B1 using LSE formulas</span></span>
<span id="cb46-510"><a href="#cb46-510" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; b_1 = S_XY / S_XX</span></span>
<span id="cb46-511"><a href="#cb46-511" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; b_0 = Y-bar - b_1 X-bar</span></span>
<span id="cb46-512"><a href="#cb46-512" aria-hidden="true" tabindex="-1"></a>s_xy <span class="ot">&lt;-</span> <span class="fu">sum</span>((x <span class="sc">-</span> <span class="fu">mean</span>(x)) <span class="sc">*</span> (y <span class="sc">-</span> <span class="fu">mean</span>(y)))</span>
<span id="cb46-513"><a href="#cb46-513" aria-hidden="true" tabindex="-1"></a>s_xx <span class="ot">&lt;-</span> <span class="fu">sum</span>((x <span class="sc">-</span> <span class="fu">mean</span>(x))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb46-514"><a href="#cb46-514" aria-hidden="true" tabindex="-1"></a>b_1 <span class="ot">&lt;-</span> s_xy <span class="sc">/</span> s_xx</span>
<span id="cb46-515"><a href="#cb46-515" aria-hidden="true" tabindex="-1"></a>b_0 <span class="ot">&lt;-</span> <span class="fu">mean</span>(y) <span class="sc">-</span> b_1 <span class="sc">*</span> <span class="fu">mean</span>(x)</span>
<span id="cb46-516"><a href="#cb46-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-517"><a href="#cb46-517" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-518"><a href="#cb46-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-521"><a href="#cb46-521" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-522"><a href="#cb46-522" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-523"><a href="#cb46-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-524"><a href="#cb46-524" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to results from lm()</span></span>
<span id="cb46-525"><a href="#cb46-525" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">c</span>(b_0, b_1), mod_slr<span class="sc">$</span>coefficients)</span>
<span id="cb46-526"><a href="#cb46-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-527"><a href="#cb46-527" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-528"><a href="#cb46-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-529"><a href="#cb46-529" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Matrices</span></span>
<span id="cb46-530"><a href="#cb46-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-533"><a href="#cb46-533" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-534"><a href="#cb46-534" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate estimated betas using matrix regression formulas:</span></span>
<span id="cb46-535"><a href="#cb46-535" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; beta_hat = (X'X)^-1X'Y</span></span>
<span id="cb46-536"><a href="#cb46-536" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">intercept =</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">length</span>(x)), x)</span>
<span id="cb46-537"><a href="#cb46-537" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y</span>
<span id="cb46-538"><a href="#cb46-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-539"><a href="#cb46-539" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-540"><a href="#cb46-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-543"><a href="#cb46-543" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-544"><a href="#cb46-544" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-545"><a href="#cb46-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-546"><a href="#cb46-546" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to results from lm()</span></span>
<span id="cb46-547"><a href="#cb46-547" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(beta_hat, mod_slr<span class="sc">$</span>coefficients)</span>
<span id="cb46-548"><a href="#cb46-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-549"><a href="#cb46-549" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-550"><a href="#cb46-550" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-551"><a href="#cb46-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-552"><a href="#cb46-552" aria-hidden="true" tabindex="-1"></a>LSE for other models</span>
<span id="cb46-553"><a href="#cb46-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-554"><a href="#cb46-554" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Can also derive LSE estimators for other models using the same process.</span>
<span id="cb46-555"><a href="#cb46-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-556"><a href="#cb46-556" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Example 1</span>
<span id="cb46-557"><a href="#cb46-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-558"><a href="#cb46-558" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Regression through the origin: $Y = \beta X + \epsilon$.</span>
<span id="cb46-559"><a href="#cb46-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-560"><a href="#cb46-560" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb46-561"><a href="#cb46-561" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Setup and Derivation</span></span>
<span id="cb46-562"><a href="#cb46-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-565"><a href="#cb46-565" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-566"><a href="#cb46-566" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-567"><a href="#cb46-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-568"><a href="#cb46-568" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate sample regression through the origin dataset from population model</span></span>
<span id="cb46-569"><a href="#cb46-569" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; E ~ Uniform(a, b)</span></span>
<span id="cb46-570"><a href="#cb46-570" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y = BX + E</span></span>
<span id="cb46-571"><a href="#cb46-571" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y | X ~ Uniform(B*X + a, B*X + b)</span></span>
<span id="cb46-572"><a href="#cb46-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-573"><a href="#cb46-573" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items</span></span>
<span id="cb46-574"><a href="#cb46-574" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sample size, population parameters and error distribution parameters</span></span>
<span id="cb46-575"><a href="#cb46-575" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb46-576"><a href="#cb46-576" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb46-577"><a href="#cb46-577" aria-hidden="true" tabindex="-1"></a>min <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">3</span></span>
<span id="cb46-578"><a href="#cb46-578" aria-hidden="true" tabindex="-1"></a>max <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb46-579"><a href="#cb46-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-580"><a href="#cb46-580" aria-hidden="true" tabindex="-1"></a><span class="co"># generate X values</span></span>
<span id="cb46-581"><a href="#cb46-581" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">max =</span> <span class="dv">5</span>)</span>
<span id="cb46-582"><a href="#cb46-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-583"><a href="#cb46-583" aria-hidden="true" tabindex="-1"></a><span class="co"># Y | X ~ Uniform(min = BX + a, max = BX + b)</span></span>
<span id="cb46-584"><a href="#cb46-584" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> beta <span class="sc">*</span> x <span class="sc">+</span> min, <span class="at">max =</span> beta <span class="sc">*</span> x <span class="sc">+</span> max)</span>
<span id="cb46-585"><a href="#cb46-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-586"><a href="#cb46-586" aria-hidden="true" tabindex="-1"></a><span class="co"># plot sample data</span></span>
<span id="cb46-587"><a href="#cb46-587" aria-hidden="true" tabindex="-1"></a><span class="co"># add regression line to plot and reference line for origin</span></span>
<span id="cb46-588"><a href="#cb46-588" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb46-589"><a href="#cb46-589" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(<span class="at">formula =</span> y <span class="sc">~</span> x <span class="sc">-</span> <span class="dv">1</span>), <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb46-590"><a href="#cb46-590" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"lightgrey"</span>)</span>
<span id="cb46-591"><a href="#cb46-591" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"lightgrey"</span>)</span>
<span id="cb46-592"><a href="#cb46-592" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="dv">3</span>, <span class="at">y =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">labels =</span> <span class="fu">bquote</span>(<span class="fu">hat</span>(Y) <span class="sc">*</span> <span class="st">" = "</span> <span class="sc">*</span> <span class="fu">hat</span>(beta) <span class="sc">*</span> <span class="st">"X"</span>) , <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb46-593"><a href="#cb46-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-594"><a href="#cb46-594" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-595"><a href="#cb46-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-596"><a href="#cb46-596" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Derivation of estimator:</span>
<span id="cb46-597"><a href="#cb46-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-598"><a href="#cb46-598" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/slr-lse-derivation-origin.png)</span>{width="40%"}</span>
<span id="cb46-599"><a href="#cb46-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-600"><a href="#cb46-600" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R Functions</span></span>
<span id="cb46-601"><a href="#cb46-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-604"><a href="#cb46-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-605"><a href="#cb46-605" aria-hidden="true" tabindex="-1"></a><span class="co"># fit SLR model without intercept</span></span>
<span id="cb46-606"><a href="#cb46-606" aria-hidden="true" tabindex="-1"></a>mod_noint <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> y <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> x)</span>
<span id="cb46-607"><a href="#cb46-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-608"><a href="#cb46-608" aria-hidden="true" tabindex="-1"></a><span class="co"># display estimated coefficient</span></span>
<span id="cb46-609"><a href="#cb46-609" aria-hidden="true" tabindex="-1"></a><span class="fu">coefficients</span>(mod_noint)</span>
<span id="cb46-610"><a href="#cb46-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-611"><a href="#cb46-611" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-612"><a href="#cb46-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-613"><a href="#cb46-613" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb46-614"><a href="#cb46-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-617"><a href="#cb46-617" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-618"><a href="#cb46-618" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate estimate B using LSE formula</span></span>
<span id="cb46-619"><a href="#cb46-619" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">sum</span>(x <span class="sc">*</span> y) <span class="sc">/</span> <span class="fu">sum</span>(x<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb46-620"><a href="#cb46-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-621"><a href="#cb46-621" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-622"><a href="#cb46-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-625"><a href="#cb46-625" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-626"><a href="#cb46-626" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-627"><a href="#cb46-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-628"><a href="#cb46-628" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to results from lm()</span></span>
<span id="cb46-629"><a href="#cb46-629" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(b, <span class="fu">coefficients</span>(mod_noint))</span>
<span id="cb46-630"><a href="#cb46-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-631"><a href="#cb46-631" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-632"><a href="#cb46-632" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-633"><a href="#cb46-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-634"><a href="#cb46-634" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Example 2</span>
<span id="cb46-635"><a href="#cb46-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-636"><a href="#cb46-636" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Regression through the origin with squared predictor variable: $Y = \beta_1 X^2 + \epsilon$.</span>
<span id="cb46-637"><a href="#cb46-637" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-638"><a href="#cb46-638" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Sometimes a transformation can make deriving estimators easier. This way we can get the model in a familiar form and derive like usual (simpler). Then we just have to make the appropriate substitutions at the end in order to get the estimators for the original models.</span>
<span id="cb46-639"><a href="#cb46-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-640"><a href="#cb46-640" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>This strategy lessens the number of models we have to know how to derive (note this is just for deriving; no need to do it when fitting models because it's an extra middle step that doesn't change anything, leads to equivalent results).</span>
<span id="cb46-641"><a href="#cb46-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-642"><a href="#cb46-642" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb46-643"><a href="#cb46-643" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Setup and Derivation</span></span>
<span id="cb46-644"><a href="#cb46-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-647"><a href="#cb46-647" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-648"><a href="#cb46-648" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-649"><a href="#cb46-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-650"><a href="#cb46-650" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate sample regression through the origin with squared predictor dataset from population model</span></span>
<span id="cb46-651"><a href="#cb46-651" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; E ~ Uniform(a, b)</span></span>
<span id="cb46-652"><a href="#cb46-652" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y = BX + E</span></span>
<span id="cb46-653"><a href="#cb46-653" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y | X ~ Uniform(B*X^2 + a, B*X^2 + b)</span></span>
<span id="cb46-654"><a href="#cb46-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-655"><a href="#cb46-655" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items</span></span>
<span id="cb46-656"><a href="#cb46-656" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sample size, population parameters and error distribution parameters</span></span>
<span id="cb46-657"><a href="#cb46-657" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb46-658"><a href="#cb46-658" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb46-659"><a href="#cb46-659" aria-hidden="true" tabindex="-1"></a>min <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">3</span></span>
<span id="cb46-660"><a href="#cb46-660" aria-hidden="true" tabindex="-1"></a>max <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb46-661"><a href="#cb46-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-662"><a href="#cb46-662" aria-hidden="true" tabindex="-1"></a><span class="co"># generate X values</span></span>
<span id="cb46-663"><a href="#cb46-663" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">max =</span> <span class="dv">5</span>)</span>
<span id="cb46-664"><a href="#cb46-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-665"><a href="#cb46-665" aria-hidden="true" tabindex="-1"></a><span class="co"># Y | X ~ Uniform(min = BX^2 + a, max = BX^2 + b)</span></span>
<span id="cb46-666"><a href="#cb46-666" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> beta <span class="sc">*</span> x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> min, <span class="at">max =</span> beta <span class="sc">*</span> x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> max)</span>
<span id="cb46-667"><a href="#cb46-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-668"><a href="#cb46-668" aria-hidden="true" tabindex="-1"></a><span class="co"># plot sample data</span></span>
<span id="cb46-669"><a href="#cb46-669" aria-hidden="true" tabindex="-1"></a><span class="co"># add regression line to plot and reference line for origin</span></span>
<span id="cb46-670"><a href="#cb46-670" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb46-671"><a href="#cb46-671" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(<span class="at">formula =</span> y <span class="sc">~</span> x <span class="sc">-</span> <span class="dv">1</span>), <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb46-672"><a href="#cb46-672" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"lightgrey"</span>)</span>
<span id="cb46-673"><a href="#cb46-673" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"lightgrey"</span>)</span>
<span id="cb46-674"><a href="#cb46-674" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="dv">4</span>, <span class="at">y =</span> <span class="dv">15</span>, <span class="at">labels =</span> <span class="fu">bquote</span>(<span class="fu">hat</span>(Y) <span class="sc">*</span> <span class="st">" = "</span> <span class="sc">*</span> <span class="fu">hat</span>(beta) <span class="sc">*</span> X<span class="sc">^</span><span class="dv">2</span>) , <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb46-675"><a href="#cb46-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-676"><a href="#cb46-676" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-677"><a href="#cb46-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-678"><a href="#cb46-678" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Derivation of estimator:</span>
<span id="cb46-679"><a href="#cb46-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-680"><a href="#cb46-680" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/slr-lse-derivation-origin-squared.png)</span>{width="90%"}</span>
<span id="cb46-681"><a href="#cb46-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-682"><a href="#cb46-682" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R Functions</span></span>
<span id="cb46-683"><a href="#cb46-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-686"><a href="#cb46-686" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-687"><a href="#cb46-687" aria-hidden="true" tabindex="-1"></a><span class="co"># fit SLR model with no intercept and squared X</span></span>
<span id="cb46-688"><a href="#cb46-688" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; use asis function I() to treat `^` as an arithmetic operator and not a formula operator</span></span>
<span id="cb46-689"><a href="#cb46-689" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; save design matrix for later demo</span></span>
<span id="cb46-690"><a href="#cb46-690" aria-hidden="true" tabindex="-1"></a>mod_noint_squared <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> y <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> <span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>), <span class="at">x =</span> <span class="cn">TRUE</span>)</span>
<span id="cb46-691"><a href="#cb46-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-692"><a href="#cb46-692" aria-hidden="true" tabindex="-1"></a><span class="co"># display estimated coefficient</span></span>
<span id="cb46-693"><a href="#cb46-693" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_noint_squared)</span>
<span id="cb46-694"><a href="#cb46-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-695"><a href="#cb46-695" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-696"><a href="#cb46-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-697"><a href="#cb46-697" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb46-698"><a href="#cb46-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-701"><a href="#cb46-701" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-702"><a href="#cb46-702" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate estimates B using LSE formula</span></span>
<span id="cb46-703"><a href="#cb46-703" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">sum</span>(x<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> y) <span class="sc">/</span> <span class="fu">sum</span>(x<span class="sc">^</span><span class="dv">4</span>)</span>
<span id="cb46-704"><a href="#cb46-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-705"><a href="#cb46-705" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-706"><a href="#cb46-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-709"><a href="#cb46-709" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-710"><a href="#cb46-710" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-711"><a href="#cb46-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-712"><a href="#cb46-712" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to results from lm()</span></span>
<span id="cb46-713"><a href="#cb46-713" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(b, <span class="fu">coef</span>(mod_noint_squared))</span>
<span id="cb46-714"><a href="#cb46-714" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb46-715"><a href="#cb46-715" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-716"><a href="#cb46-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-719"><a href="#cb46-719" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-720"><a href="#cb46-720" aria-hidden="true" tabindex="-1"></a><span class="co"># demonstrating that transformed model way is equivalent</span></span>
<span id="cb46-721"><a href="#cb46-721" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; square predictor variable</span></span>
<span id="cb46-722"><a href="#cb46-722" aria-hidden="true" tabindex="-1"></a>x_star <span class="ot">&lt;-</span> x<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb46-723"><a href="#cb46-723" aria-hidden="true" tabindex="-1"></a>mod_transformed <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> y <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span>  x_star, <span class="at">x =</span> <span class="cn">TRUE</span>)</span>
<span id="cb46-724"><a href="#cb46-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-725"><a href="#cb46-725" aria-hidden="true" tabindex="-1"></a><span class="co"># compare design matrices of two models</span></span>
<span id="cb46-726"><a href="#cb46-726" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">head</span>(mod_noint_squared<span class="sc">$</span>x), <span class="fu">head</span>(mod_transformed<span class="sc">$</span>x))</span>
<span id="cb46-727"><a href="#cb46-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-728"><a href="#cb46-728" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate estimates B using LSE formula</span></span>
<span id="cb46-729"><a href="#cb46-729" aria-hidden="true" tabindex="-1"></a>b_star <span class="ot">&lt;-</span> <span class="fu">sum</span>(x_star <span class="sc">*</span> y) <span class="sc">/</span> <span class="fu">sum</span>(x_star<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb46-730"><a href="#cb46-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-731"><a href="#cb46-731" aria-hidden="true" tabindex="-1"></a><span class="co"># compare betas from usual method and transformed model way</span></span>
<span id="cb46-732"><a href="#cb46-732" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(b, b_star)</span>
<span id="cb46-733"><a href="#cb46-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-734"><a href="#cb46-734" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-735"><a href="#cb46-735" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-736"><a href="#cb46-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-737"><a href="#cb46-737" aria-hidden="true" tabindex="-1"></a>Properties of least squares estimators</span>
<span id="cb46-738"><a href="#cb46-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-739"><a href="#cb46-739" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Gauss-Markov theorem**: If the conditions of the SLR model hold (i.e. $Y_i= \beta_0 + \beta_1 X_i + \epsilon_i$, where $\epsilon_i$ have mean zero, variance $\sigma^2$ and are uncorrelated), then the LSE $\hat{\beta}_0$ and $\hat{\beta}_1$ are the **Best Linear Unbiased Estimators (BLUE)** (note that $\epsilon_i$ do not have to be normal).</span>
<span id="cb46-740"><a href="#cb46-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-741"><a href="#cb46-741" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>Linear estimators → Through lots of algebra (shown later), $\hat{\beta_0}$ and $\hat{\beta}_1$ can be written as be written as a linear combination of the $Y_i$: $\sum k_i Y_i$, where $k_i$ are constant. Thus they are linear estimators.</span>
<span id="cb46-742"><a href="#cb46-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-743"><a href="#cb46-743" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>Unbiased estimators → Their expected values are $\beta_0$ and $\beta_1$, respectively. So neither estimator tends to overestimate or underestimate systematically.</span>
<span id="cb46-744"><a href="#cb46-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-745"><a href="#cb46-745" aria-hidden="true" tabindex="-1"></a><span class="ss">    3.  </span>Best → More precise than *all other linear unbiased estimators of* $\beta_0$ and $\beta_1$ (smaller variance of the sampling distributions).</span>
<span id="cb46-746"><a href="#cb46-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-747"><a href="#cb46-747" aria-hidden="true" tabindex="-1"></a><span class="fu">### Point estimation of the mean response</span></span>
<span id="cb46-748"><a href="#cb46-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-749"><a href="#cb46-749" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For the population relationship $Y = \beta_0 + \beta_1 X + \epsilon$, we have the regression function $E(Y) = \beta_0 + \beta_1 X$ (because $E(\epsilon) = 0$). This is estimated with $\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X$.</span>
<span id="cb46-750"><a href="#cb46-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-751"><a href="#cb46-751" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Terms and what they represent:</span>
<span id="cb46-752"><a href="#cb46-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-753"><a href="#cb46-753" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$Y$ is a value of the response variable; the observed value.</span>
<span id="cb46-754"><a href="#cb46-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-755"><a href="#cb46-755" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$E(Y)$ the mean response. So it is the center of the probability distribution of $Y$ corresponding to the level $X$ of the predictor variable (so technically a conditional expected value $E(Y \mid X)$.</span>
<span id="cb46-756"><a href="#cb46-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-757"><a href="#cb46-757" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\hat{Y}$ is a point estimator of the mean response when the level of the predictor variable is $X$; the fitted value.</span>
<span id="cb46-758"><a href="#cb46-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-759"><a href="#cb46-759" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Application of Gauss-Markov theorem</span>
<span id="cb46-760"><a href="#cb46-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-761"><a href="#cb46-761" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\hat{Y}$ is the BLUE for $E(Y)$ with $V(\hat{Y}) = V(\epsilon) = \sigma^2$.</span>
<span id="cb46-762"><a href="#cb46-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-763"><a href="#cb46-763" aria-hidden="true" tabindex="-1"></a><span class="fu">### Residuals and model errors</span></span>
<span id="cb46-764"><a href="#cb46-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-765"><a href="#cb46-765" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Model error term $\epsilon_i = Y_i - E(Y_i) = Y_i - (\beta_0 + \beta_1 X_i)$ → Measures the difference between an observation and its expected value (unknown true regression line). It is unknown / unobservable.</span>
<span id="cb46-766"><a href="#cb46-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-767"><a href="#cb46-767" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Residual $\hat{\epsilon}_i = e_i = Y_i - \hat{Y}_i$ → This is a known, observable estimate of the unobservable model error. Measures the deviation of the observed value from the fitted regression function.</span>
<span id="cb46-768"><a href="#cb46-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-769"><a href="#cb46-769" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/residual.png)</span>{width="40%"}</span>
<span id="cb46-770"><a href="#cb46-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-771"><a href="#cb46-771" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Residuals are very useful for studying whether the given regression model is appropriate for the data.</span>
<span id="cb46-772"><a href="#cb46-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-773"><a href="#cb46-773" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - &lt;mark&gt; Independence &lt;/mark&gt; &amp;rarr;  Because of how are models are constructed   the sum of the residuals is necessarily zero, and thus the residuals are necessarily not independent. However, the model errors are independent (by assumption), and their is almost surely not zero (???? but we expect them to balance out, expected value equal to zero). --&gt;</span></span>
<span id="cb46-774"><a href="#cb46-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-775"><a href="#cb46-775" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Properties of fitted regression line: PAGE 23, gives 6 properties, could demonstrate if wanted, not sure why these are useful to know --&gt;</span></span>
<span id="cb46-776"><a href="#cb46-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-777"><a href="#cb46-777" aria-hidden="true" tabindex="-1"></a><span class="fu">## Estimation of error terms variance</span></span>
<span id="cb46-778"><a href="#cb46-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-779"><a href="#cb46-779" aria-hidden="true" tabindex="-1"></a>Need to estimate the variance $\sigma^2$ of the error terms $\epsilon_i$ in a regression model to get an indication of the variability of the probability distributions of $Y$. Also several inferences for models require an estimate of $\sigma^2$.</span>
<span id="cb46-780"><a href="#cb46-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-781"><a href="#cb46-781" aria-hidden="true" tabindex="-1"></a>Motivation</span>
<span id="cb46-782"><a href="#cb46-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-783"><a href="#cb46-783" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For a single population, the variance $\sigma^2$ is estimated by the sample variance $S^2$, which is an unbiased estimator. We find $S^2$ by taking the sum of the squared deviations of the observed value and the estimated mean (sum of squares) and then dividing it by the degrees of freedom $n - 1$ (one df is lost when estimating $\mu$; mean square) .</span>
<span id="cb46-784"><a href="#cb46-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-785"><a href="#cb46-785" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-786"><a href="#cb46-786" aria-hidden="true" tabindex="-1"></a>S^2 = \frac{\sum_{i = 1}^n (Y_i - \bar{Y})^2}{n - 1}</span>
<span id="cb46-787"><a href="#cb46-787" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-788"><a href="#cb46-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-789"><a href="#cb46-789" aria-hidden="true" tabindex="-1"></a>Regression model</span>
<span id="cb46-790"><a href="#cb46-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-791"><a href="#cb46-791" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Same logic as above, except we use the residuals as the deviations because each $Y_i$ comes from a different probability distribution with different $X$ (depends on the $X_i$ level).</span>
<span id="cb46-792"><a href="#cb46-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-793"><a href="#cb46-793" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-794"><a href="#cb46-794" aria-hidden="true" tabindex="-1"></a>\text{Error (residual) sum of squares} \hspace{10pt} SSE = \sum_{i = 1}^n (Y_i - \hat{Y_i})^2 = \sum_{i = 1}^n e_i^2</span>
<span id="cb46-795"><a href="#cb46-795" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-796"><a href="#cb46-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-797"><a href="#cb46-797" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Then divide by the $df = n - 2$ to the mean square (two dfs are lost when because $\beta_0$ and $\beta_1$ need to be estimated when getting the estimated means $\hat{Y_i}$).</span>
<span id="cb46-798"><a href="#cb46-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-799"><a href="#cb46-799" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-800"><a href="#cb46-800" aria-hidden="true" tabindex="-1"></a>\text{Error (residual) mean square} \hspace{10pt} S^2 = MSE = \frac{SSE}{n - 2} = \frac{\sum_{i = 1}^n (Y_i - \hat{Y_i})^2}{n - 2} = \frac{\sum_{i = 1}^n e_i^2}{n - 2}</span>
<span id="cb46-801"><a href="#cb46-801" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-802"><a href="#cb46-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-803"><a href="#cb46-803" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It will be shown later that $MSE$ is an unbiased estimator for $\sigma^2$ → $E(MSE) = \sigma^2$.</span>
<span id="cb46-804"><a href="#cb46-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-805"><a href="#cb46-805" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>An estimator of the standard deviation is simply $S = \sqrt{MSE}$.</span>
<span id="cb46-806"><a href="#cb46-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-807"><a href="#cb46-807" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb46-808"><a href="#cb46-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-809"><a href="#cb46-809" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb46-810"><a href="#cb46-810" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb46-811"><a href="#cb46-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-814"><a href="#cb46-814" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-815"><a href="#cb46-815" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate dataset (using uniform errors)</span></span>
<span id="cb46-816"><a href="#cb46-816" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items, generate X values, errors and y values</span></span>
<span id="cb46-817"><a href="#cb46-817" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>; beta_0 <span class="ot">&lt;-</span> <span class="dv">1</span>; beta_1 <span class="ot">&lt;-</span> <span class="dv">2</span>; min <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span>; max <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb46-818"><a href="#cb46-818" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">15</span>)</span>
<span id="cb46-819"><a href="#cb46-819" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> min, <span class="at">max =</span> max)</span>
<span id="cb46-820"><a href="#cb46-820" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x <span class="sc">+</span> epsilon</span>
<span id="cb46-821"><a href="#cb46-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-822"><a href="#cb46-822" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb46-823"><a href="#cb46-823" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb46-824"><a href="#cb46-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-825"><a href="#cb46-825" aria-hidden="true" tabindex="-1"></a><span class="co"># display model summary -&gt; looking for residual standard error = S = sqrt(MSE)</span></span>
<span id="cb46-826"><a href="#cb46-826" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; save to object to extract it</span></span>
<span id="cb46-827"><a href="#cb46-827" aria-hidden="true" tabindex="-1"></a>(summ <span class="ot">&lt;-</span> <span class="fu">summary</span>(mod))</span>
<span id="cb46-828"><a href="#cb46-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-829"><a href="#cb46-829" aria-hidden="true" tabindex="-1"></a><span class="co"># display S and MSE = S^2</span></span>
<span id="cb46-830"><a href="#cb46-830" aria-hidden="true" tabindex="-1"></a>summ<span class="sc">$</span>sigma</span>
<span id="cb46-831"><a href="#cb46-831" aria-hidden="true" tabindex="-1"></a>summ<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb46-832"><a href="#cb46-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-833"><a href="#cb46-833" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-834"><a href="#cb46-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-835"><a href="#cb46-835" aria-hidden="true" tabindex="-1"></a>These are estimates of population quantities for the error terms, and when simulating the data we assumed $\epsilon_i \sim \text{Uniform}\,(a, b) \Longrightarrow \sigma^2 = V(\epsilon_i) = \frac{(b - a)^2}{12}$. For $a$ = <span class="in">`r min`</span> and $b$ = <span class="in">`r max`</span>, $V(\epsilon_i)$ = <span class="in">`r round((max - min)^2 / 12, 3)`</span>.</span>
<span id="cb46-836"><a href="#cb46-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-837"><a href="#cb46-837" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb46-838"><a href="#cb46-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-841"><a href="#cb46-841" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-842"><a href="#cb46-842" aria-hidden="true" tabindex="-1"></a><span class="co"># SIDENOTE -&gt; showing multiple equivalent ways to do the same thing (just keep the last way)</span></span>
<span id="cb46-843"><a href="#cb46-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-844"><a href="#cb46-844" aria-hidden="true" tabindex="-1"></a><span class="co"># get fitted values using functions</span></span>
<span id="cb46-845"><a href="#cb46-845" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> mod<span class="sc">$</span>fitted.values</span>
<span id="cb46-846"><a href="#cb46-846" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> <span class="fu">fitted</span>(mod)</span>
<span id="cb46-847"><a href="#cb46-847" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> <span class="fu">fitted.values</span>(mod) <span class="co"># alias for fitted()</span></span>
<span id="cb46-848"><a href="#cb46-848" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod) <span class="co"># discussed more later</span></span>
<span id="cb46-849"><a href="#cb46-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-850"><a href="#cb46-850" aria-hidden="true" tabindex="-1"></a><span class="co"># extract residuals using functions (or some manual calculations)</span></span>
<span id="cb46-851"><a href="#cb46-851" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">residuals</span>(mod)</span>
<span id="cb46-852"><a href="#cb46-852" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod) <span class="co"># alias for residuals()</span></span>
<span id="cb46-853"><a href="#cb46-853" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> mod<span class="sc">$</span>residuals</span>
<span id="cb46-854"><a href="#cb46-854" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> y <span class="sc">-</span> y_hat</span>
<span id="cb46-855"><a href="#cb46-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-856"><a href="#cb46-856" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate SSE and df</span></span>
<span id="cb46-857"><a href="#cb46-857" aria-hidden="true" tabindex="-1"></a>sse <span class="ot">&lt;-</span> <span class="fu">sum</span>(e<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb46-858"><a href="#cb46-858" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> mod<span class="sc">$</span>df.residual <span class="co"># extract from model object</span></span>
<span id="cb46-859"><a href="#cb46-859" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">df.residual</span>(mod)</span>
<span id="cb46-860"><a href="#cb46-860" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> summ<span class="sc">$</span>df[<span class="dv">2</span>] <span class="co"># extract from model summary -&gt; error df is the second item (even if have MLR model)</span></span>
<span id="cb46-861"><a href="#cb46-861" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> n <span class="sc">-</span> <span class="dv">2</span> <span class="co"># for SLR (with intercept)</span></span>
<span id="cb46-862"><a href="#cb46-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-863"><a href="#cb46-863" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate MSE</span></span>
<span id="cb46-864"><a href="#cb46-864" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> sse <span class="sc">/</span> df</span>
<span id="cb46-865"><a href="#cb46-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-866"><a href="#cb46-866" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate residual standard deviation</span></span>
<span id="cb46-867"><a href="#cb46-867" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(mse)</span>
<span id="cb46-868"><a href="#cb46-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-869"><a href="#cb46-869" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to results from summary(lm())</span></span>
<span id="cb46-870"><a href="#cb46-870" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; s</span></span>
<span id="cb46-871"><a href="#cb46-871" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(summ<span class="sc">$</span>sigma, s)</span>
<span id="cb46-872"><a href="#cb46-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-873"><a href="#cb46-873" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; MSE</span></span>
<span id="cb46-874"><a href="#cb46-874" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(summ<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span>, mse)</span>
<span id="cb46-875"><a href="#cb46-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-876"><a href="#cb46-876" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; SSE = MSE * df</span></span>
<span id="cb46-877"><a href="#cb46-877" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(summ<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> summ<span class="sc">$</span>df[<span class="dv">2</span>], sse)</span>
<span id="cb46-878"><a href="#cb46-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-879"><a href="#cb46-879" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-880"><a href="#cb46-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-881"><a href="#cb46-881" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- alternate formula for sse = syy - beta1-hat sxy: from notes; not sure if needed --&gt;</span></span>
<span id="cb46-882"><a href="#cb46-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-883"><a href="#cb46-883" aria-hidden="true" tabindex="-1"></a><span class="fu">### Matrices</span></span>
<span id="cb46-884"><a href="#cb46-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-887"><a href="#cb46-887" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-888"><a href="#cb46-888" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate MSE using quadratic forms</span></span>
<span id="cb46-889"><a href="#cb46-889" aria-hidden="true" tabindex="-1"></a><span class="co"># SSE = Y'(I -H)Y</span></span>
<span id="cb46-890"><a href="#cb46-890" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">intercept =</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">length</span>(x)), x)</span>
<span id="cb46-891"><a href="#cb46-891" aria-hidden="true" tabindex="-1"></a>hat_matrix <span class="ot">&lt;-</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X)</span>
<span id="cb46-892"><a href="#cb46-892" aria-hidden="true" tabindex="-1"></a>sse <span class="ot">&lt;-</span> <span class="fu">t</span>(y) <span class="sc">%*%</span> (Matrix<span class="sc">::</span><span class="fu">diag</span>(<span class="at">x =</span> <span class="dv">1</span>, <span class="at">nrow =</span> <span class="fu">length</span>(y)) <span class="sc">-</span> hat_matrix) <span class="sc">%*%</span> y</span>
<span id="cb46-893"><a href="#cb46-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-894"><a href="#cb46-894" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; SSE = MSE * df</span></span>
<span id="cb46-895"><a href="#cb46-895" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(summ<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> summ<span class="sc">$</span>df[<span class="dv">2</span>], sse)</span>
<span id="cb46-896"><a href="#cb46-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-897"><a href="#cb46-897" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-898"><a href="#cb46-898" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-899"><a href="#cb46-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-900"><a href="#cb46-900" aria-hidden="true" tabindex="-1"></a><span class="fu">## Normal error regression model</span></span>
<span id="cb46-901"><a href="#cb46-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-902"><a href="#cb46-902" aria-hidden="true" tabindex="-1"></a>Least squares results</span>
<span id="cb46-903"><a href="#cb46-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-904"><a href="#cb46-904" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>No matter what may be the form of the distribution of the error terms $\epsilon_i$ (and thus of the $Y_i$), the LSE provides unbiased point estimators of $\beta_0$ and $\beta_1$, that have minimum variance among all unbiased linear estimators (BLUEs).</span>
<span id="cb46-905"><a href="#cb46-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-906"><a href="#cb46-906" aria-hidden="true" tabindex="-1"></a>Assumptions on error term distribution</span>
<span id="cb46-907"><a href="#cb46-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-908"><a href="#cb46-908" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>These assumptions on $\epsilon_i$ are needed to set up interval estimates and make tests.</span>
<span id="cb46-909"><a href="#cb46-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-910"><a href="#cb46-910" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The standard assumption is that the error terms are normally distributed. This greatly simplifies the theory of regression analysis and is justifiable in many real-world situations where regression analysis is applied.</span>
<span id="cb46-911"><a href="#cb46-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-912"><a href="#cb46-912" aria-hidden="true" tabindex="-1"></a>New regression model</span>
<span id="cb46-913"><a href="#cb46-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-914"><a href="#cb46-914" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-915"><a href="#cb46-915" aria-hidden="true" tabindex="-1"></a>Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \hspace{20pt} \text{where} \hspace{10pt} \epsilon_i \overset{iid}\sim \text{Normal}\,(0,\sigma^2)</span>
<span id="cb46-916"><a href="#cb46-916" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-917"><a href="#cb46-917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-918"><a href="#cb46-918" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This is the same regression model as before, just with specified error distribution now ($iid$ = independent and identically distributed).</span>
<span id="cb46-919"><a href="#cb46-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-920"><a href="#cb46-920" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Because this model assumes normal errors, the assumption of uncorrelatedness of the original (unspecified error) model now becomes an independence assumption ($\perp <span class="sc">\!\!\!</span> \perp\Longrightarrow \mathrm{Corr}(\epsilon_i,\epsilon_j) = 0$. So the outcome in anyone trial has no effect on the error term for any other trial (in terms of positive or negative, small or large).</span>
<span id="cb46-921"><a href="#cb46-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-922"><a href="#cb46-922" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This model means $Y_i \overset{\perp <span class="sc">\!\!\!</span> \perp}\sim \text{Normal}\,$ with $E(Y_i) = \beta_0 + \beta_1 X_i$ and $V(Y_i) = \sigma^2$.</span>
<span id="cb46-923"><a href="#cb46-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-924"><a href="#cb46-924" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/normal-error-model.png)</span>{width="50%"}</span>
<span id="cb46-925"><a href="#cb46-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-926"><a href="#cb46-926" aria-hidden="true" tabindex="-1"></a>Justification of the normality assumption.</span>
<span id="cb46-927"><a href="#cb46-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-928"><a href="#cb46-928" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Error terms frequently represent the effects of factors omitted from the model that affect the response to some extent and that vary at random without reference to the variable $X$.</span>
<span id="cb46-929"><a href="#cb46-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-930"><a href="#cb46-930" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>These random effects have a degree of mutual independence, the composite error term representing all these factors tends to normal as the number of factors becomes large (by the CLT).</span>
<span id="cb46-931"><a href="#cb46-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-932"><a href="#cb46-932" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Also, the estimation and testing procedures shown later are based on the $t$ distribution and are usually only sensitive to large departures from normality. So, unless the departures from normality are serious, particularly with respect to skewness, the actual confidence coefficients and risks of errors will be close to the levels for exact normality.</span>
<span id="cb46-933"><a href="#cb46-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-934"><a href="#cb46-934" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimation of paramters by method of maximum likelihood</span></span>
<span id="cb46-935"><a href="#cb46-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-936"><a href="#cb46-936" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb46-937"><a href="#cb46-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-938"><a href="#cb46-938" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The method of maximum likelihood chooses as estimates values of the parameters that are most consistent with the sample data. The measure of consistency is the product of densities and is called the **likelihood value** $L(\mu)$.</span>
<span id="cb46-939"><a href="#cb46-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-940"><a href="#cb46-940" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If the value of $\mu$ is consistent with the sample data $\Longrightarrow$ densities relatively large $\Longrightarrow$ large likelihood value. If not, both will be small.</span>
<span id="cb46-941"><a href="#cb46-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-942"><a href="#cb46-942" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/mle-example.png)</span>{width="70%"}</span>
<span id="cb46-943"><a href="#cb46-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-944"><a href="#cb46-944" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Just like the LSE, there are two ways to find MLEs: a systematic numerical search and by use of an analytical solution.</span>
<span id="cb46-945"><a href="#cb46-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-946"><a href="#cb46-946" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The product of the densities viewed as a function of the unknown parameters is called the **likelihood function**.</span>
<span id="cb46-947"><a href="#cb46-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-948"><a href="#cb46-948" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If the likelihood function is relatively peaked in the neighborhood of the maximum, then the MLE estimate is precise because values of $\mu$ not near the MLE are much less consistent with the data.</span>
<span id="cb46-949"><a href="#cb46-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-950"><a href="#cb46-950" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When it is relatively flat in a fairly wide region around the MLE, many values of the parameter are almost as consistent with the sample data as the MLE and therefore the MLE is relatively imprecise.</span>
<span id="cb46-951"><a href="#cb46-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-952"><a href="#cb46-952" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- SHOW PLOTS and stuff from MLE DEMO??? --&gt;</span></span>
<span id="cb46-953"><a href="#cb46-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-954"><a href="#cb46-954" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- find example of flat mle maybe --&gt;</span></span>
<span id="cb46-955"><a href="#cb46-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-956"><a href="#cb46-956" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- and where have to numerical maximize to get coefficients? functions for how to do this in R?? Is this where gradient descent comes into play?? --&gt;</span></span>
<span id="cb46-957"><a href="#cb46-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-958"><a href="#cb46-958" aria-hidden="true" tabindex="-1"></a>Steps to MLEs</span>
<span id="cb46-959"><a href="#cb46-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-960"><a href="#cb46-960" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>For multivariate parameter vector $\boldsymbol{\theta} = (\theta_1, \ldots, \theta_{k})$, write the likelihood function (i.e. joint density function) and the log-likelihood function</span>
<span id="cb46-961"><a href="#cb46-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-962"><a href="#cb46-962" aria-hidden="true" tabindex="-1"></a>    <span class="co">&lt;!-- !!! add more background about MLEs, like why optimize log... --&gt;</span></span>
<span id="cb46-963"><a href="#cb46-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-964"><a href="#cb46-964" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-965"><a href="#cb46-965" aria-hidden="true" tabindex="-1"></a>L(\boldsymbol{\theta} \mid \mathbf{y}) = \prod_{i = 1}^n f(\mathbf{y} \mid \boldsymbol{\theta}) \hspace{20pt} \rightarrow \hspace{20pt} \ell(\boldsymbol{\theta}) = \ln<span class="co">[</span><span class="ot">L(\boldsymbol{\theta} \mid \mathbf{y})</span><span class="co">]</span></span>
<span id="cb46-966"><a href="#cb46-966" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-967"><a href="#cb46-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-968"><a href="#cb46-968" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Optimize the log-likelihood function by taking the partial derivatives with respect to each parameters of interest $\theta_1, \ldots, \theta_{k}$.</span>
<span id="cb46-969"><a href="#cb46-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-970"><a href="#cb46-970" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Set to zero and solve for each parameter of interest.</span>
<span id="cb46-971"><a href="#cb46-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-972"><a href="#cb46-972" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-973"><a href="#cb46-973" aria-hidden="true" tabindex="-1"></a>\text{For } j = 1, \ldots, k \hspace{20pt} \ell'(\boldsymbol{\theta}) = \frac{\partial}{\partial \theta_j} \ell(\boldsymbol{\theta}) = 0 \hspace{20pt} \rightarrow \hspace{20pt} \hat{\boldsymbol{\theta}} = (\hat{\theta}_1, \ldots, \hat{\theta}_{k}) = \text{potential MLE}</span>
<span id="cb46-974"><a href="#cb46-974" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-975"><a href="#cb46-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-976"><a href="#cb46-976" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Verify that the global maximum of the log-likelihood function occurs at $\boldsymbol{\theta} = \hat{\boldsymbol{\theta}}$.</span>
<span id="cb46-977"><a href="#cb46-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-978"><a href="#cb46-978" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Find the second derivative of the log-likelihood function, then plug in $\hat{\boldsymbol{\theta}}$ and see if less than zero.</span>
<span id="cb46-979"><a href="#cb46-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-980"><a href="#cb46-980" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Hessian matrix stuff --&gt;</span></span>
<span id="cb46-981"><a href="#cb46-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-982"><a href="#cb46-982" aria-hidden="true" tabindex="-1"></a>MLEs for normal error regression model</span>
<span id="cb46-983"><a href="#cb46-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-984"><a href="#cb46-984" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Generally</span>
<span id="cb46-985"><a href="#cb46-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-986"><a href="#cb46-986" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb46-987"><a href="#cb46-987" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb46-988"><a href="#cb46-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-989"><a href="#cb46-989" aria-hidden="true" tabindex="-1"></a>| Parameter  | MLE                                                                 |</span>
<span id="cb46-990"><a href="#cb46-990" aria-hidden="true" tabindex="-1"></a>|:--------------|:--------------------------------------------------------|</span>
<span id="cb46-991"><a href="#cb46-991" aria-hidden="true" tabindex="-1"></a>| $\beta_0$  | $\hat{\beta}_0 \hspace{10pt}$ Same as LSE                           |</span>
<span id="cb46-992"><a href="#cb46-992" aria-hidden="true" tabindex="-1"></a>| $\beta_1$  | $\hat{\beta}_1 \hspace{10pt}$ Same as LSE                           |</span>
<span id="cb46-993"><a href="#cb46-993" aria-hidden="true" tabindex="-1"></a>| $\sigma^2$ | $\displaystyle \hat{\sigma}^2 = \frac{\sum (Y_i - \hat{Y_i})^2}{n}$ |</span>
<span id="cb46-994"><a href="#cb46-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-995"><a href="#cb46-995" aria-hidden="true" tabindex="-1"></a>Notes</span>
<span id="cb46-996"><a href="#cb46-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-997"><a href="#cb46-997" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Properties of estimators</span>
<span id="cb46-998"><a href="#cb46-998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-999"><a href="#cb46-999" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Since MLEs for $\hat{\beta}_0$ and $\hat{\beta}_1$ are the same as the LSE estimators, they have the same properties: BLUE (unbiased and minimum variance in class of unbiased linear estimators).</span>
<span id="cb46-1000"><a href="#cb46-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1001"><a href="#cb46-1001" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>And because they are MLEs, we can also say they are: consistent ($\hat{\beta}_i \overset{p}\rightarrow \beta_i$, converge in probability to their respective parameters); sufficient (captures all of the information about $\beta_i$ contained in the sample); minimum variance in class of unbiased estimators (linear or otherwise).</span>
<span id="cb46-1002"><a href="#cb46-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1003"><a href="#cb46-1003" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- better explanation of sufficiency; state theorem why best variance for all unbiased estimators --&gt;</span></span>
<span id="cb46-1004"><a href="#cb46-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1005"><a href="#cb46-1005" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>MLE $\hat{\sigma}^2$ and MSE</span>
<span id="cb46-1006"><a href="#cb46-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1007"><a href="#cb46-1007" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Relationship $S^2 = MSE = \frac{n}{n - 2} \hat{\sigma}^2 \hspace{20pt} \Longleftrightarrow \hspace{20pt} \hat{\sigma}^2 = \frac{n - 2}{n} MSE$. However, for large $n$, the difference is small.</span>
<span id="cb46-1008"><a href="#cb46-1008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1009"><a href="#cb46-1009" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>MLE $\hat{\sigma}^2$ is biased → $E(\hat{\sigma}^2) = \frac{n - 2}{n} \sigma^2$, which is an underestimation of $\sigma^2$. Because of this, MSE is generally used because it is unbiased. However, $\hat{\sigma}^2$ is asymptotically unbiased (as $n \rightarrow \infty$) and has a smaller variance than MSE, which may be preferred in some scenarios (tradeoff between bias and precision).</span>
<span id="cb46-1010"><a href="#cb46-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1011"><a href="#cb46-1011" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Generally MLE gives the same results as LSE.</span>
<span id="cb46-1012"><a href="#cb46-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1013"><a href="#cb46-1013" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- investigate this, when, why? when is one better? !!!! what about when not normal??--&gt;</span></span>
<span id="cb46-1014"><a href="#cb46-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1015"><a href="#cb46-1015" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb46-1016"><a href="#cb46-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1017"><a href="#cb46-1017" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/placeholder.png)</span>{width="50%"}</span>
<span id="cb46-1018"><a href="#cb46-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1019"><a href="#cb46-1019" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Can also derive MLEs for transformed models using the same strategy as with LSE.</span>
<span id="cb46-1020"><a href="#cb46-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1021"><a href="#cb46-1021" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Example: Suppose we have $\ln(Y_i) = \beta_0 + \beta_1 X_i + \epsilon_i$. We can transform $Y_i^* = \beta_0^* + \beta_1^* X_i + \epsilon_i$, derive like usual, then substitute at end to get untransformed estimators.</span>
<span id="cb46-1022"><a href="#cb46-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1023"><a href="#cb46-1023" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- demo calculating mle sigma2 in r based on residuals and compare to mse --&gt;</span></span>
<span id="cb46-1024"><a href="#cb46-1024" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>