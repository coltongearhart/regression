<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.517">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Regression - 7&nbsp; Regression models for quantitative and qualitative predictors</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./notes-multiple-regression-2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part2-mlr.html">Multiple linear regression</a></li><li class="breadcrumb-item"><a href="./notes-reg-models-quan-and-qual.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Regression models for quanititative and qualitative predictors</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><header id="title-block-header" class="quarto-title-block default page-columns page-full"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part2-mlr.html">Multiple linear regression</a></li><li class="breadcrumb-item"><a href="./notes-reg-models-quan-and-qual.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Regression models for quanititative and qualitative predictors</span></a></li></ol></nav><div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">
<span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Regression models for quantitative and qualitative predictors</span>
</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Regression</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part1-slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple linear regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-diagnostics-and-remedial-measures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Diagnostics and remedial measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-matrix-slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Matrix approach to SLR</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part2-mlr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple linear regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-multiple-regression-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Multiple regression 1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-multiple-regression-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Multiple regression 2</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-reg-models-quan-and-qual.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Regression models for quanititative and qualitative predictors</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#polynomial-regression-models" id="toc-polynomial-regression-models" class="nav-link active" data-scroll-target="#polynomial-regression-models"><span class="header-section-number">7.1</span> Polynomial regression models</a>
  <ul class="collapse">
<li><a href="#uses-of-polynomial-models" id="toc-uses-of-polynomial-models" class="nav-link" data-scroll-target="#uses-of-polynomial-models"><span class="header-section-number">7.1.1</span> Uses of polynomial models</a></li>
  <li><a href="#one-predictor-variable-second-order" id="toc-one-predictor-variable-second-order" class="nav-link" data-scroll-target="#one-predictor-variable-second-order"><span class="header-section-number">7.1.2</span> One predictor variable – Second order</a></li>
  <li><a href="#one-predictor-variable-higher-orders" id="toc-one-predictor-variable-higher-orders" class="nav-link" data-scroll-target="#one-predictor-variable-higher-orders"><span class="header-section-number">7.1.3</span> One predictor variable – Higher orders</a></li>
  <li><a href="#two-or-more-predictor-variables-second-order" id="toc-two-or-more-predictor-variables-second-order" class="nav-link" data-scroll-target="#two-or-more-predictor-variables-second-order"><span class="header-section-number">7.1.4</span> Two or more predictor variables – Second order</a></li>
  <li><a href="#implementation-of-polynomial-regression-models" id="toc-implementation-of-polynomial-regression-models" class="nav-link" data-scroll-target="#implementation-of-polynomial-regression-models"><span class="header-section-number">7.1.5</span> Implementation of polynomial regression models</a></li>
  </ul>
</li>
  <li>
<a href="#interaction-regression-models" id="toc-interaction-regression-models" class="nav-link" data-scroll-target="#interaction-regression-models"><span class="header-section-number">7.2</span> Interaction regression models</a>
  <ul class="collapse">
<li><a href="#interaction-effects" id="toc-interaction-effects" class="nav-link" data-scroll-target="#interaction-effects"><span class="header-section-number">7.2.1</span> Interaction effects</a></li>
  <li><a href="#interpretation-of-interaction-regression-models-with-linear-effects" id="toc-interpretation-of-interaction-regression-models-with-linear-effects" class="nav-link" data-scroll-target="#interpretation-of-interaction-regression-models-with-linear-effects"><span class="header-section-number">7.2.2</span> Interpretation of interaction regression models with linear effects</a></li>
  <li><a href="#implementation-of-interaction-effects" id="toc-implementation-of-interaction-effects" class="nav-link" data-scroll-target="#implementation-of-interaction-effects"><span class="header-section-number">7.2.3</span> Implementation of interaction effects</a></li>
  <li><a href="#demo" id="toc-demo" class="nav-link" data-scroll-target="#demo"><span class="header-section-number">7.2.4</span> Demo</a></li>
  </ul>
</li>
  <li>
<a href="#qualitative-predictors" id="toc-qualitative-predictors" class="nav-link" data-scroll-target="#qualitative-predictors"><span class="header-section-number">7.3</span> Qualitative predictors</a>
  <ul class="collapse">
<li><a href="#implementation-of-qualitative-predictors" id="toc-implementation-of-qualitative-predictors" class="nav-link" data-scroll-target="#implementation-of-qualitative-predictors"><span class="header-section-number">7.3.1</span> Implementation of qualitative predictors</a></li>
  <li><a href="#interpretation-of-regression-coefficients" id="toc-interpretation-of-regression-coefficients" class="nav-link" data-scroll-target="#interpretation-of-regression-coefficients"><span class="header-section-number">7.3.2</span> Interpretation of regression coefficients</a></li>
  <li><a href="#modeling-interactions-between-quantitative-and-qualitative-predictors" id="toc-modeling-interactions-between-quantitative-and-qualitative-predictors" class="nav-link" data-scroll-target="#modeling-interactions-between-quantitative-and-qualitative-predictors"><span class="header-section-number">7.3.3</span> Modeling interactions between quantitative and qualitative predictors</a></li>
  <li><a href="#sec-misc-topics-quals" id="toc-sec-misc-topics-quals" class="nav-link" data-scroll-target="#sec-misc-topics-quals"><span class="header-section-number">7.3.4</span> Miscellaneous topics with qualitative predictors</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content"><!-- % define LaTeX macros (/shortcuts) --><!-- % define vector (without parentheses, so when writing out in like a definition) of the form X_1, ..., X_n, where X and n are variable. NOTE: to call use $\vecn{X}{n}$ --><!-- % shortcut for ~ 'Named dist ' in normal font with space before parameters would go --><!-- % (followsp is short for 'follow special') shortcut that can be used for iid or ind ~ 'Named dist ' in normal font with space before parameters would go --><!-- % define independence symbol (it basically makes two orthogonal symbols very close to each other. The number of \! controls the space between each of the orthogonal symbols) --><!-- % shortcut for Cov(X,Y) with formatting for Cov --><!-- % shortcut for Corr(X,Y) with formatting for Corr --><!-- % shortcut for non-italic e in math mode --><!-- % shortcut for matrix notation --><!-- % shortcut for null hypothesis formatted nicely --><!-- % shortcut for alternative hypothesis formatted nicely --><section id="polynomial-regression-models" class="level2" data-number="7.1"><h2 data-number="7.1" class="anchored" data-anchor-id="polynomial-regression-models">
<span class="header-section-number">7.1</span> Polynomial regression models</h2>
<p>We first consider polynomial regression models for quantitative predictor variables. They are among the most frequently used curvilinear response models in practice because they are handled easily as a special case of the general linear regression model (<span class="citation" data-cites="gen-lin-mod">@gen-lin-mod</span>).</p>
<p>Next, we discuss several commonly used polynomial regression models.</p>
<p>Then we discuss some of the major issues encountered with polynomial regression models.</p>
<section id="uses-of-polynomial-models" class="level3" data-number="7.1.1"><h3 data-number="7.1.1" class="anchored" data-anchor-id="uses-of-polynomial-models">
<span class="header-section-number">7.1.1</span> Uses of polynomial models</h3>
<p>Polynomial regression models have two basic types of uses:</p>
<ol type="1">
<li><p>When the true curvilinear response function is indeed a polynomial function.</p></li>
<li><p>When the true curvilinear response function is unknown (or complex) but a polynomial function is a good approximation to the true function.</p></li>
</ol>
<p>The second type of use, where the polynomial function is employed as an approximation when the shape of the true curvilinear response function is unknown, is very common. It may be viewed as a nonparametric approach to obtaining information about the shape of the response function.</p>
<p>A main danger in using polynomial regression models is that extrapolations may be hazardous with these models, especially those with higher-order terms. Polynomial regression models may provide good fits for the data at hand, but may turn in unexpected directions when extrapolated beyond the range of the data.</p>
</section><section id="one-predictor-variable-second-order" class="level3" data-number="7.1.2"><h3 data-number="7.1.2" class="anchored" data-anchor-id="one-predictor-variable-second-order">
<span class="header-section-number">7.1.2</span> One predictor variable – Second order</h3>
<p>Polynomial regression models may contain one, two, or more than two predictor variables. Further, each predictor variable may be present in various powers. We begin with the simplest case: one predictor variable with second order.</p>
<p><span class="math display">\[Y_i \hspace{10pt} = \hspace{10pt} \beta_0 + \beta_1 x_i + \beta_2 x_i^2 \hspace{10pt} = \hspace{10pt} \beta_0 + \beta_1 x_i + \beta_{11} x_i^2 + \epsilon_i\]</span> where <span class="math inline">\(x_i = X_i - \bar{X}\)</span>. This model has a <em>quadratic response function</em> (a parabola):</p>
<p><span class="math display">\[E(Y_i) = \beta_0 + \beta_1 x + \beta_{11} x^2 \]</span></p>
<p><img src="files/images/quadratic-response-functions.png" class="img-fluid" style="width:50.0%"></p>
<p>Notes</p>
<ul>
<li>
<p>The predictor variable is centered, i.e.&nbsp;expressed as a deviation around its mean <span class="math inline">\(\bar{X}\)</span>, and that the <span class="math inline">\(i\)</span>th centered observation is denoted by <span class="math inline">\(x_i\)</span>.</p>
<ul>
<li><p>The reason for using a centered predictor variable in the polynomial regression model is that <span class="math inline">\(X\)</span> and <span class="math inline">\(X^2\)</span> often will be highly correlated. Centering the predictor variable often reduces the multicollinearity substantially and tends to avoid computational difficulties.</p></li>
<li><p>An alternative to using centered variables in polynomial regression is to use <em>orthogonal polynomials</em>. This is what R uses in <code><a href="https://rdrr.io/r/stats/poly.html">poly()</a></code>.</p></li>
</ul>
</li>
<li><p>Can use different subscripts on the <span class="math inline">\(\beta\)</span>s so they match up with the power of the corresponding <span class="math inline">\(x\)</span> term better.</p></li>
<li><p>The danger of extrapolating a polynomial response function is illustrated by the response functions in the image above. If this function is extrapolated beyond <span class="math inline">\(x = 2\)</span>, it actually turns downward, might not be appropriate in a given case.</p></li>
</ul>
<p>Orthogonal polynomials demo</p>
</section><section id="one-predictor-variable-higher-orders" class="level3" data-number="7.1.3"><h3 data-number="7.1.3" class="anchored" data-anchor-id="one-predictor-variable-higher-orders">
<span class="header-section-number">7.1.3</span> One predictor variable – Higher orders</h3>
<p>The previous model can easily be extended to higher orders. For example, here is a third order model:</p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 x_i + \beta_{11} x_i^2 + \beta_{111} x_i^3 + \epsilon_i\]</span></p>
<p><img src="files/images/cubic-response-functions.png" class="img-fluid" style="width:50.0%"></p>
<p>Polynomial models with the predictor variable present in higher powers than the third should be employed with special caution.</p>
<ul>
<li><p>The interpretation of the coefficients becomes difficult for such models, and the models may be highly erratic for interpolations and even small extrapolations.</p></li>
<li><p>Note that a polynomial model of sufficiently high order can always be found to fit data containing no repeat observations perfectly. For instance, the fitted polynomial regression function for one predictor variable of order <span class="math inline">\(n - 1\)</span> will pass through all <span class="math inline">\(n\)</span> observed <span class="math inline">\(Y\)</span> values.</p></li>
</ul>
<p>Overfitting demo</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># generate data</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">num_x</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">num_x</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">10</span><span class="op">)</span><span class="op">}</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">%&lt;&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">n</span><span class="op">)</span>, <span class="va">.</span><span class="op">)</span></span>
<span><span class="va">betas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="va">num_x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># combine data</span></span>
<span><span class="va">data_sample</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">Y</span>, <span class="va">X</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">data.frame</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data_sample</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Y"</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">num_x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit highest order model</span></span>
<span><span class="co"># -&gt; note perfect fit</span></span>
<span><span class="va">mod_overfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">X1</span>, degree <span class="op">=</span> <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>, <span class="va">data_sample</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">mod_overfit</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 5
   term                      estimate std.error statistic p.value
   &lt;chr&gt;                        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
 1 (Intercept)                  9.87        NaN       NaN     NaN
 2 poly(X1, degree = n - 1)1   19.1         NaN       NaN     NaN
 3 poly(X1, degree = n - 1)2   -2.00        NaN       NaN     NaN
 4 poly(X1, degree = n - 1)3    9.07        NaN       NaN     NaN
 5 poly(X1, degree = n - 1)4   -6.83        NaN       NaN     NaN
 6 poly(X1, degree = n - 1)5   -4.14        NaN       NaN     NaN
 7 poly(X1, degree = n - 1)6   -2.22        NaN       NaN     NaN
 8 poly(X1, degree = n - 1)7   -0.428       NaN       NaN     NaN
 9 poly(X1, degree = n - 1)8   -0.383       NaN       NaN     NaN
10 poly(X1, degree = n - 1)9    0.465       NaN       NaN     NaN</code></pre>
</div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">glance</span><span class="op">(</span><span class="va">mod_overfit</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 12
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1         1           NaN   NaN       NaN     NaN     9    Inf  -Inf  -Inf
# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
</div>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot response function</span></span>
<span><span class="co"># -&gt; add fitted values to dataset and extract them to plot (have to sort first)</span></span>
<span><span class="va">data_sample</span> <span class="op">%$%</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">X1</span>, <span class="va">Y</span><span class="op">)</span></span>
<span><span class="fu">augment</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mod_overfit</span>, data <span class="op">=</span> <span class="va">data_sample</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">X1</span><span class="op">)</span> <span class="op">%$%</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X1</span>, y <span class="op">=</span> <span class="va">.fitted</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-reg-models-quan-and-qual_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
</section><section id="two-or-more-predictor-variables-second-order" class="level3" data-number="7.1.4"><h3 data-number="7.1.4" class="anchored" data-anchor-id="two-or-more-predictor-variables-second-order">
<span class="header-section-number">7.1.4</span> Two or more predictor variables – Second order</h3>
<p>Again, can extend the previous models to now include a second predictor variable and beyond (now including cross terms (interaction terms), still considered second order). For example, here is a second order model with two predictor variables:</p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_{11} x_{i1}^2 + \beta_{22} x_{i2}^2 + \beta_{12} x_{i1} x_{i2} + \epsilon_i\]</span></p>
<p>where <span class="math inline">\(x_{i1} = X_{i1} - \bar{X}_1\)</span> and <span class="math inline">\(x_{i2} = X_{i2} - \bar{X}_2\)</span>. This model has a <em>conic response function</em>:</p>
<p><span class="math display">\[E(Y_i) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_{11} x_1^2 + \beta_{22} x_2^2 + \beta_{12} x_1 x_2 \]</span> <img src="files/images/conic-response-function.png" class="img-fluid" style="width:50.0%"></p>
</section><section id="implementation-of-polynomial-regression-models" class="level3" data-number="7.1.5"><h3 data-number="7.1.5" class="anchored" data-anchor-id="implementation-of-polynomial-regression-models">
<span class="header-section-number">7.1.5</span> Implementation of polynomial regression models</h3>
<p>Fitting of polynomial models</p>
<ul>
<li>Fitting of polynomial regression models presents no new problems since they are special cases of the usual general linear regression model.</li>
</ul>
<p>Hiearchical approach to fitting</p>
<ul>
<li><p>When using a polynomial regression model as an approximation to the true regression function, statisticians will often fit a second-order or third-order model and then explore whether a lower-order model is adequate with partial <span class="math inline">\(F\)</span> tests.</p></li>
<li>
<p>With the hierarchical approach, if a polynomial term of a given order is retained, then all related terms of lower order are also retained in the model.</p>
<ul>
<li><p>Thus, one would not drop the quadratic term of a predictor variable but retain the cubic term in the model.</p></li>
<li><p>Since the quadratic term is of lower order, it is viewed as providing more basic information about the shape of the response function; the cubic term is of higher order and is viewed as providing refinements in the specification of the shape of the response function.</p></li>
</ul>
</li>
</ul>
<p>Regression function in terms of <span class="math inline">\(X\)</span></p>
<ul>
<li><p>After a polynomial regression model has been developed, we often wish to express the final model in terms of the original variables rather than keeping it in terms of the centered variables. This can be done readily (not showing because not Rs implementation).</p></li>
<li><p>The fitted values and residuals for the regression function in terms of <span class="math inline">\(X\)</span> are exactly the SAME as for the regression function in terms of the centered values <span class="math inline">\(x\)</span>.</p></li>
<li><p>The estimated standard deviation however do not translate. They need to be found using alternate methods.</p></li>
</ul>
<!-- HOW to interpret orthogonal polynomial results --></section></section><section id="interaction-regression-models" class="level2" data-number="7.2"><h2 data-number="7.2" class="anchored" data-anchor-id="interaction-regression-models">
<span class="header-section-number">7.2</span> Interaction regression models</h2>
<section id="interaction-effects" class="level3" data-number="7.2.1"><h3 data-number="7.2.1" class="anchored" data-anchor-id="interaction-effects">
<span class="header-section-number">7.2.1</span> Interaction effects</h3>
<p><img src="files/images/interaction-effects-content.png" class="img-fluid" style="width:80.0%"></p>
</section><section id="interpretation-of-interaction-regression-models-with-linear-effects" class="level3" data-number="7.2.2"><h3 data-number="7.2.2" class="anchored" data-anchor-id="interpretation-of-interaction-regression-models-with-linear-effects">
<span class="header-section-number">7.2.2</span> Interpretation of interaction regression models with linear effects</h3>
<p>Interpretation of regression coefficients</p>
<ul>
<li>The regression model for two quantitative predictor variables with linear effects on <span class="math inline">\(Y\)</span> and interacting effects of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> on <span class="math inline">\(Y\)</span> represented by a cross-product term is as follows:</li>
</ul>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \beta_3 X_{i1} X_{i2} + \epsilon_i\]</span> - The meaning of the regression coefficients <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> here is not the same as that given earlier because of the interaction term <span class="math inline">\(\beta_3 X_{i1} X_{i2}\)</span>. <span class="math inline">\(\beta_1\)</span> no longer represent mean change in <span class="math inline">\(Y\)</span> for a one unit increase in <span class="math inline">\(X_1\)</span> when all other predictors are held constant at any given level.</p>
<ul>
<li>It can be easily shown that the change in the mean response with a unit increase in <span class="math inline">\(X_1\)</span> when <span class="math inline">\(X_2\)</span> is held constant is</li>
</ul>
<p><span class="math display">\[\beta_1 + \beta_3 X_2\]</span></p>
<ul>
<li>Similarly the change in the mean response with a unit increase in <span class="math inline">\(X_2\)</span> when <span class="math inline">\(X_1\)</span> is held constant is</li>
</ul>
<p><span class="math display">\[\beta_2 + \beta_3 X_1\]</span> - Thus, in the regression model above, both the effect of <span class="math inline">\(X_1\)</span> for given level of <span class="math inline">\(X_2\)</span> and the effect of <span class="math inline">\(X_2\)</span> for given level of <span class="math inline">\(X_1\)</span> depend on the level of the other predictor variable.</p>
<ul>
<li>
<p>Below are <em>conditional effects plots</em> because they show the effects of <span class="math inline">\(X_1\)</span> on the mean response conditional on different levels of the other predictor variable.</p>
<ul>
<li><p>For additive models, the effect of <span class="math inline">\(X_1\)</span> is the same for both levels of <span class="math inline">\(X_2\)</span> (same slope) (i.e.&nbsp;<span class="math inline">\(Y\)</span> increases by the same amount when <span class="math inline">\(X_1\)</span> varies regardless of the level of <span class="math inline">\(X_2\)</span>.</p></li>
<li><p>For the reinforcement interaction, the effect of <span class="math inline">\(X_1\)</span> becomes stronger at hifher levels of <span class="math inline">\(X_2\)</span>. This occurs if both the linear terms and the interaction terms have the same sign.</p></li>
<li><p>In the inteference plot, the effect of <span class="math inline">\(X_1\)</span> is lessoned at higher levels of <span class="math inline">\(X_2\)</span> because the linear terms and the interaction terms have opposing signs.</p></li>
</ul>
</li>
</ul>
<p><img src="files/images/interaction-effects-plots.png" class="img-fluid" style="width:80.0%"></p>
<p>See <a href="https://cran.r-project.org/web/packages/interplot/vignettes/interplot-vignette.html">interplot-vignette</a> for explanations on interaction plots in R (they are a bit different than above).</p>
</section><section id="implementation-of-interaction-effects" class="level3" data-number="7.2.3"><h3 data-number="7.2.3" class="anchored" data-anchor-id="implementation-of-interaction-effects">
<span class="header-section-number">7.2.3</span> Implementation of interaction effects</h3>
<ul>
<li>
<p>When interaction terms area dded to a regression model,high multicollinearities may exist between some of the predictor variables and spme of the interaction terms, as well as among some of the interaction terms.</p>
<ul>
<li>A partial remedy to improve computational accuracy is to center the predictor variables; i.e.&nbsp;<span class="math inline">\(x_{ik} = X_{ik} - \bar{X}_k\)</span>
</li>
</ul>
</li>
<li>
<p>When the number of predictor variables in the regression model is large, the potential number of interaction terms can become very large.</p>
<ul>
<li>For example, if eight predictor variables are present in the regression model in linear terms, there are potentially 28 pairwise interaction terms that could be added to the regression model. The dataset would need to be quite large before 36 <span class="math inline">\(X\)</span> variables could be used in the regression model.</li>
</ul>
</li>
<li>
<p>It is therefore desirable to identify in advance, whenever possible, those interactions that are most likely to influence the response variable in important ways.</p>
<ul>
<li><p>In addition to utilizing <em>a priori</em> knowledge, one can plot the residuals for the additive regression model against the different interaction terms to determine which ones appear to be influential in affecting the response variable.</p></li>
<li><p>When the number of predictor variables is large, these plots may need to be limited to intemction terms involving those predictor variables that appear to be the most important on the basis of the initial fit of the additive regression model.</p></li>
</ul>
</li>
</ul></section><section id="demo" class="level3" data-number="7.2.4"><h3 data-number="7.2.4" class="anchored" data-anchor-id="demo">
<span class="header-section-number">7.2.4</span> Demo</h3>
<p>No interaction effect</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># generate data from additive model</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">num_x</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">num_x</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">}</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">%&lt;&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">n</span><span class="op">)</span>, <span class="va">.</span><span class="op">)</span></span>
<span><span class="va">betas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="va">num_x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># combine data</span></span>
<span><span class="va">data_sample</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">Y</span>, <span class="va">X</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">data.frame</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data_sample</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Y"</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">num_x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit interaction model</span></span>
<span><span class="va">mod_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">X1</span> <span class="op">*</span> <span class="va">X2</span>, <span class="va">data_sample</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">mod_1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)    1.62     0.793       2.05 5.11e- 2
2 X1             2.49     0.219      11.4  1.35e-11
3 X2             2.37     0.325       7.27 1.00e- 7
4 X1:X2         -0.132    0.0979     -1.35 1.88e- 1</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># interaction plot</span></span>
<span><span class="co"># -&gt; var1 = variable of interest</span></span>
<span><span class="co"># -&gt; var2 = conditioning variable</span></span>
<span><span class="fu">interplot</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/interplot/man/interplot.html">interplot</a></span><span class="op">(</span><span class="va">mod_1</span>, var1 <span class="op">=</span> <span class="st">"X2"</span>, var2 <span class="op">=</span> <span class="st">"X1"</span>,</span>
<span>                     point <span class="op">=</span> <span class="cn">T</span>,</span>
<span>                     stats_cp <span class="op">=</span> <span class="st">"ci"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Non significant interaction"</span>,</span>
<span>       x <span class="op">=</span> <span class="st">"X2"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Estimated coefficient for X1"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-reg-models-quan-and-qual_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>The algorithm behind the plot is essentially fitting a bunch of models for each unique level of <span class="math inline">\(X_2\)</span> (the conditioning variable) and plotting a CI for the resulting estimated coefficients for <span class="math inline">\(X_1\)</span>.</p></li>
<li><p>Reference line could be at <span class="math inline">\(Y = 0\)</span>, which obviously means non significant, but so does small values of the coefficient (relative to the standard error, have to make <span class="math inline">\(t\)</span>-stats out of them).</p></li>
<li><p>Confidence interval in bottom corner should however be interpreted with respect to 0; it is measuring something different (explained in the vignette). Can also look at the distribution of the conditioning variable with <code>hist = T</code>, which can help for effects that are significant over part of the range, but not all.</p></li>
</ul>
<p>Interaction effect</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># generate data from interaction model</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">num_x</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">num_x</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="va">data.frame</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>X1X2 <span class="op">=</span> <span class="va">X1</span> <span class="op">*</span> <span class="va">X2</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">as.matrix</span></span>
<span><span class="va">X</span> <span class="op">%&lt;&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">n</span><span class="op">)</span>, <span class="va">.</span><span class="op">)</span></span>
<span><span class="va">betas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="va">num_x</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># combine data</span></span>
<span><span class="va">data_sample</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">Y</span>, <span class="va">X</span><span class="op">[</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">data.frame</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data_sample</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Y"</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">num_x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit interaction model</span></span>
<span><span class="va">mod_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">X1</span> <span class="op">*</span> <span class="va">X2</span>, <span class="va">data_sample</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">mod_2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)   -0.263     0.923    -0.285 7.78e- 1
2 X1             2.13      0.287     7.42  6.98e- 8
3 X2             2.58      0.341     7.58  4.76e- 8
4 X1:X2          1.94      0.142    13.7   2.13e-13</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># interaction plot</span></span>
<span><span class="co"># -&gt; var1 = variable of interest</span></span>
<span><span class="co"># -&gt; var2 = conditioning variable</span></span>
<span><span class="fu">interplot</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/interplot/man/interplot.html">interplot</a></span><span class="op">(</span><span class="va">mod_2</span>, var1 <span class="op">=</span> <span class="st">"X2"</span>, var2 <span class="op">=</span> <span class="st">"X1"</span>,</span>
<span>                     stats_cp <span class="op">=</span> <span class="st">"ci"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Significant interaction"</span>,</span>
<span>       x <span class="op">=</span> <span class="st">"X2"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Estimated coefficient for X1"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-reg-models-quan-and-qual_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
</section></section><section id="qualitative-predictors" class="level2" data-number="7.3"><h2 data-number="7.3" class="anchored" data-anchor-id="qualitative-predictors">
<span class="header-section-number">7.3</span> Qualitative predictors</h2>
<section id="implementation-of-qualitative-predictors" class="level3" data-number="7.3.1"><h3 data-number="7.3.1" class="anchored" data-anchor-id="implementation-of-qualitative-predictors">
<span class="header-section-number">7.3.1</span> Implementation of qualitative predictors</h3>
<p>As mentioned in <a href="notes-multiple-regression-1.html#sec-first-order-two-preds" class="quarto-xref"><span>Section&nbsp;5.2.1</span></a>, qualitative, as well as quantitative, predictor variables can be used in regression models.</p>
<p>A qualitative variable with <span class="math inline">\(c\)</span> classes will be represented by <span class="math inline">\(c - 1\)</span> indicator variables, each taking on the values 0 and 1.</p>
<ul>
<li><p>Need one less predictor variable to avoid linear dependency with the intercept term (see book for explanation).</p></li>
<li><p>Additionally, we use indicator variables (rather than allocated codes (e.g.&nbsp;one variable with levels 1, 2, 3 for the three levels)), make no assumptions about the spacing of the classes and rely on the data to show the differential effects that occur.</p></li>
</ul>
<p>Demo</p>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># look at anova model (just to get the idea of how indicators are coded)</span></span>
<span></span>
<span><span class="co"># investigate data</span></span>
<span><span class="co"># -&gt; R dataset with two categorical variables (wool and tension) and one numeric response (breaks)</span></span>
<span><span class="co"># -&gt; confirm numeric and look at number of levels for each X</span></span>
<span><span class="fu">datasets</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/r/datasets/warpbreaks.html">warpbreaks</a></span> <span class="op">%&gt;%</span> <span class="va">glimpse</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 54
Columns: 3
$ breaks  &lt;dbl&gt; 26, 30, 54, 25, 70, 52, 51, 26, 67, 18, 21, 29, 17, 12, 18, 35…
$ wool    &lt;fct&gt; A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A,…
$ tension &lt;fct&gt; L, L, L, L, L, L, L, L, L, M, M, M, M, M, M, M, M, M, H, H, H,…</code></pre>
</div>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">warpbreaks</span> <span class="op">%&gt;%</span> <span class="fu">map</span><span class="op">(</span><span class="va">class</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$breaks
[1] "numeric"

$wool
[1] "factor"

$tension
[1] "factor"</code></pre>
</div>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">warpbreaks</span> <span class="op">%&gt;%</span> <span class="fu">select</span><span class="op">(</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">map</span><span class="op">(</span><span class="va">levels</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$wool
[1] "A" "B"

$tension
[1] "L" "M" "H"</code></pre>
</div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># view replication</span></span>
<span><span class="co"># -&gt; it's a balanced design</span></span>
<span><span class="va">warpbreaks</span> <span class="op">%&gt;%</span> <span class="fu">select</span><span class="op">(</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">table</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    tension
wool L M H
   A 9 9 9
   B 9 9 9</code></pre>
</div>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># design matrix via lm()</span></span>
<span></span>
<span><span class="co"># specify model with only categorical predictor</span></span>
<span><span class="va">mod_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">breaks</span> <span class="op">~</span> <span class="va">wool</span>, <span class="va">warpbreaks</span>, x <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">mod_cat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)    31.0       2.50     12.4  3.61e-17
2 woolB          -5.78      3.54     -1.63 1.08e- 1</code></pre>
</div>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare dataset to design matrix of indicator variables</span></span>
<span><span class="co"># -&gt; .$model this just gives the dataset where the variables are pulled from</span></span>
<span><span class="va">tmp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">mod_cat</span><span class="op">$</span><span class="va">model</span>, <span class="va">mod_cat</span><span class="op">$</span><span class="va">x</span><span class="op">[</span> , <span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu">arrange</span><span class="op">(</span><span class="va">tmp</span>, <span class="va">breaks</span><span class="op">)</span>, n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   breaks wool mod_cat$x[, -1]
1      10    A               0
2      12    A               0
3      13    B               1
4      14    B               1
5      15    A               0
6      15    B               1
7      15    B               1
8      16    B               1
9      16    B               1
10     17    A               0</code></pre>
</div>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># switch the default level</span></span>
<span><span class="co"># -&gt; just needs to be the first level</span></span>
<span><span class="va">mod_cat</span> <span class="op">&lt;-</span> <span class="va">warpbreaks</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>wool <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">wool</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"B"</span>,<span class="st">"A"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">breaks</span> <span class="op">~</span> <span class="va">wool</span>, data <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">}</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">mod_cat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)    25.3       2.50     10.1  7.37e-14
2 woolA           5.78      3.54      1.63 1.08e- 1</code></pre>
</div>
</div>
</section><section id="interpretation-of-regression-coefficients" class="level3" data-number="7.3.2"><h3 data-number="7.3.2" class="anchored" data-anchor-id="interpretation-of-regression-coefficients">
<span class="header-section-number">7.3.2</span> Interpretation of regression coefficients</h3>
<p>One predictor – Two levels</p>
<ul>
<li>Suppose we have the regression model:</li>
</ul>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \epsilon_i\]</span></p>
<ul>
<li>where</li>
</ul>
<p><span class="math display">\[
X_{i1} = \text{quantitative predictor};\\
X_{i2} =
  \left\{
    \begin{array}{ll}
      0 &amp; \text{level 1}\\
      1 &amp; \text{level 2}
    \end{array}
  \right.
\]</span></p>
<ul>
<li>The response function for the model is</li>
</ul>
<p><span class="math display">\[E(Y) = \beta_0 + \beta_1 X_1 + \beta_2 X_2\]</span>.</p>
<ul>
<li><p>To understand the meaning of regression coefficients in this model, we have to look at the model for the different levels of the categorical predictor.</p></li>
<li><p>Suppose we are looking at the model for level 1, where <span class="math inline">\(X_2 = 0\)</span>. The response function becomes:</p></li>
</ul>
<p><span class="math display">\[E(Y) = \beta_0 + \beta_1 X_1 + \beta_2 (0) = \beta_0 + \beta_1 X_1 \hspace{10pt} \text{level 1}\]</span></p>
<ul>
<li><p>This response function is a straight line with <span class="math inline">\(Y\)</span> intercept <span class="math inline">\(\beta_0\)</span> and slope <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>For a level 2 observation, <span class="math inline">\(X_2 = 1\)</span>. The response function becomes:</p></li>
</ul>
<p><span class="math display">\[E(Y) = \beta_0 + \beta_1 X_1 + \beta_2 (1) = (\beta_0 + \beta_2) + \beta_1 X_1 \hspace{10pt} \text{level 2}\]</span></p>
<ul>
<li><p>This response function is a also straight line, with the same slope <span class="math inline">\(\beta_1\)</span>, but with <span class="math inline">\(Y\)</span> intercept <span class="math inline">\(\beta_0 + \beta_1\)</span>.</p></li>
<li><p>Thus <span class="math inline">\(beta_2\)</span> measures the differential effect between level 2 and level 1,</p></li>
</ul>
<p><span class="math display">\[
\begin{align*}
\beta_0 &amp;= E(Y \mid X_2 = 0)\\
\beta_2 &amp;= E(Y \mid X_2 = 1) - E(Y \mid X_2 = 0)
\end{align*}
\]</span></p>
<ul>
<li>Here is a visual of the two response functions.</li>
</ul>
<p><img src="files/images/response-functions-quals.png" class="img-fluid" style="width:80.0%"></p>
<ul>
<li>In general, <span class="math inline">\(\beta_1\)</span> shows how much higher (or lower) the mean response line is for the class coded 1 than the line for the class coded 0, for any given level of <span class="math inline">\(X_1\)</span>
</li>
</ul>
<p>One predictor – More than two levels</p>
<ul>
<li><p>The above logic and strategy can easily be extended to categorical predictors with more than 2 levels.</p></li>
<li><p>Suppose we have the model:</p></li>
</ul>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \beta_2 X_{i2} + \epsilon_i\]</span></p>
<p><span class="math display">\[
X_{i1} = \text{quantitative predictor};
\\
X_{i2} =
  \left\{
    \begin{array}{ll}
      1 &amp; \text{level 2}\\
      0 &amp; \text{otherwise}
    \end{array}
  \right.;
\\
X_{i3} =
  \left\{
    \begin{array}{ll}
      1 &amp; \text{level 3}\\
      0 &amp; \text{otherwise}
    \end{array}
  \right.
\]</span></p>
<ul>
<li><p>Now <span class="math inline">\(\beta_3 = E(Y \mid X_2 = 0, X_3 = 1) - E(Y \mid X_2 = 0, X_3 = 0)\)</span></p></li>
<li><p>We may wish to estimate differential effects other than against the default zero level. This can be done by estimating differences between regression coefficients, say if there are 3 levels and we want to compare level 3 to level 2:</p></li>
</ul>
<p><span class="math display">\[\beta_3 - \beta_2 = E(Y \mid X_2 = 0, X_3 = 1) - E(Y \mid X_2 = 1, X_3 = 0)\]</span></p>
<ul>
<li><p>This now measures the differential effect (how much higher or lower the response functioni is) of level 3 relative to level 2.</p></li>
<li><p>The point estimator of this quantity is, of course, <span class="math inline">\(\hat{\beta}_3 - \hat{\beta}_2\)</span>, and the estimated variance of this estimator is</p></li>
</ul>
<p><span class="math display">\[s^2\{\hat{\beta}_3 - \hat{\beta}_2\} = s^2\{\hat{\beta}_3\} + s^2\{\hat{\beta}_2\} - 2 s\{\hat{\beta}_3,\hat{\beta}_2\}\]</span></p>
<ul>
<li>(add variances and two times covariance, but minus). The needed variances and covariance can be readily ob’tained from the estimated variance-covariance matrix of the regression coefficients.</li>
</ul>
<p>Demo of design matrix intepretation</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># again, look at design matrix via lm() for more than two categories</span></span>
<span></span>
<span><span class="co"># specify model with only categorical predictor</span></span>
<span><span class="va">mod_cat2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">breaks</span> <span class="op">~</span> <span class="va">tension</span>, <span class="va">warpbreaks</span>, x <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">mod_cat2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)     36.4      2.80     13.0  8.30e-18
2 tensionM       -10        3.96     -2.53 1.47e- 2
3 tensionH       -14.7      3.96     -3.72 5.01e- 4</code></pre>
</div>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare dataset to design matrix of indicator variables</span></span>
<span><span class="co"># -&gt; .$model this just gives the dataset where the variables are pulled from</span></span>
<span><span class="va">tmp2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">mod_cat2</span><span class="op">$</span><span class="va">model</span>, <span class="va">mod_cat2</span><span class="op">$</span><span class="va">x</span><span class="op">[</span> , <span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu">arrange</span><span class="op">(</span><span class="va">tmp2</span>, <span class="va">breaks</span><span class="op">)</span>, n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   breaks tension tensionM tensionH
1      10       H        0        1
2      12       M        1        0
3      13       H        0        1
4      14       L        0        0
5      15       H        0        1
6      15       H        0        1
7      15       H        0        1
8      16       M        1        0
9      16       H        0        1
10     17       M        1        0</code></pre>
</div>
</div>
<p>Demo of modeling with first order quantitative and qualitative predictors</p>
<div class="cell">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># now use data with continuous predictor</span></span>
<span><span class="va">mod_both</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Petal.Length</span> <span class="op">~</span> <span class="va">Petal.Width</span> <span class="op">+</span> <span class="va">Species</span>, <span class="va">iris</span>, x <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot three different response functions</span></span>
<span><span class="co"># -&gt; first get all points on there so zoom is correct</span></span>
<span><span class="va">iris</span> <span class="op">%$%</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>, y <span class="op">=</span> <span class="va">Petal.Length</span>, main <span class="op">=</span> <span class="st">"Constant slope, different intercepts"</span><span class="op">)</span></span>
<span><span class="va">iris</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">==</span> <span class="st">"setosa"</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>, y <span class="op">=</span> <span class="va">Petal.Length</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="va">iris</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">==</span> <span class="st">"versicolor"</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>, y <span class="op">=</span> <span class="va">Petal.Length</span>, col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span>
<span><span class="va">iris</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">==</span> <span class="st">"virginica"</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>, y <span class="op">=</span> <span class="va">Petal.Length</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">3</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">4</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-reg-models-quan-and-qual_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Now test on levels coefficients’ relative to other than the base level.</p>
<div class="cell">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># tests on coefficients (different intercepts)</span></span>
<span><span class="fu">tidy</span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  term              estimate std.error statistic  p.value
  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)           1.21    0.0652     18.6  2.88e-40
2 Petal.Width           1.02    0.152       6.69 4.41e-10
3 Speciesversicolor     1.70    0.181       9.38 1.17e-16
4 Speciesvirginica      2.28    0.281       8.09 2.08e-13</code></pre>
</div>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># both the latter two specied have different heights of there regression functions based on the t-tests of beta2 and beta3 (relative to beta1)</span></span>
<span></span>
<span><span class="co"># verify standard errors for t tests using matrix results</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="va">mod_both</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">varcov_beta</span> <span class="op">&lt;-</span> <span class="fu">glance</span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">X</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">mod_both</span> <span class="op">%&gt;%</span> <span class="va">tidy</span> <span class="op">%&gt;%</span> <span class="fu">pull</span><span class="op">(</span><span class="va">std.error</span><span class="op">)</span>, <span class="va">varcov_beta</span> <span class="op">%&gt;%</span> <span class="va">diag</span> <span class="op">%&gt;%</span> <span class="va">sqrt</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`mod_both %&gt;% tidy %&gt;% pull(std.error)`
[1] 0.06524192 0.15224171 0.18094771 0.28132455

$`varcov_beta %&gt;% diag %&gt;% sqrt`
      (Intercept)       Petal.Width Speciesversicolor  Speciesvirginica 
       0.06524192        0.15224171        0.18094771        0.28132455 </code></pre>
</div>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># test beta3 - beta2</span></span>
<span><span class="va">beta3_beta2_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">beta3_beta2_hat_se</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">varcov_beta</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span> <span class="op">-</span> <span class="fl">2</span><span class="op">*</span><span class="va">varcov_beta</span><span class="op">[</span><span class="fl">4</span>,<span class="fl">3</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">t_star</span> <span class="op">&lt;-</span> <span class="va">beta3_beta2_hat</span> <span class="op">/</span> <span class="va">beta3_beta2_hat_se</span></span>
<span></span>
<span><span class="co"># verify by changing the default level and checking t-stat</span></span>
<span><span class="co"># -&gt; need 2 to be the default</span></span>
<span><span class="va">mod_both2</span> <span class="op">&lt;-</span> <span class="va">iris</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>Species <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Species</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"versicolor"</span>, <span class="st">"setosa"</span>, <span class="st">"virginica"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Petal.Length</span> <span class="op">~</span> <span class="va">Petal.Width</span> <span class="op">+</span> <span class="va">Species</span>, <span class="va">.</span><span class="op">)</span><span class="op">}</span></span>
<span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu">tidy</span><span class="op">(</span><span class="va">mod_both2</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">term</span> <span class="op">==</span> <span class="st">"Speciesvirginica"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">pull</span><span class="op">(</span><span class="va">statistic</span><span class="op">)</span>, <span class="va">t_star</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`tidy(mod_both2) %&gt;% filter(term == "Speciesvirginica") %&gt;% pull(statistic)`
[1] 4.431538

$t_star
[1] 4.431538</code></pre>
</div>
</div>
<p>Fitting one line instead of two</p>
<ul>
<li>Fitting one line, as opposed to separate regression for each category, is the preferred method because of two reasons:</li>
</ul>
<ol type="1">
<li><p>Since the model assumes equal slopes and the same constant error term variance for each type of firm, the common slope <span class="math inline">\(\beta_1\)</span> can best be estimated by pooling the two levels.</p></li>
<li><p>Also, other inferences, such as for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_2\)</span>, can be made more precisely by working with one regression model containing an indicator variable since more degrees of freedom will then be associated with <span class="math inline">\(MSE\)</span>.</p></li>
</ol>
<ul>
<li>More is said about this strategy in <a href="#sec-misc-topics-quals" class="quarto-xref"><span>Section&nbsp;7.3.4</span></a>.</li>
</ul></section><section id="modeling-interactions-between-quantitative-and-qualitative-predictors" class="level3" data-number="7.3.3"><h3 data-number="7.3.3" class="anchored" data-anchor-id="modeling-interactions-between-quantitative-and-qualitative-predictors">
<span class="header-section-number">7.3.3</span> Modeling interactions between quantitative and qualitative predictors</h3>
<p>Setup</p>
<ul>
<li>Suppose we have the model below. Even though one of the predictor variables in the regression model is qualitative, interaction effects can still be introduced into the model in the usual manner, by including cross-product terms.</li>
</ul>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \beta_3 X_{i1} X_{i2} +\epsilon_i\]</span></p>
<ul>
<li>where</li>
</ul>
<p><span class="math display">\[
X_{i1} = \text{quantitative predictor}\\
X_{i2} =
  \left\{
    \begin{array}{ll}
      0 &amp; \text{level 1}\\
      1 &amp; \text{level 2}
    \end{array}
  \right.
\]</span></p>
<ul>
<li>The response function of the model is:</li>
</ul>
<p><span class="math display">\[E(Y_i) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2\]</span> Meaning of regression coefficients</p>
<ul>
<li><p>Again, the meaning of the regression coefficients in response function above can best be understood by examining the nature of this function for each level.</p></li>
<li><p>For level 1, <span class="math inline">\(X_2 = 0\)</span> and thus <span class="math inline">\(X_1 X_2 = 0\)</span>, so</p></li>
</ul>
<p><span class="math display">\[E(Y_i) = \beta_0 + \beta_1 X_1 + \beta_2 (0) + \beta_3 (0) = \beta_0 + \beta_1 X_1 \hspace{20pt} \text{level 1}\]</span></p>
<ul>
<li><p>This has intercept <span class="math inline">\(\beta_0\)</span> and slope <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>For level 2, <span class="math inline">\(X_2 = 1\)</span> and thus <span class="math inline">\(X_1 X_2 = X_1\)</span>, so</p></li>
</ul>
<p><span class="math display">\[E(Y_i) = \beta_0 + \beta_1 X_1 + \beta_2 (1) + \beta_3 X_1 = (\beta_0 + \beta_2) + (\beta_1 + \beta_3) X_1 \hspace{20pt} \text{level 2}\]</span></p>
<ul>
<li><p>This has intercept <span class="math inline">\(\beta_0 + \beta_2\)</span> and slope <span class="math inline">\(\beta_1 + \beta_3\)</span>.</p></li>
<li><p>We see that <span class="math inline">\(\beta_2\)</span> here indicates how much greater (or smaller) is the <span class="math inline">\(Y\)</span> intercept of the response function for the class coded 1 than that for the class coded O. Similarly, <span class="math inline">\(\beta_3\)</span> indicates how much greater (or smaller) is the slope of the response function for the class coded 1 than that for the class coded O.</p></li>
<li><p>Because both the intercept and the slope differ for the two classes in regression model, it is no longer true that <span class="math inline">\(\beta_2\)</span> indicates how much higher (or lower) one response function is than the other for any given level of <span class="math inline">\(X_1\)</span>.</p></li>
<li><p>Thus, when interaction effects are present, the effect of the qualitative predictor variable can be studied only by comparing the regression functions within the scope of the model for the different classes of the qualitative variable.</p></li>
</ul>
<p><img src="files/images/qualitative-interaction-effects.png" class="img-fluid" style="width:80.0%"></p>
<ul>
<li>When one of the predictor variables is qualitative and the other quantitative, nonparallel response functions that do not intersect within the scope of the model are sometimes said to represent an <em>ordinal interaction</em>. When the response functions intersect within the scope of the model, the interaction is then said to be a <em>disordinal interaction</em>.</li>
</ul>
<p>Testing interaction effects</p>
<ul>
<li><p>Fitting the previous regression model yields the same response functions as would fitting separate regressions for level 1 and level 2. An advantage of using this model with an indicator variable is that one regression run will yield both fitted regressions.</p></li>
<li>
<p>Another advantage is that tests for comparing the regression functions for the different classes of the qualitative variable can be clearly seen to involve tests of regression coefficients in a general linear model.</p>
<ul>
<li>For example we can do two tests: one on just the slopes and another of if the entire regression lines are identical.</li>
</ul>
</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  \text{Test on slopes}\\
  H_0&amp;: \beta_3 = 0\\
  H_A&amp;: \beta_3 \ne 0\\
  \text{Test on entire regression line}\\
  H_0&amp;: \beta_2 = \beta_3 = 0\\
  H_A&amp;: \text{not both } \beta_2 = 0 \text{ and } \beta_3 = 0
\end{align*}
\]</span></p>
<p>Demo of design matrix interpretation and how constructed with interaction effects</p>
<div class="cell">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># specify each term individual -&gt; A + B + AB</span></span>
<span><span class="va">mod_cat3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">breaks</span> <span class="op">~</span> <span class="va">wool</span> <span class="op">+</span> <span class="va">tension</span> <span class="op">+</span> <span class="va">wool</span> <span class="op">:</span> <span class="va">tension</span>, data <span class="op">=</span> <span class="va">warpbreaks</span>, x <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># equivalent shorthand notation to cross factors</span></span>
<span><span class="va">mod_cat3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">breaks</span> <span class="op">~</span> <span class="va">wool</span> <span class="op">*</span> <span class="va">tension</span>, data <span class="op">=</span> <span class="va">warpbreaks</span>, x <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># extract design matrix</span></span>
<span><span class="va">X_lm</span> <span class="op">&lt;-</span> <span class="va">mod_cat3</span><span class="op">$</span><span class="va">x</span></span>
<span></span>
<span><span class="co"># check how to read indicators (ignoring replication)</span></span>
<span><span class="va">warpbreaks</span> <span class="op">%&gt;%</span> <span class="fu">select</span><span class="op">(</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">bind_cols</span><span class="op">(</span><span class="va">X_lm</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">unique</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   wool tension (Intercept) woolB tensionM tensionH woolB:tensionM
1     A       L           1     0        0        0              0
10    A       M           1     0        1        0              0
19    A       H           1     0        0        1              0
28    B       L           1     1        0        0              0
37    B       M           1     1        1        0              1
46    B       H           1     1        0        1              0
   woolB:tensionH
1               0
10              0
19              0
28              0
37              0
46              1</code></pre>
</div>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># -&gt; R has levels - 1 indicators for each categorical variable</span></span>
<span><span class="co"># -&gt; the "dropped" base level also isn't explicitly included in any interaction indicator terms</span></span>
<span><span class="co"># --&gt; so interactions are taken into account with zeros for actual interactions terms and 0 or 1 for the second factor</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>All higher order terms involving the base level are also dropped.</li>
</ul>
<p>Demo to visualize model with interactions</p>
<div class="cell">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># now use data with continuous predictor</span></span>
<span><span class="va">mod_both_int</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Petal.Length</span> <span class="op">~</span> <span class="va">Petal.Width</span> <span class="op">*</span> <span class="va">Species</span>, <span class="va">iris</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both_int</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  (Intercept)                   Petal.Width 
                    1.3275634                     0.5464903 
            Speciesversicolor              Speciesvirginica 
                    0.4537120                     2.9130892 
Petal.Width:Speciesversicolor  Petal.Width:Speciesvirginica 
                    1.3228344                     0.1007691 </code></pre>
</div>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot three different response functions</span></span>
<span><span class="co"># -&gt; first get all points on there so zoom is correct</span></span>
<span><span class="va">iris</span> <span class="op">%$%</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>, y <span class="op">=</span> <span class="va">Petal.Length</span>, main <span class="op">=</span> <span class="st">"Different regression lines (different intercepts and slopes)"</span><span class="op">)</span></span>
<span><span class="va">iris</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">==</span> <span class="st">"setosa"</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>, y <span class="op">=</span> <span class="va">Petal.Length</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="va">iris</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">==</span> <span class="st">"versicolor"</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>, y <span class="op">=</span> <span class="va">Petal.Length</span>, col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span>
<span><span class="va">iris</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">==</span> <span class="st">"virginica"</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>, y <span class="op">=</span> <span class="va">Petal.Length</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both_int</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both_int</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both_int</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">3</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both_int</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">5</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both_int</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">4</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_both_int</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">6</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-reg-models-quan-and-qual_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare to ggplot</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">iris</span>,</span>
<span>       <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Width</span>,</span>
<span>           y <span class="op">=</span> <span class="va">Petal.Length</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>color <span class="op">=</span> <span class="va">Species</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>color <span class="op">=</span> <span class="va">Species</span><span class="op">)</span>,</span>
<span>              se <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>              method <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>              fullrange <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-reg-models-quan-and-qual_files/figure-html/unnamed-chunk-16-2.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># test if only slopes are different</span></span>
<span><span class="va">mod_full</span> <span class="op">&lt;-</span> <span class="va">mod_both_int</span></span>
<span><span class="va">mod_reduced</span> <span class="op">&lt;-</span> <span class="va">mod_both</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_full</span>, <span class="va">mod_reduced</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: Petal.Length ~ Petal.Width * Species
Model 2: Petal.Length ~ Petal.Width + Species
  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
1    144 18.816                                  
2    146 20.833 -2   -2.0178 7.7213 0.0006525 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># test if entire regression lines are different</span></span>
<span><span class="va">mod_full</span> <span class="op">&lt;-</span> <span class="va">mod_both_int</span></span>
<span><span class="va">mod_reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">mod_both</span>, <span class="va">.</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span><span class="va">Species</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_full</span>, <span class="va">mod_reduced</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: Petal.Length ~ Petal.Width * Species
Model 2: Petal.Length ~ Petal.Width
  Res.Df    RSS Df Sum of Sq      F                Pr(&gt;F)    
1    144 18.816                                              
2    148 33.845 -4   -15.029 28.755 &lt; 0.00000000000000022 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</section><section id="sec-misc-topics-quals" class="level3" data-number="7.3.4"><h3 data-number="7.3.4" class="anchored" data-anchor-id="sec-misc-topics-quals">
<span class="header-section-number">7.3.4</span> Miscellaneous topics with qualitative predictors</h3>
<p>Qualitative predictors only</p>
<ul>
<li>
<p>Regression models containing only qualitative predictor variables can also be constructed.</p>
<ul>
<li><p>Models in which all explanatory variables are qualitative are called <em>analysis of variance models (ANOVA)</em>.</p></li>
<li><p>Models containing some quantitative and some qualitative explanatory variables, where the chief explanatory variables of interest are qualitative and the quantitative variables are introduced primarily to reduce the variance of the error terms, are called <em>analysis of covariance models (ANCOVA)</em>.</p></li>
</ul>
</li>
</ul>
<p>Indicator variables vs quantitative variables</p>
<ul>
<li>
<p>Indicator variables can be used even if the predictor variable is quantitative.</p>
<ul>
<li><p>For instance, the quantitative variable age may be transformed by grouping ages into classes such as under 21, 21-34, 35-49, etc. Indicator variables are then used for the classes of this new predictor variable.</p></li>
<li><p>This is called <em>discretizing</em> the variable.</p></li>
</ul>
</li>
<li><p>At first sight, this may seem to be a questionable approach because information about the actual ages is thrown away. Furthermore, additional parameters are placed into the model, which leads to a reduction of the degrees of freedom associated with <span class="math inline">\(MSE\)</span>. Nevertheless, there are occasions when replacement of a quantitative variable by indicator variables may be appropriate.</p></li>
<li>
<p>For large data sets, use of indicator variables can serve as an alternative to lowess and other nonparametric fits of the response function.</p>
<ul>
<li><p>Cost: For say 1000 observations, the loss of 10 or 20 degrees of freedom is immaterial.</p></li>
<li><p>Gain: If you are very much in doubt about the shape of the regression function, which could be highly complex, you could utilize the indicator variable approach in order to obtain information about the shape ofthe response function without making any assumptions about its functional form (not assuming linear or quadratic for example).</p></li>
</ul>
</li>
</ul>
<p>Demo</p>
<div class="cell">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot data</span></span>
<span><span class="va">diamonds</span> <span class="op">%$%</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carat</span>, y <span class="op">=</span> <span class="va">price</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit linear model to see</span></span>
<span><span class="va">mod_linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">price</span> <span class="op">~</span> <span class="va">carat</span>, <span class="va">diamonds</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">mod_linear</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-reg-models-quan-and-qual_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># think a more complex function would be better</span></span>
<span></span>
<span><span class="co"># discretize x variable and fit model with indicator variables</span></span>
<span><span class="va">mod_discretized</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">diamonds</span><span class="op">$</span><span class="va">price</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="fu">cut_number</span><span class="op">(</span><span class="va">diamonds</span><span class="op">$</span><span class="va">carat</span>, n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mod_discretized</span> <span class="op">%&gt;%</span> <span class="va">tidy</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 5
   term                                   estimate std.error statistic   p.value
   &lt;chr&gt;                                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
 1 (Intercept)                               655.       20.3     32.2  5.55e-226
 2 as.factor(cut_number(diamonds$carat, …     95.4      31.5      3.03 2.44e-  3
 3 as.factor(cut_number(diamonds$carat, …    267.       30.1      8.88 6.59e- 19
 4 as.factor(cut_number(diamonds$carat, …    831.       30.6     27.2  1.70e-161
 5 as.factor(cut_number(diamonds$carat, …   1435.       29.8     48.1  0        
 6 as.factor(cut_number(diamonds$carat, …   2441.       28.8     84.9  0        
 7 as.factor(cut_number(diamonds$carat, …   4384.       30.6    143.   0        
 8 as.factor(cut_number(diamonds$carat, …   5170.       31.6    164.   0        
 9 as.factor(cut_number(diamonds$carat, …   7289.       29.2    250.   0        
10 as.factor(cut_number(diamonds$carat, …  12281.       31.4    391.   0        </code></pre>
</div>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># fully discretize model</span></span>
<span><span class="va">mod_full_discretized</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">price</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">diamonds</span><span class="op">$</span><span class="va">carat</span><span class="op">)</span>, <span class="va">diamonds</span><span class="op">)</span></span>
<span><span class="va">mod_full_discretized</span> <span class="op">%&gt;%</span> <span class="va">tidy</span> <span class="op">%&gt;%</span> <span class="va">nrow</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 273</code></pre>
</div>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># add complex models to plot for comparison</span></span>
<span><span class="va">diamonds</span> <span class="op">%$%</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carat</span>, y <span class="op">=</span> <span class="va">price</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">mod_linear</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="va">diamonds</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">augment</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mod_discretized</span>, data <span class="op">=</span> <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">carat</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carat</span>, y <span class="op">=</span> <span class="va">.fitted</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="co"># step function because x values in between cutoffs with same predicted y value</span></span>
<span><span class="va">diamonds</span> <span class="op">%$%</span> <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lowess.html">lowess</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carat</span>, y <span class="op">=</span> <span class="va">price</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span>
<span><span class="va">diamonds</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">augment</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mod_full_discretized</span>, data <span class="op">=</span> <span class="va">.</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">carat</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carat</span>, y <span class="op">=</span> <span class="va">.fitted</span>, col <span class="op">=</span> <span class="st">"yellow"</span><span class="op">)</span> <span class="co"># when no replication, gets predicted exactly -&gt; but this is still a smooth curve because covers each unique value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-reg-models-quan-and-qual_files/figure-html/unnamed-chunk-18-2.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Comparison of two or more regression functions</p>
<ul>
<li><p>To formally test if these two regression lines are different (e.g.&nbsp;if data come from two different populations, such as males vs females), we can use indicator variables and partial <span class="math inline">\(F\)</span>-tests.</p></li>
<li>
<p>We simply consider the different populations as classes of a predictor variable, define indicator variables for the different populations, and develop a regression model containing appropriate interaction terms</p>
<ul>
<li><p>If just testing the heights, then just need additive indicator variables for the qualitative predictor.</p></li>
<li><p>If also want to consider different slopes (i.e.&nbsp;not assume a common slope among the two populations), then include interaction terms for the continuous predictor(s) and the indicator variable(s).</p></li>
</ul>
</li>
<li>
<p>All of the above scenarios require assume that the populations have equal error term variances.</p>
<ul>
<li>If the error vanances are not equal, transformations of the response variable may equalize them at least approximately.</li>
</ul>
</li>
</ul>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./notes-multiple-regression-2.html" class="pagination-link  aria-label=" regression="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Multiple regression 2</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb57" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regression models for quantitative and qualitative predictors</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-prereqs</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a><span class="co"># knitr options</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define LaTeX macros (/shortcuts) --&gt;</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define vector (without parentheses, so when writing out in like a definition) of the form X_1, ..., X_n, where X and n are variable. </span><span class="al">NOTE</span><span class="co">: to call use $\vecn{X}{n}$ --&gt;</span></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>\newcommand{\vecn}<span class="co">[</span><span class="ot">2</span><span class="co">]</span>{#1_1, \ldots, #1_{#2}}</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for ~ 'Named dist ' in normal font with space before parameters would go --&gt;</span></span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>\newcommand{\follow}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\sim \text{#1}\,}</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % (followsp is short for 'follow special') shortcut that can be used for iid or ind ~ 'Named dist ' in normal font with space before parameters would go --&gt;</span></span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a>\newcommand{\followsp}<span class="co">[</span><span class="ot">2</span><span class="co">]</span>{\overset{#1}\sim \text{#2}\,}</span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define independence symbol (it basically makes two orthogonal symbols very close to each other. The number of \! controls the space between each of the orthogonal symbols) --&gt;</span></span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a>\newcommand{\ind}{\perp <span class="sc">\!\!\!</span> \perp}</span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for Cov(X,Y) with formatting for Cov --&gt;</span></span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a>\newcommand{\cov}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\mathrm{Cov}(#1)}</span>
<span id="cb57-36"><a href="#cb57-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-37"><a href="#cb57-37" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for Corr(X,Y) with formatting for Corr --&gt;</span></span>
<span id="cb57-38"><a href="#cb57-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-39"><a href="#cb57-39" aria-hidden="true" tabindex="-1"></a>\newcommand{\corr}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\mathrm{Corr}(#1)}</span>
<span id="cb57-40"><a href="#cb57-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-41"><a href="#cb57-41" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for non-italic e in math mode --&gt;</span></span>
<span id="cb57-42"><a href="#cb57-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-43"><a href="#cb57-43" aria-hidden="true" tabindex="-1"></a>\newcommand{\e}{\mathrm{e}}</span>
<span id="cb57-44"><a href="#cb57-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-45"><a href="#cb57-45" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for matrix notation --&gt;</span></span>
<span id="cb57-46"><a href="#cb57-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-47"><a href="#cb57-47" aria-hidden="true" tabindex="-1"></a>\newcommand{\mat}<span class="co">[</span><span class="ot">3</span><span class="co">]</span>{\underset{#2 \times #3}{\boldsymbol{#1}}}</span>
<span id="cb57-48"><a href="#cb57-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-49"><a href="#cb57-49" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for null hypothesis formatted nicely --&gt;</span></span>
<span id="cb57-50"><a href="#cb57-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-51"><a href="#cb57-51" aria-hidden="true" tabindex="-1"></a>\newcommand{\ho}{H_0}</span>
<span id="cb57-52"><a href="#cb57-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-53"><a href="#cb57-53" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for alternative hypothesis formatted nicely --&gt;</span></span>
<span id="cb57-54"><a href="#cb57-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-55"><a href="#cb57-55" aria-hidden="true" tabindex="-1"></a>\newcommand{\ha}{H_A}</span>
<span id="cb57-56"><a href="#cb57-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-57"><a href="#cb57-57" aria-hidden="true" tabindex="-1"></a><span class="fu">## Polynomial regression models</span></span>
<span id="cb57-58"><a href="#cb57-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-59"><a href="#cb57-59" aria-hidden="true" tabindex="-1"></a>We first consider polynomial regression models for quantitative predictor variables. They are among the most frequently used curvilinear response models in practice because they are handled easily as a special case of the general linear regression model (@gen-lin-mod).</span>
<span id="cb57-60"><a href="#cb57-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-61"><a href="#cb57-61" aria-hidden="true" tabindex="-1"></a>Next, we discuss several commonly used polynomial regression models.</span>
<span id="cb57-62"><a href="#cb57-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-63"><a href="#cb57-63" aria-hidden="true" tabindex="-1"></a>Then we discuss some of the major issues encountered with polynomial regression models.</span>
<span id="cb57-64"><a href="#cb57-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-65"><a href="#cb57-65" aria-hidden="true" tabindex="-1"></a><span class="fu">### Uses of polynomial models</span></span>
<span id="cb57-66"><a href="#cb57-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-67"><a href="#cb57-67" aria-hidden="true" tabindex="-1"></a>Polynomial regression models have two basic types of uses:</span>
<span id="cb57-68"><a href="#cb57-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-69"><a href="#cb57-69" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>When the true curvilinear response function is indeed a polynomial function.</span>
<span id="cb57-70"><a href="#cb57-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-71"><a href="#cb57-71" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>When the true curvilinear response function is unknown (or complex) but a polynomial function is a good approximation to the true function.</span>
<span id="cb57-72"><a href="#cb57-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-73"><a href="#cb57-73" aria-hidden="true" tabindex="-1"></a>The second type of use, where the polynomial function is employed as an approximation when the shape of the true curvilinear response function is unknown, is very common.  It may be viewed as a nonparametric approach to obtaining information about the shape of the response function.</span>
<span id="cb57-74"><a href="#cb57-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-75"><a href="#cb57-75" aria-hidden="true" tabindex="-1"></a>A main danger in using polynomial regression models is that extrapolations may be hazardous with these models, especially those with higher-order terms. Polynomial regression models may provide good fits for the data at hand, but may turn in unexpected directions when extrapolated beyond the range of the data.</span>
<span id="cb57-76"><a href="#cb57-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-77"><a href="#cb57-77" aria-hidden="true" tabindex="-1"></a><span class="fu">### One predictor variable -- Second order</span></span>
<span id="cb57-78"><a href="#cb57-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-79"><a href="#cb57-79" aria-hidden="true" tabindex="-1"></a>Polynomial regression models may contain one, two, or more than two predictor variables. Further, each predictor variable may be present in various powers. We begin with the simplest case: one predictor variable with second order.</span>
<span id="cb57-80"><a href="#cb57-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-81"><a href="#cb57-81" aria-hidden="true" tabindex="-1"></a>$$Y_i \hspace{10pt} = \hspace{10pt} \beta_0 + \beta_1 x_i + \beta_2 x_i^2 \hspace{10pt} = \hspace{10pt} \beta_0 + \beta_1 x_i + \beta_{11} x_i^2 + \epsilon_i$$</span>
<span id="cb57-82"><a href="#cb57-82" aria-hidden="true" tabindex="-1"></a>where $x_i = X_i - \bar{X}$. This model has a *quadratic response function* (a parabola):</span>
<span id="cb57-83"><a href="#cb57-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-84"><a href="#cb57-84" aria-hidden="true" tabindex="-1"></a>$$E(Y_i) = \beta_0 + \beta_1 x + \beta_{11} x^2 $$</span>
<span id="cb57-85"><a href="#cb57-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-86"><a href="#cb57-86" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/quadratic-response-functions.png)</span>{width="50%"}</span>
<span id="cb57-87"><a href="#cb57-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-88"><a href="#cb57-88" aria-hidden="true" tabindex="-1"></a>Notes</span>
<span id="cb57-89"><a href="#cb57-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-90"><a href="#cb57-90" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The predictor variable is centered, i.e. expressed as a deviation around its mean $\bar{X}$, and that the $i$th centered observation is denoted by $x_i$.</span>
<span id="cb57-91"><a href="#cb57-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-92"><a href="#cb57-92" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>The reason for using a centered predictor variable in the polynomial regression model is that $X$ and $X^2$ often will be highly correlated.  Centering the predictor variable often reduces the multicollinearity substantially and tends to avoid computational difficulties.</span>
<span id="cb57-93"><a href="#cb57-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-94"><a href="#cb57-94" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>An alternative to using centered variables in polynomial regression is to use *orthogonal polynomials*. This is what R uses in <span class="in">`poly()`</span>.</span>
<span id="cb57-95"><a href="#cb57-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-96"><a href="#cb57-96" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can use different subscripts on the $\beta$s so they match up with the power of the corresponding $x$ term better.</span>
<span id="cb57-97"><a href="#cb57-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-98"><a href="#cb57-98" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The danger of extrapolating a polynomial response function is illustrated by the response functions in the image above. If this function is extrapolated beyond $x = 2$, it actually turns downward, might not be appropriate in a given case.</span>
<span id="cb57-99"><a href="#cb57-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-100"><a href="#cb57-100" aria-hidden="true" tabindex="-1"></a>Orthogonal polynomials demo</span>
<span id="cb57-101"><a href="#cb57-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-104"><a href="#cb57-104" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-105"><a href="#cb57-105" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-106"><a href="#cb57-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-107"><a href="#cb57-107" aria-hidden="true" tabindex="-1"></a><span class="fu">### One predictor variable -- Higher orders</span></span>
<span id="cb57-108"><a href="#cb57-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-109"><a href="#cb57-109" aria-hidden="true" tabindex="-1"></a>The previous model can easily be extended to higher orders. For example, here is a third order model:</span>
<span id="cb57-110"><a href="#cb57-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-111"><a href="#cb57-111" aria-hidden="true" tabindex="-1"></a>$$Y_i = \beta_0 + \beta_1 x_i + \beta_{11} x_i^2 + \beta_{111} x_i^3 + \epsilon_i$$</span>
<span id="cb57-112"><a href="#cb57-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-113"><a href="#cb57-113" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/cubic-response-functions.png)</span>{width="50%"}</span>
<span id="cb57-114"><a href="#cb57-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-115"><a href="#cb57-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-116"><a href="#cb57-116" aria-hidden="true" tabindex="-1"></a>Polynomial models with the predictor variable present in higher powers than the third should be employed with special caution.</span>
<span id="cb57-117"><a href="#cb57-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-118"><a href="#cb57-118" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The interpretation of the coefficients becomes difficult for such models, and the models may be highly erratic for interpolations and even small extrapolations.</span>
<span id="cb57-119"><a href="#cb57-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-120"><a href="#cb57-120" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Note that a polynomial model of sufficiently high order can always be found to fit data containing no repeat observations perfectly. For instance, the fitted polynomial regression function for one predictor variable of order $n - 1$ will pass through all $n$ observed $Y$ values.</span>
<span id="cb57-121"><a href="#cb57-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-122"><a href="#cb57-122" aria-hidden="true" tabindex="-1"></a>Overfitting demo</span>
<span id="cb57-123"><a href="#cb57-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-126"><a href="#cb57-126" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-127"><a href="#cb57-127" aria-hidden="true" tabindex="-1"></a><span class="co"># generate data</span></span>
<span id="cb57-128"><a href="#cb57-128" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb57-129"><a href="#cb57-129" aria-hidden="true" tabindex="-1"></a>num_x <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb57-130"><a href="#cb57-130" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>(num_x), <span class="cf">function</span>(i) {<span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">10</span>)})</span>
<span id="cb57-131"><a href="#cb57-131" aria-hidden="true" tabindex="-1"></a>X <span class="sc">%&lt;&gt;%</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n), .)</span>
<span id="cb57-132"><a href="#cb57-132" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fu">rep</span>(<span class="dv">2</span>, num_x))</span>
<span id="cb57-133"><a href="#cb57-133" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> betas <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb57-134"><a href="#cb57-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-135"><a href="#cb57-135" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-136"><a href="#cb57-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-139"><a href="#cb57-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-140"><a href="#cb57-140" aria-hidden="true" tabindex="-1"></a><span class="co"># combine data</span></span>
<span id="cb57-141"><a href="#cb57-141" aria-hidden="true" tabindex="-1"></a>data_sample <span class="ot">&lt;-</span> <span class="fu">cbind</span>(Y, X[, <span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span> </span>
<span id="cb57-142"><a href="#cb57-142" aria-hidden="true" tabindex="-1"></a>  data.frame</span>
<span id="cb57-143"><a href="#cb57-143" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(data_sample) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Y"</span>, <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span>num_x))</span>
<span id="cb57-144"><a href="#cb57-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-145"><a href="#cb57-145" aria-hidden="true" tabindex="-1"></a><span class="co"># fit highest order model</span></span>
<span id="cb57-146"><a href="#cb57-146" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; note perfect fit</span></span>
<span id="cb57-147"><a href="#cb57-147" aria-hidden="true" tabindex="-1"></a>mod_overfit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> <span class="fu">poly</span>(X1, <span class="at">degree =</span> n <span class="sc">-</span> <span class="dv">1</span>), data_sample)</span>
<span id="cb57-148"><a href="#cb57-148" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mod_overfit)</span>
<span id="cb57-149"><a href="#cb57-149" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(mod_overfit)</span>
<span id="cb57-150"><a href="#cb57-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-151"><a href="#cb57-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-152"><a href="#cb57-152" aria-hidden="true" tabindex="-1"></a><span class="co"># plot response function</span></span>
<span id="cb57-153"><a href="#cb57-153" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; add fitted values to dataset and extract them to plot (have to sort first)</span></span>
<span id="cb57-154"><a href="#cb57-154" aria-hidden="true" tabindex="-1"></a>data_sample <span class="sc">%$%</span> <span class="fu">plot</span>(X1, Y)</span>
<span id="cb57-155"><a href="#cb57-155" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(<span class="at">x =</span> mod_overfit, <span class="at">data =</span> data_sample) <span class="sc">%&gt;%</span></span>
<span id="cb57-156"><a href="#cb57-156" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(X1) <span class="sc">%$%</span></span>
<span id="cb57-157"><a href="#cb57-157" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="at">x =</span> X1, <span class="at">y =</span> .fitted, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb57-158"><a href="#cb57-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-159"><a href="#cb57-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-160"><a href="#cb57-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-161"><a href="#cb57-161" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two or more predictor variables -- Second order</span></span>
<span id="cb57-162"><a href="#cb57-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-163"><a href="#cb57-163" aria-hidden="true" tabindex="-1"></a>Again, can extend the previous models to now include a second predictor variable and beyond (now including cross terms (interaction terms), still considered second order). For example, here is a second order model with two predictor variables:</span>
<span id="cb57-164"><a href="#cb57-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-165"><a href="#cb57-165" aria-hidden="true" tabindex="-1"></a>$$Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_{11} x_{i1}^2 + \beta_{22} x_{i2}^2 + \beta_{12} x_{i1} x_{i2} + \epsilon_i$$</span>
<span id="cb57-166"><a href="#cb57-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-167"><a href="#cb57-167" aria-hidden="true" tabindex="-1"></a>where $x_{i1} = X_{i1} - \bar{X}_1$ and $x_{i2} = X_{i2} - \bar{X}_2$. This model has a *conic response function*:</span>
<span id="cb57-168"><a href="#cb57-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-169"><a href="#cb57-169" aria-hidden="true" tabindex="-1"></a>$$E(Y_i) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_{11} x_1^2 + \beta_{22} x_2^2 + \beta_{12} x_1 x_2 $$</span>
<span id="cb57-170"><a href="#cb57-170" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/conic-response-function.png)</span>{width="50%"}</span>
<span id="cb57-171"><a href="#cb57-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-172"><a href="#cb57-172" aria-hidden="true" tabindex="-1"></a><span class="fu">### Implementation of polynomial regression models</span></span>
<span id="cb57-173"><a href="#cb57-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-174"><a href="#cb57-174" aria-hidden="true" tabindex="-1"></a>Fitting of polynomial models</span>
<span id="cb57-175"><a href="#cb57-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-176"><a href="#cb57-176" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Fitting of polynomial regression models presents no new problems since they are special cases of the usual general linear regression model.</span>
<span id="cb57-177"><a href="#cb57-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-178"><a href="#cb57-178" aria-hidden="true" tabindex="-1"></a>Hiearchical approach to fitting</span>
<span id="cb57-179"><a href="#cb57-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-180"><a href="#cb57-180" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When using a polynomial regression model as an approximation to the true regression function, statisticians will often fit a second-order or third-order model and then explore whether a lower-order model is adequate with partial $F$ tests.</span>
<span id="cb57-181"><a href="#cb57-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-182"><a href="#cb57-182" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>With the hierarchical approach, if a polynomial term of a given order is retained, then all related terms of lower order are also retained in the model.</span>
<span id="cb57-183"><a href="#cb57-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-184"><a href="#cb57-184" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Thus, one would not drop the quadratic term of a predictor variable but retain the cubic term in the model.</span>
<span id="cb57-185"><a href="#cb57-185" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-186"><a href="#cb57-186" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Since the quadratic term is of lower order, it is viewed as providing more basic information about the shape of the response function; the cubic term is of higher order and is viewed as providing refinements in the specification of the shape of the response function.</span>
<span id="cb57-187"><a href="#cb57-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-188"><a href="#cb57-188" aria-hidden="true" tabindex="-1"></a>Regression function in terms of $X$</span>
<span id="cb57-189"><a href="#cb57-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-190"><a href="#cb57-190" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>After a polynomial regression model has been developed, we often wish to express the final model in terms of the original variables rather than keeping it in terms of the centered variables. This can be done readily (not showing because not Rs implementation).</span>
<span id="cb57-191"><a href="#cb57-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-192"><a href="#cb57-192" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The fitted values and residuals for the regression function in terms of $X$ are exactly the SAME as for the regression function in terms of the centered values $x$.</span>
<span id="cb57-193"><a href="#cb57-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-194"><a href="#cb57-194" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The estimated standard deviation however do not translate. They need to be found using alternate methods.</span>
<span id="cb57-195"><a href="#cb57-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-196"><a href="#cb57-196" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- HOW to interpret orthogonal polynomial results --&gt;</span></span>
<span id="cb57-197"><a href="#cb57-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-198"><a href="#cb57-198" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interaction regression models</span></span>
<span id="cb57-199"><a href="#cb57-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-200"><a href="#cb57-200" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interaction effects</span></span>
<span id="cb57-201"><a href="#cb57-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-202"><a href="#cb57-202" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/interaction-effects-content.png)</span>{width="80%"}</span>
<span id="cb57-203"><a href="#cb57-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-204"><a href="#cb57-204" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation of interaction regression models with linear effects</span></span>
<span id="cb57-205"><a href="#cb57-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-206"><a href="#cb57-206" aria-hidden="true" tabindex="-1"></a>Interpretation of regression coefficients</span>
<span id="cb57-207"><a href="#cb57-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-208"><a href="#cb57-208" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The regression model for two quantitative predictor variables with linear effects on $Y$ and interacting effects of $X_1$ and $X_2$ on $Y$ represented by a cross-product term is as follows:</span>
<span id="cb57-209"><a href="#cb57-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-210"><a href="#cb57-210" aria-hidden="true" tabindex="-1"></a>$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \beta_3 X_{i1} X_{i2} + \epsilon_i$$</span>
<span id="cb57-211"><a href="#cb57-211" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The meaning of the regression coefficients $\beta_1$ and $\beta_2$ here is not the same as that given earlier because of the interaction term $\beta_3 X_{i1} X_{i2}$. $\beta_1$ no longer represent mean change in $Y$ for a one unit increase in $X_1$ when all other predictors are held constant at any given level.</span>
<span id="cb57-212"><a href="#cb57-212" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-213"><a href="#cb57-213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>It can be easily shown that the change in the mean response with a unit increase in $X_1$ when $X_2$ is held constant is</span>
<span id="cb57-214"><a href="#cb57-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-215"><a href="#cb57-215" aria-hidden="true" tabindex="-1"></a>$$\beta_1 + \beta_3 X_2$$</span>
<span id="cb57-216"><a href="#cb57-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-217"><a href="#cb57-217" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Similarly the change in the mean response with a unit increase in $X_2$ when $X_1$ is held constant is</span>
<span id="cb57-218"><a href="#cb57-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-219"><a href="#cb57-219" aria-hidden="true" tabindex="-1"></a>$$\beta_2 + \beta_3 X_1$$</span>
<span id="cb57-220"><a href="#cb57-220" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Thus, in the regression model above, both the effect of $X_1$ for given level of $X_2$ and the effect of $X_2$ for given level of $X_1$ depend on the level of the other predictor variable.</span>
<span id="cb57-221"><a href="#cb57-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-222"><a href="#cb57-222" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Below are *conditional effects plots* because they show the effects of $X_1$ on the mean response conditional on different levels of the other predictor variable.</span>
<span id="cb57-223"><a href="#cb57-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-224"><a href="#cb57-224" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>For additive models, the effect of $X_1$ is the same for both levels of $X_2$ (same slope) (i.e. $Y$ increases by the same amount when $X_1$ varies regardless of the level of $X_2$. </span>
<span id="cb57-225"><a href="#cb57-225" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-226"><a href="#cb57-226" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>For the reinforcement interaction, the effect of $X_1$ becomes stronger at hifher levels of $X_2$. This occurs if both the linear terms and the interaction terms have the same sign.</span>
<span id="cb57-227"><a href="#cb57-227" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-228"><a href="#cb57-228" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>In the inteference plot, the effect of $X_1$ is lessoned at higher levels of $X_2$ because the linear terms and the interaction terms have opposing signs.</span>
<span id="cb57-229"><a href="#cb57-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-230"><a href="#cb57-230" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/interaction-effects-plots.png)</span>{width="80%"}</span>
<span id="cb57-231"><a href="#cb57-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-232"><a href="#cb57-232" aria-hidden="true" tabindex="-1"></a>See <span class="co">[</span><span class="ot">interplot-vignette</span><span class="co">](https://cran.r-project.org/web/packages/interplot/vignettes/interplot-vignette.html)</span> for explanations on interaction plots in R (they are a bit different than above).</span>
<span id="cb57-233"><a href="#cb57-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-234"><a href="#cb57-234" aria-hidden="true" tabindex="-1"></a><span class="fu">### Implementation of interaction effects</span></span>
<span id="cb57-235"><a href="#cb57-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-236"><a href="#cb57-236" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When interaction terms area dded to a regression model,high multicollinearities may exist between some of the predictor variables and spme of the interaction terms, as well as among some of the interaction terms.</span>
<span id="cb57-237"><a href="#cb57-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-238"><a href="#cb57-238" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>A partial remedy to improve computational accuracy is to center the predictor variables; i.e. $x_{ik} = X_{ik} - \bar{X}_k$</span>
<span id="cb57-239"><a href="#cb57-239" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-240"><a href="#cb57-240" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When the number of predictor variables in the regression model is large, the potential number of interaction terms can become very large.</span>
<span id="cb57-241"><a href="#cb57-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-242"><a href="#cb57-242" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>For example, if eight predictor variables are present in the regression model in linear terms, there are potentially 28 pairwise interaction terms that could be added to the regression model. The dataset would need to be quite large before 36 $X$ variables could be used in the regression model.</span>
<span id="cb57-243"><a href="#cb57-243" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-244"><a href="#cb57-244" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>It is therefore desirable to identify in advance, whenever possible, those interactions that are most likely to influence the response variable in important ways.</span>
<span id="cb57-245"><a href="#cb57-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-246"><a href="#cb57-246" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>In addition to utilizing *a priori* knowledge, one can plot the residuals for the additive regression model against the different interaction terms to determine which ones appear to be influential in affecting the response variable.</span>
<span id="cb57-247"><a href="#cb57-247" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-248"><a href="#cb57-248" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>When the number of predictor variables is large, these plots may need to be limited to intemction terms involving those predictor variables that appear to be the most important on the basis of the initial fit of the additive regression model.</span>
<span id="cb57-249"><a href="#cb57-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-250"><a href="#cb57-250" aria-hidden="true" tabindex="-1"></a><span class="fu">### Demo</span></span>
<span id="cb57-251"><a href="#cb57-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-252"><a href="#cb57-252" aria-hidden="true" tabindex="-1"></a>No interaction effect</span>
<span id="cb57-253"><a href="#cb57-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-256"><a href="#cb57-256" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-257"><a href="#cb57-257" aria-hidden="true" tabindex="-1"></a><span class="co"># generate data from additive model</span></span>
<span id="cb57-258"><a href="#cb57-258" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb57-259"><a href="#cb57-259" aria-hidden="true" tabindex="-1"></a>num_x <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb57-260"><a href="#cb57-260" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>(num_x), <span class="cf">function</span>(i) {<span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">3</span>)})</span>
<span id="cb57-261"><a href="#cb57-261" aria-hidden="true" tabindex="-1"></a>X <span class="sc">%&lt;&gt;%</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n), .)</span>
<span id="cb57-262"><a href="#cb57-262" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fu">rep</span>(<span class="dv">2</span>, num_x))</span>
<span id="cb57-263"><a href="#cb57-263" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> betas <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb57-264"><a href="#cb57-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-265"><a href="#cb57-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-266"><a href="#cb57-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-269"><a href="#cb57-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-270"><a href="#cb57-270" aria-hidden="true" tabindex="-1"></a><span class="co"># combine data</span></span>
<span id="cb57-271"><a href="#cb57-271" aria-hidden="true" tabindex="-1"></a>data_sample <span class="ot">&lt;-</span> <span class="fu">cbind</span>(Y, X[, <span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span> </span>
<span id="cb57-272"><a href="#cb57-272" aria-hidden="true" tabindex="-1"></a>  data.frame</span>
<span id="cb57-273"><a href="#cb57-273" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(data_sample) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Y"</span>, <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span>num_x))</span>
<span id="cb57-274"><a href="#cb57-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-275"><a href="#cb57-275" aria-hidden="true" tabindex="-1"></a><span class="co"># fit interaction model</span></span>
<span id="cb57-276"><a href="#cb57-276" aria-hidden="true" tabindex="-1"></a>mod_1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X1 <span class="sc">*</span> X2, data_sample)</span>
<span id="cb57-277"><a href="#cb57-277" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mod_1)</span>
<span id="cb57-278"><a href="#cb57-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-279"><a href="#cb57-279" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-280"><a href="#cb57-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-283"><a href="#cb57-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-284"><a href="#cb57-284" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction plot</span></span>
<span id="cb57-285"><a href="#cb57-285" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; var1 = variable of interest</span></span>
<span id="cb57-286"><a href="#cb57-286" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; var2 = conditioning variable</span></span>
<span id="cb57-287"><a href="#cb57-287" aria-hidden="true" tabindex="-1"></a>interplot<span class="sc">::</span><span class="fu">interplot</span>(mod_1, <span class="at">var1 =</span> <span class="st">"X2"</span>, <span class="at">var2 =</span> <span class="st">"X1"</span>,</span>
<span id="cb57-288"><a href="#cb57-288" aria-hidden="true" tabindex="-1"></a>                     <span class="at">point =</span> T,</span>
<span id="cb57-289"><a href="#cb57-289" aria-hidden="true" tabindex="-1"></a>                     <span class="at">stats_cp =</span> <span class="st">"ci"</span>) <span class="sc">+</span> </span>
<span id="cb57-290"><a href="#cb57-290" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Non significant interaction"</span>,</span>
<span id="cb57-291"><a href="#cb57-291" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"X2"</span>,</span>
<span id="cb57-292"><a href="#cb57-292" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Estimated coefficient for X1"</span>)</span>
<span id="cb57-293"><a href="#cb57-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-294"><a href="#cb57-294" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-295"><a href="#cb57-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-296"><a href="#cb57-296" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The algorithm behind the plot is essentially fitting a bunch of models for each unique level of $X_2$ (the conditioning variable) and plotting a CI for the resulting estimated coefficients for $X_1$.</span>
<span id="cb57-297"><a href="#cb57-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-298"><a href="#cb57-298" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reference line could be at $Y = 0$, which obviously means non significant, but so does small values of the coefficient (relative to the standard error, have to make $t$-stats out of them).</span>
<span id="cb57-299"><a href="#cb57-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-300"><a href="#cb57-300" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Confidence interval in bottom corner should however be interpreted with respect to 0; it is measuring something different (explained in the vignette). Can also look at the distribution of the conditioning variable with <span class="in">`hist = T`</span>, which can help for effects that are significant over part of the range, but not all.</span>
<span id="cb57-301"><a href="#cb57-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-302"><a href="#cb57-302" aria-hidden="true" tabindex="-1"></a>Interaction effect</span>
<span id="cb57-303"><a href="#cb57-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-306"><a href="#cb57-306" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-307"><a href="#cb57-307" aria-hidden="true" tabindex="-1"></a><span class="co"># generate data from interaction model</span></span>
<span id="cb57-308"><a href="#cb57-308" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb57-309"><a href="#cb57-309" aria-hidden="true" tabindex="-1"></a>num_x <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb57-310"><a href="#cb57-310" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>(num_x), <span class="cf">function</span>(i) {<span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">3</span>)}) <span class="sc">%&gt;%</span></span>
<span id="cb57-311"><a href="#cb57-311" aria-hidden="true" tabindex="-1"></a>  data.frame <span class="sc">%&gt;%</span> </span>
<span id="cb57-312"><a href="#cb57-312" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">X1X2 =</span> X1 <span class="sc">*</span> X2) <span class="sc">%&gt;%</span> </span>
<span id="cb57-313"><a href="#cb57-313" aria-hidden="true" tabindex="-1"></a>  as.matrix</span>
<span id="cb57-314"><a href="#cb57-314" aria-hidden="true" tabindex="-1"></a>X <span class="sc">%&lt;&gt;%</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n), .)</span>
<span id="cb57-315"><a href="#cb57-315" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fu">rep</span>(<span class="dv">2</span>, num_x<span class="sc">+</span><span class="dv">1</span>))</span>
<span id="cb57-316"><a href="#cb57-316" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> betas <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb57-317"><a href="#cb57-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-318"><a href="#cb57-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-319"><a href="#cb57-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-322"><a href="#cb57-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-323"><a href="#cb57-323" aria-hidden="true" tabindex="-1"></a><span class="co"># combine data</span></span>
<span id="cb57-324"><a href="#cb57-324" aria-hidden="true" tabindex="-1"></a>data_sample <span class="ot">&lt;-</span> <span class="fu">cbind</span>(Y, X[, <span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]) <span class="sc">%&gt;%</span> </span>
<span id="cb57-325"><a href="#cb57-325" aria-hidden="true" tabindex="-1"></a>  data.frame</span>
<span id="cb57-326"><a href="#cb57-326" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(data_sample) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Y"</span>, <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span>num_x))</span>
<span id="cb57-327"><a href="#cb57-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-328"><a href="#cb57-328" aria-hidden="true" tabindex="-1"></a><span class="co"># fit interaction model</span></span>
<span id="cb57-329"><a href="#cb57-329" aria-hidden="true" tabindex="-1"></a>mod_2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X1 <span class="sc">*</span> X2, data_sample)</span>
<span id="cb57-330"><a href="#cb57-330" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mod_2)</span>
<span id="cb57-331"><a href="#cb57-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-332"><a href="#cb57-332" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-333"><a href="#cb57-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-336"><a href="#cb57-336" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-337"><a href="#cb57-337" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction plot</span></span>
<span id="cb57-338"><a href="#cb57-338" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; var1 = variable of interest</span></span>
<span id="cb57-339"><a href="#cb57-339" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; var2 = conditioning variable</span></span>
<span id="cb57-340"><a href="#cb57-340" aria-hidden="true" tabindex="-1"></a>interplot<span class="sc">::</span><span class="fu">interplot</span>(mod_2, <span class="at">var1 =</span> <span class="st">"X2"</span>, <span class="at">var2 =</span> <span class="st">"X1"</span>,</span>
<span id="cb57-341"><a href="#cb57-341" aria-hidden="true" tabindex="-1"></a>                     <span class="at">stats_cp =</span> <span class="st">"ci"</span>) <span class="sc">+</span> </span>
<span id="cb57-342"><a href="#cb57-342" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Significant interaction"</span>,</span>
<span id="cb57-343"><a href="#cb57-343" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"X2"</span>,</span>
<span id="cb57-344"><a href="#cb57-344" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Estimated coefficient for X1"</span>)</span>
<span id="cb57-345"><a href="#cb57-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-346"><a href="#cb57-346" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-347"><a href="#cb57-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-348"><a href="#cb57-348" aria-hidden="true" tabindex="-1"></a><span class="fu">## Qualitative predictors</span></span>
<span id="cb57-349"><a href="#cb57-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-350"><a href="#cb57-350" aria-hidden="true" tabindex="-1"></a><span class="fu">### Implementation of qualitative predictors</span></span>
<span id="cb57-351"><a href="#cb57-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-352"><a href="#cb57-352" aria-hidden="true" tabindex="-1"></a>As mentioned in @sec-first-order-two-preds, qualitative, as well as quantitative, predictor variables can be used in regression models.</span>
<span id="cb57-353"><a href="#cb57-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-354"><a href="#cb57-354" aria-hidden="true" tabindex="-1"></a>A qualitative variable with $c$ classes will be represented by $c - 1$ indicator variables, each taking on the values 0 and 1.</span>
<span id="cb57-355"><a href="#cb57-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-356"><a href="#cb57-356" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Need one less predictor variable to avoid linear dependency with the intercept term (see book for explanation).</span>
<span id="cb57-357"><a href="#cb57-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-358"><a href="#cb57-358" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Additionally, we use indicator variables (rather than allocated codes (e.g. one variable with levels 1, 2, 3 for the three levels)), make no assumptions about the spacing of the classes and rely on the data to show the differential effects that occur.</span>
<span id="cb57-359"><a href="#cb57-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-360"><a href="#cb57-360" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb57-361"><a href="#cb57-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-364"><a href="#cb57-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-365"><a href="#cb57-365" aria-hidden="true" tabindex="-1"></a><span class="co"># look at anova model (just to get the idea of how indicators are coded)</span></span>
<span id="cb57-366"><a href="#cb57-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-367"><a href="#cb57-367" aria-hidden="true" tabindex="-1"></a><span class="co"># investigate data</span></span>
<span id="cb57-368"><a href="#cb57-368" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; R dataset with two categorical variables (wool and tension) and one numeric response (breaks)</span></span>
<span id="cb57-369"><a href="#cb57-369" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; confirm numeric and look at number of levels for each X</span></span>
<span id="cb57-370"><a href="#cb57-370" aria-hidden="true" tabindex="-1"></a>datasets<span class="sc">::</span>warpbreaks <span class="sc">%&gt;%</span> glimpse</span>
<span id="cb57-371"><a href="#cb57-371" aria-hidden="true" tabindex="-1"></a>warpbreaks <span class="sc">%&gt;%</span> <span class="fu">map</span>(class)</span>
<span id="cb57-372"><a href="#cb57-372" aria-hidden="true" tabindex="-1"></a>warpbreaks <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="dv">1</span>) <span class="sc">%&gt;%</span> <span class="fu">map</span>(levels)</span>
<span id="cb57-373"><a href="#cb57-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-374"><a href="#cb57-374" aria-hidden="true" tabindex="-1"></a><span class="co"># view replication</span></span>
<span id="cb57-375"><a href="#cb57-375" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; it's a balanced design</span></span>
<span id="cb57-376"><a href="#cb57-376" aria-hidden="true" tabindex="-1"></a>warpbreaks <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="dv">1</span>) <span class="sc">%&gt;%</span> table</span>
<span id="cb57-377"><a href="#cb57-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-378"><a href="#cb57-378" aria-hidden="true" tabindex="-1"></a><span class="co"># design matrix via lm()</span></span>
<span id="cb57-379"><a href="#cb57-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-380"><a href="#cb57-380" aria-hidden="true" tabindex="-1"></a><span class="co"># specify model with only categorical predictor</span></span>
<span id="cb57-381"><a href="#cb57-381" aria-hidden="true" tabindex="-1"></a>mod_cat <span class="ot">&lt;-</span> <span class="fu">lm</span>(breaks <span class="sc">~</span> wool, warpbreaks, <span class="at">x =</span> <span class="cn">TRUE</span>)</span>
<span id="cb57-382"><a href="#cb57-382" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mod_cat)</span>
<span id="cb57-383"><a href="#cb57-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-384"><a href="#cb57-384" aria-hidden="true" tabindex="-1"></a><span class="co"># compare dataset to design matrix of indicator variables</span></span>
<span id="cb57-385"><a href="#cb57-385" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; .$model this just gives the dataset where the variables are pulled from</span></span>
<span id="cb57-386"><a href="#cb57-386" aria-hidden="true" tabindex="-1"></a>tmp <span class="ot">&lt;-</span> <span class="fu">cbind</span>(mod_cat<span class="sc">$</span>model, mod_cat<span class="sc">$</span>x[ , <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb57-387"><a href="#cb57-387" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">arrange</span>(tmp, breaks), <span class="at">n =</span> <span class="dv">10</span>)</span>
<span id="cb57-388"><a href="#cb57-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-389"><a href="#cb57-389" aria-hidden="true" tabindex="-1"></a><span class="co"># switch the default level</span></span>
<span id="cb57-390"><a href="#cb57-390" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; just needs to be the first level</span></span>
<span id="cb57-391"><a href="#cb57-391" aria-hidden="true" tabindex="-1"></a>mod_cat <span class="ot">&lt;-</span> warpbreaks <span class="sc">%&gt;%</span> </span>
<span id="cb57-392"><a href="#cb57-392" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">wool =</span> <span class="fu">factor</span>(wool, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"B"</span>,<span class="st">"A"</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb57-393"><a href="#cb57-393" aria-hidden="true" tabindex="-1"></a>  {<span class="fu">lm</span>(breaks <span class="sc">~</span> wool, <span class="at">data =</span> .)}</span>
<span id="cb57-394"><a href="#cb57-394" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mod_cat)</span>
<span id="cb57-395"><a href="#cb57-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-396"><a href="#cb57-396" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-397"><a href="#cb57-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-398"><a href="#cb57-398" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation of regression coefficients</span></span>
<span id="cb57-399"><a href="#cb57-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-400"><a href="#cb57-400" aria-hidden="true" tabindex="-1"></a>One predictor -- Two levels</span>
<span id="cb57-401"><a href="#cb57-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-402"><a href="#cb57-402" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Suppose we have the regression model:</span>
<span id="cb57-403"><a href="#cb57-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-404"><a href="#cb57-404" aria-hidden="true" tabindex="-1"></a>$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \epsilon_i$$</span>
<span id="cb57-405"><a href="#cb57-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-406"><a href="#cb57-406" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>where</span>
<span id="cb57-407"><a href="#cb57-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-408"><a href="#cb57-408" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-409"><a href="#cb57-409" aria-hidden="true" tabindex="-1"></a>X_{i1} = \text{quantitative predictor};<span class="sc">\\</span></span>
<span id="cb57-410"><a href="#cb57-410" aria-hidden="true" tabindex="-1"></a>X_{i2} =</span>
<span id="cb57-411"><a href="#cb57-411" aria-hidden="true" tabindex="-1"></a>  \left<span class="sc">\{</span></span>
<span id="cb57-412"><a href="#cb57-412" aria-hidden="true" tabindex="-1"></a>    \begin{array}{ll}</span>
<span id="cb57-413"><a href="#cb57-413" aria-hidden="true" tabindex="-1"></a>      0 &amp; \text{level 1}<span class="sc">\\</span></span>
<span id="cb57-414"><a href="#cb57-414" aria-hidden="true" tabindex="-1"></a>      1 &amp; \text{level 2}</span>
<span id="cb57-415"><a href="#cb57-415" aria-hidden="true" tabindex="-1"></a>    \end{array}</span>
<span id="cb57-416"><a href="#cb57-416" aria-hidden="true" tabindex="-1"></a>  \right.</span>
<span id="cb57-417"><a href="#cb57-417" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-418"><a href="#cb57-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-419"><a href="#cb57-419" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The response function for the model is</span>
<span id="cb57-420"><a href="#cb57-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-421"><a href="#cb57-421" aria-hidden="true" tabindex="-1"></a>$$E(Y) = \beta_0 + \beta_1 X_1 + \beta_2 X_2$$.</span>
<span id="cb57-422"><a href="#cb57-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-423"><a href="#cb57-423" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>To understand the meaning of regression coefficients in this model, we have to look at the model for the different levels of the categorical predictor.</span>
<span id="cb57-424"><a href="#cb57-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-425"><a href="#cb57-425" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Suppose we are looking at the model for level 1, where $X_2 = 0$. The response function becomes:</span>
<span id="cb57-426"><a href="#cb57-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-427"><a href="#cb57-427" aria-hidden="true" tabindex="-1"></a>$$E(Y) = \beta_0 + \beta_1 X_1 + \beta_2 (0) = \beta_0 + \beta_1 X_1 \hspace{10pt} \text{level 1}$$</span>
<span id="cb57-428"><a href="#cb57-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-429"><a href="#cb57-429" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>This response function is a straight line with $Y$ intercept $\beta_0$ and slope $\beta_1$.</span>
<span id="cb57-430"><a href="#cb57-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-431"><a href="#cb57-431" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For a level 2 observation, $X_2 = 1$. The response function becomes:</span>
<span id="cb57-432"><a href="#cb57-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-433"><a href="#cb57-433" aria-hidden="true" tabindex="-1"></a>$$E(Y) = \beta_0 + \beta_1 X_1 + \beta_2 (1) = (\beta_0 + \beta_2) + \beta_1 X_1 \hspace{10pt} \text{level 2}$$</span>
<span id="cb57-434"><a href="#cb57-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-435"><a href="#cb57-435" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>This response function is a also straight line, with the same slope  $\beta_1$, but with $Y$ intercept $\beta_0 + \beta_1$.</span>
<span id="cb57-436"><a href="#cb57-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-437"><a href="#cb57-437" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Thus $beta_2$ measures the differential effect between level 2 and level 1,</span>
<span id="cb57-438"><a href="#cb57-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-439"><a href="#cb57-439" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-440"><a href="#cb57-440" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb57-441"><a href="#cb57-441" aria-hidden="true" tabindex="-1"></a>\beta_0 &amp;= E(Y \mid X_2 = 0)<span class="sc">\\</span></span>
<span id="cb57-442"><a href="#cb57-442" aria-hidden="true" tabindex="-1"></a>\beta_2 &amp;= E(Y \mid X_2 = 1) - E(Y \mid X_2 = 0)</span>
<span id="cb57-443"><a href="#cb57-443" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb57-444"><a href="#cb57-444" aria-hidden="true" tabindex="-1"></a>$$  </span>
<span id="cb57-445"><a href="#cb57-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-446"><a href="#cb57-446" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Here is a visual of the two response functions.</span>
<span id="cb57-447"><a href="#cb57-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-448"><a href="#cb57-448" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/response-functions-quals.png)</span>{width="80%"}</span>
<span id="cb57-449"><a href="#cb57-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-450"><a href="#cb57-450" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>In general, $\beta_1$ shows how much higher (or lower) the mean response line is for the class coded 1 than the line for the class coded 0, for any given level of $X_1$</span>
<span id="cb57-451"><a href="#cb57-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-452"><a href="#cb57-452" aria-hidden="true" tabindex="-1"></a>One predictor -- More than two levels</span>
<span id="cb57-453"><a href="#cb57-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-454"><a href="#cb57-454" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The above logic and strategy can easily be extended to categorical predictors with more than 2 levels.</span>
<span id="cb57-455"><a href="#cb57-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-456"><a href="#cb57-456" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Suppose we have the model:</span>
<span id="cb57-457"><a href="#cb57-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-458"><a href="#cb57-458" aria-hidden="true" tabindex="-1"></a>$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \beta_2 X_{i2} + \epsilon_i$$</span>
<span id="cb57-459"><a href="#cb57-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-460"><a href="#cb57-460" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-461"><a href="#cb57-461" aria-hidden="true" tabindex="-1"></a>X_{i1} = \text{quantitative predictor};</span>
<span id="cb57-462"><a href="#cb57-462" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span></span>
<span id="cb57-463"><a href="#cb57-463" aria-hidden="true" tabindex="-1"></a>X_{i2} =</span>
<span id="cb57-464"><a href="#cb57-464" aria-hidden="true" tabindex="-1"></a>  \left<span class="sc">\{</span></span>
<span id="cb57-465"><a href="#cb57-465" aria-hidden="true" tabindex="-1"></a>    \begin{array}{ll}</span>
<span id="cb57-466"><a href="#cb57-466" aria-hidden="true" tabindex="-1"></a>      1 &amp; \text{level 2}<span class="sc">\\</span></span>
<span id="cb57-467"><a href="#cb57-467" aria-hidden="true" tabindex="-1"></a>      0 &amp; \text{otherwise}</span>
<span id="cb57-468"><a href="#cb57-468" aria-hidden="true" tabindex="-1"></a>    \end{array}</span>
<span id="cb57-469"><a href="#cb57-469" aria-hidden="true" tabindex="-1"></a>  \right.;</span>
<span id="cb57-470"><a href="#cb57-470" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span></span>
<span id="cb57-471"><a href="#cb57-471" aria-hidden="true" tabindex="-1"></a>X_{i3} =</span>
<span id="cb57-472"><a href="#cb57-472" aria-hidden="true" tabindex="-1"></a>  \left<span class="sc">\{</span></span>
<span id="cb57-473"><a href="#cb57-473" aria-hidden="true" tabindex="-1"></a>    \begin{array}{ll}</span>
<span id="cb57-474"><a href="#cb57-474" aria-hidden="true" tabindex="-1"></a>      1 &amp; \text{level 3}<span class="sc">\\</span></span>
<span id="cb57-475"><a href="#cb57-475" aria-hidden="true" tabindex="-1"></a>      0 &amp; \text{otherwise}</span>
<span id="cb57-476"><a href="#cb57-476" aria-hidden="true" tabindex="-1"></a>    \end{array}</span>
<span id="cb57-477"><a href="#cb57-477" aria-hidden="true" tabindex="-1"></a>  \right.</span>
<span id="cb57-478"><a href="#cb57-478" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-479"><a href="#cb57-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-480"><a href="#cb57-480" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Now $\beta_3 = E(Y \mid X_2 = 0, X_3 = 1) - E(Y \mid X_2 = 0, X_3 = 0)$</span>
<span id="cb57-481"><a href="#cb57-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-482"><a href="#cb57-482" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We may wish to estimate differential effects other than against the default zero level. This can be done by estimating differences between regression coefficients, say if there are 3 levels and we want to compare level 3 to level 2:</span>
<span id="cb57-483"><a href="#cb57-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-484"><a href="#cb57-484" aria-hidden="true" tabindex="-1"></a>$$\beta_3 - \beta_2 = E(Y \mid X_2 = 0, X_3 = 1) - E(Y \mid X_2 = 1, X_3 = 0)$$</span>
<span id="cb57-485"><a href="#cb57-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-486"><a href="#cb57-486" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>This now measures the differential effect (how much higher or lower the response functioni is) of level 3 relative to level 2.</span>
<span id="cb57-487"><a href="#cb57-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-488"><a href="#cb57-488" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The point estimator of this quantity is, of course, $\hat{\beta}_3 - \hat{\beta}_2$, and the estimated variance of this estimator is</span>
<span id="cb57-489"><a href="#cb57-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-490"><a href="#cb57-490" aria-hidden="true" tabindex="-1"></a>$$s^2<span class="sc">\{</span>\hat{\beta}_3 - \hat{\beta}_2\} = s^2\{\hat{\beta}_3\} + s^2\{\hat{\beta}_2\} - 2 s\{\hat{\beta}_3,\hat{\beta}_2<span class="sc">\}</span>$$</span>
<span id="cb57-491"><a href="#cb57-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-492"><a href="#cb57-492" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(add variances and two times covariance, but minus). The needed variances and covariance can be readily ob'tained from the estimated variance-covariance matrix of the regression coefficients.</span>
<span id="cb57-493"><a href="#cb57-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-494"><a href="#cb57-494" aria-hidden="true" tabindex="-1"></a>Demo of design matrix intepretation</span>
<span id="cb57-495"><a href="#cb57-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-498"><a href="#cb57-498" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-499"><a href="#cb57-499" aria-hidden="true" tabindex="-1"></a><span class="co"># again, look at design matrix via lm() for more than two categories</span></span>
<span id="cb57-500"><a href="#cb57-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-501"><a href="#cb57-501" aria-hidden="true" tabindex="-1"></a><span class="co"># specify model with only categorical predictor</span></span>
<span id="cb57-502"><a href="#cb57-502" aria-hidden="true" tabindex="-1"></a>mod_cat2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(breaks <span class="sc">~</span> tension, warpbreaks, <span class="at">x =</span> <span class="cn">TRUE</span>)</span>
<span id="cb57-503"><a href="#cb57-503" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mod_cat2)</span>
<span id="cb57-504"><a href="#cb57-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-505"><a href="#cb57-505" aria-hidden="true" tabindex="-1"></a><span class="co"># compare dataset to design matrix of indicator variables</span></span>
<span id="cb57-506"><a href="#cb57-506" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; .$model this just gives the dataset where the variables are pulled from</span></span>
<span id="cb57-507"><a href="#cb57-507" aria-hidden="true" tabindex="-1"></a>tmp2 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(mod_cat2<span class="sc">$</span>model, mod_cat2<span class="sc">$</span>x[ , <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb57-508"><a href="#cb57-508" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">arrange</span>(tmp2, breaks), <span class="at">n =</span> <span class="dv">10</span>)</span>
<span id="cb57-509"><a href="#cb57-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-510"><a href="#cb57-510" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-511"><a href="#cb57-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-512"><a href="#cb57-512" aria-hidden="true" tabindex="-1"></a>Demo of modeling with first order quantitative and qualitative predictors</span>
<span id="cb57-513"><a href="#cb57-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-516"><a href="#cb57-516" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-517"><a href="#cb57-517" aria-hidden="true" tabindex="-1"></a><span class="co"># now use data with continuous predictor</span></span>
<span id="cb57-518"><a href="#cb57-518" aria-hidden="true" tabindex="-1"></a>mod_both <span class="ot">&lt;-</span> <span class="fu">lm</span>(Petal.Length <span class="sc">~</span> Petal.Width <span class="sc">+</span> Species, iris, <span class="at">x =</span> <span class="cn">TRUE</span>)</span>
<span id="cb57-519"><a href="#cb57-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-520"><a href="#cb57-520" aria-hidden="true" tabindex="-1"></a><span class="co"># plot three different response functions</span></span>
<span id="cb57-521"><a href="#cb57-521" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; first get all points on there so zoom is correct</span></span>
<span id="cb57-522"><a href="#cb57-522" aria-hidden="true" tabindex="-1"></a>iris <span class="sc">%$%</span> <span class="fu">plot</span>(<span class="at">x =</span> Petal.Width, <span class="at">y =</span> Petal.Length, <span class="at">main =</span> <span class="st">"Constant slope, different intercepts"</span>)</span>
<span id="cb57-523"><a href="#cb57-523" aria-hidden="true" tabindex="-1"></a>iris <span class="sc">%&gt;%</span> </span>
<span id="cb57-524"><a href="#cb57-524" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Species <span class="sc">==</span> <span class="st">"setosa"</span>) <span class="sc">%$%</span> </span>
<span id="cb57-525"><a href="#cb57-525" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(<span class="at">x =</span> Petal.Width, <span class="at">y =</span> Petal.Length, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb57-526"><a href="#cb57-526" aria-hidden="true" tabindex="-1"></a>iris <span class="sc">%&gt;%</span> </span>
<span id="cb57-527"><a href="#cb57-527" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Species <span class="sc">==</span> <span class="st">"versicolor"</span>) <span class="sc">%$%</span> </span>
<span id="cb57-528"><a href="#cb57-528" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(<span class="at">x =</span> Petal.Width, <span class="at">y =</span> Petal.Length, <span class="at">col =</span> <span class="st">"green"</span>)</span>
<span id="cb57-529"><a href="#cb57-529" aria-hidden="true" tabindex="-1"></a>iris <span class="sc">%&gt;%</span> </span>
<span id="cb57-530"><a href="#cb57-530" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Species <span class="sc">==</span> <span class="st">"virginica"</span>) <span class="sc">%$%</span> </span>
<span id="cb57-531"><a href="#cb57-531" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(<span class="at">x =</span> Petal.Width, <span class="at">y =</span> Petal.Length, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb57-532"><a href="#cb57-532" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fu">coef</span>(mod_both)[<span class="dv">1</span>], <span class="at">b =</span> <span class="fu">coef</span>(mod_both)[<span class="dv">2</span>], <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb57-533"><a href="#cb57-533" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fu">sum</span>(<span class="fu">coef</span>(mod_both)[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)]), <span class="at">b =</span> <span class="fu">coef</span>(mod_both)[<span class="dv">2</span>], <span class="at">col =</span> <span class="st">"green"</span>)</span>
<span id="cb57-534"><a href="#cb57-534" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fu">sum</span>(<span class="fu">coef</span>(mod_both)[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span>)]), <span class="at">b =</span> <span class="fu">coef</span>(mod_both)[<span class="dv">2</span>], <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb57-535"><a href="#cb57-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-536"><a href="#cb57-536" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-537"><a href="#cb57-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-538"><a href="#cb57-538" aria-hidden="true" tabindex="-1"></a>Now test on levels coefficients' relative to other than the base level.</span>
<span id="cb57-539"><a href="#cb57-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-542"><a href="#cb57-542" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-543"><a href="#cb57-543" aria-hidden="true" tabindex="-1"></a><span class="co"># tests on coefficients (different intercepts)</span></span>
<span id="cb57-544"><a href="#cb57-544" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mod_both)</span>
<span id="cb57-545"><a href="#cb57-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-546"><a href="#cb57-546" aria-hidden="true" tabindex="-1"></a><span class="co"># both the latter two specied have different heights of there regression functions based on the t-tests of beta2 and beta3 (relative to beta1)</span></span>
<span id="cb57-547"><a href="#cb57-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-548"><a href="#cb57-548" aria-hidden="true" tabindex="-1"></a><span class="co"># verify standard errors for t tests using matrix results</span></span>
<span id="cb57-549"><a href="#cb57-549" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> mod_both<span class="sc">$</span>x</span>
<span id="cb57-550"><a href="#cb57-550" aria-hidden="true" tabindex="-1"></a>varcov_beta <span class="ot">&lt;-</span> <span class="fu">glance</span>(mod_both)<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X)</span>
<span id="cb57-551"><a href="#cb57-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-552"><a href="#cb57-552" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(mod_both <span class="sc">%&gt;%</span> tidy <span class="sc">%&gt;%</span> <span class="fu">pull</span>(std.error), varcov_beta <span class="sc">%&gt;%</span> diag <span class="sc">%&gt;%</span> sqrt)</span>
<span id="cb57-553"><a href="#cb57-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-554"><a href="#cb57-554" aria-hidden="true" tabindex="-1"></a><span class="co"># test beta3 - beta2</span></span>
<span id="cb57-555"><a href="#cb57-555" aria-hidden="true" tabindex="-1"></a>beta3_beta2_hat <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_both)[<span class="dv">4</span>] <span class="sc">-</span> <span class="fu">coef</span>(mod_both)[<span class="dv">3</span>])</span>
<span id="cb57-556"><a href="#cb57-556" aria-hidden="true" tabindex="-1"></a>beta3_beta2_hat_se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(varcov_beta)[<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]) <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>varcov_beta[<span class="dv">4</span>,<span class="dv">3</span>])</span>
<span id="cb57-557"><a href="#cb57-557" aria-hidden="true" tabindex="-1"></a>t_star <span class="ot">&lt;-</span> beta3_beta2_hat <span class="sc">/</span> beta3_beta2_hat_se</span>
<span id="cb57-558"><a href="#cb57-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-559"><a href="#cb57-559" aria-hidden="true" tabindex="-1"></a><span class="co"># verify by changing the default level and checking t-stat</span></span>
<span id="cb57-560"><a href="#cb57-560" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; need 2 to be the default</span></span>
<span id="cb57-561"><a href="#cb57-561" aria-hidden="true" tabindex="-1"></a>mod_both2 <span class="ot">&lt;-</span> iris <span class="sc">%&gt;%</span> </span>
<span id="cb57-562"><a href="#cb57-562" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Species =</span> <span class="fu">factor</span>(Species, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"versicolor"</span>, <span class="st">"setosa"</span>, <span class="st">"virginica"</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb57-563"><a href="#cb57-563" aria-hidden="true" tabindex="-1"></a>  {<span class="fu">lm</span>(Petal.Length <span class="sc">~</span> Petal.Width <span class="sc">+</span> Species, .)}</span>
<span id="cb57-564"><a href="#cb57-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-565"><a href="#cb57-565" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">tidy</span>(mod_both2) <span class="sc">%&gt;%</span> <span class="fu">filter</span>(term <span class="sc">==</span> <span class="st">"Speciesvirginica"</span>) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(statistic), t_star)</span>
<span id="cb57-566"><a href="#cb57-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-567"><a href="#cb57-567" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-568"><a href="#cb57-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-569"><a href="#cb57-569" aria-hidden="true" tabindex="-1"></a>Fitting one line instead of two</span>
<span id="cb57-570"><a href="#cb57-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-571"><a href="#cb57-571" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Fitting one line, as opposed to separate regression for each category, is the preferred method because of two reasons:</span>
<span id="cb57-572"><a href="#cb57-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-573"><a href="#cb57-573" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Since the model assumes equal slopes and the same constant error term variance for each type of firm, the common slope $\beta_1$ can best be estimated by pooling the two levels.</span>
<span id="cb57-574"><a href="#cb57-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-575"><a href="#cb57-575" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Also, other inferences, such as for $\beta_0$ and $\beta_2$, can be made more precisely by working with one regression model containing an indicator variable since more degrees of freedom will then be associated with $MSE$.</span>
<span id="cb57-576"><a href="#cb57-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-577"><a href="#cb57-577" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>More is said about this strategy in @sec-misc-topics-quals.</span>
<span id="cb57-578"><a href="#cb57-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-579"><a href="#cb57-579" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modeling interactions between quantitative and qualitative predictors</span></span>
<span id="cb57-580"><a href="#cb57-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-581"><a href="#cb57-581" aria-hidden="true" tabindex="-1"></a>Setup</span>
<span id="cb57-582"><a href="#cb57-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-583"><a href="#cb57-583" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Suppose we have the model below. Even though one of the predictor variables in the regression model is qualitative, interaction effects can still be introduced into the model in the usual manner, by including cross-product terms.</span>
<span id="cb57-584"><a href="#cb57-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-585"><a href="#cb57-585" aria-hidden="true" tabindex="-1"></a>$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \beta_3 X_{i1} X_{i2} +\epsilon_i$$</span>
<span id="cb57-586"><a href="#cb57-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-587"><a href="#cb57-587" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>where</span>
<span id="cb57-588"><a href="#cb57-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-589"><a href="#cb57-589" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-590"><a href="#cb57-590" aria-hidden="true" tabindex="-1"></a>X_{i1} = \text{quantitative predictor}<span class="sc">\\</span></span>
<span id="cb57-591"><a href="#cb57-591" aria-hidden="true" tabindex="-1"></a>X_{i2} =</span>
<span id="cb57-592"><a href="#cb57-592" aria-hidden="true" tabindex="-1"></a>  \left<span class="sc">\{</span></span>
<span id="cb57-593"><a href="#cb57-593" aria-hidden="true" tabindex="-1"></a>    \begin{array}{ll}</span>
<span id="cb57-594"><a href="#cb57-594" aria-hidden="true" tabindex="-1"></a>      0 &amp; \text{level 1}<span class="sc">\\</span></span>
<span id="cb57-595"><a href="#cb57-595" aria-hidden="true" tabindex="-1"></a>      1 &amp; \text{level 2}</span>
<span id="cb57-596"><a href="#cb57-596" aria-hidden="true" tabindex="-1"></a>    \end{array}</span>
<span id="cb57-597"><a href="#cb57-597" aria-hidden="true" tabindex="-1"></a>  \right.</span>
<span id="cb57-598"><a href="#cb57-598" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-599"><a href="#cb57-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-600"><a href="#cb57-600" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The response function of the model is:</span>
<span id="cb57-601"><a href="#cb57-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-602"><a href="#cb57-602" aria-hidden="true" tabindex="-1"></a>$$E(Y_i) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2$$</span>
<span id="cb57-603"><a href="#cb57-603" aria-hidden="true" tabindex="-1"></a>Meaning of regression coefficients</span>
<span id="cb57-604"><a href="#cb57-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-605"><a href="#cb57-605" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Again, the meaning of the regression coefficients in response function above can best be understood by examining the nature of this function for each level.</span>
<span id="cb57-606"><a href="#cb57-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-607"><a href="#cb57-607" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For level 1, $X_2 = 0$ and thus $X_1 X_2 = 0$, so </span>
<span id="cb57-608"><a href="#cb57-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-609"><a href="#cb57-609" aria-hidden="true" tabindex="-1"></a>$$E(Y_i) = \beta_0 + \beta_1 X_1 + \beta_2 (0) + \beta_3 (0) = \beta_0 + \beta_1 X_1 \hspace{20pt} \text{level 1}$$</span>
<span id="cb57-610"><a href="#cb57-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-611"><a href="#cb57-611" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>This has intercept $\beta_0$ and slope $\beta_1$.</span>
<span id="cb57-612"><a href="#cb57-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-613"><a href="#cb57-613" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For level 2, $X_2 = 1$ and thus $X_1 X_2 = X_1$, so </span>
<span id="cb57-614"><a href="#cb57-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-615"><a href="#cb57-615" aria-hidden="true" tabindex="-1"></a>$$E(Y_i) = \beta_0 + \beta_1 X_1 + \beta_2 (1) + \beta_3 X_1 = (\beta_0 + \beta_2) + (\beta_1 + \beta_3) X_1 \hspace{20pt} \text{level 2}$$</span>
<span id="cb57-616"><a href="#cb57-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-617"><a href="#cb57-617" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>This has intercept $\beta_0 + \beta_2$ and slope $\beta_1 + \beta_3$.</span>
<span id="cb57-618"><a href="#cb57-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-619"><a href="#cb57-619" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We see that $\beta_2$ here indicates how much greater (or smaller) is the $Y$ intercept of the response function for the class coded 1 than that for the class coded O. Similarly, $\beta_3$ indicates how much greater (or smaller) is the slope of the response function for the class coded 1 than that for the class coded O.</span>
<span id="cb57-620"><a href="#cb57-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-621"><a href="#cb57-621" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Because both the intercept and the slope differ for the two classes in regression model, it is no longer true that $\beta_2$ indicates how much higher (or lower) one response function is than the other for any given level of $X_1$.</span>
<span id="cb57-622"><a href="#cb57-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-623"><a href="#cb57-623" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Thus, when interaction effects are present, the effect of the qualitative predictor variable can be studied only by comparing the regression functions within the scope of the model for the different classes of the qualitative variable.</span>
<span id="cb57-624"><a href="#cb57-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-625"><a href="#cb57-625" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/qualitative-interaction-effects.png)</span>{width="80%"}</span>
<span id="cb57-626"><a href="#cb57-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-627"><a href="#cb57-627" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When one of the predictor variables is qualitative and the other quantitative, nonparallel response functions that do not intersect within the scope of the model are sometimes said to represent an *ordinal interaction*. When the response functions intersect within the scope of the model, the interaction is then said to be a *disordinal interaction*.</span>
<span id="cb57-628"><a href="#cb57-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-629"><a href="#cb57-629" aria-hidden="true" tabindex="-1"></a>Testing interaction effects</span>
<span id="cb57-630"><a href="#cb57-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-631"><a href="#cb57-631" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Fitting the previous regression model yields the same response functions as would fitting separate regressions for level 1 and level 2. An advantage of using this model with an indicator variable is that one regression run will yield both fitted regressions.</span>
<span id="cb57-632"><a href="#cb57-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-633"><a href="#cb57-633" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Another advantage is that tests for comparing the regression functions for the different classes of the qualitative variable can be clearly seen to involve tests of regression coefficients in a general linear model.</span>
<span id="cb57-634"><a href="#cb57-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-635"><a href="#cb57-635" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>For example we can do two tests: one on just the slopes and another of if the entire regression lines are identical.</span>
<span id="cb57-636"><a href="#cb57-636" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-637"><a href="#cb57-637" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-638"><a href="#cb57-638" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb57-639"><a href="#cb57-639" aria-hidden="true" tabindex="-1"></a>  \text{Test on slopes}<span class="sc">\\</span></span>
<span id="cb57-640"><a href="#cb57-640" aria-hidden="true" tabindex="-1"></a>  \ho&amp;: \beta_3 = 0<span class="sc">\\</span></span>
<span id="cb57-641"><a href="#cb57-641" aria-hidden="true" tabindex="-1"></a>  \ha&amp;: \beta_3 \ne 0<span class="sc">\\</span></span>
<span id="cb57-642"><a href="#cb57-642" aria-hidden="true" tabindex="-1"></a>  \text{Test on entire regression line}<span class="sc">\\</span></span>
<span id="cb57-643"><a href="#cb57-643" aria-hidden="true" tabindex="-1"></a>  \ho&amp;: \beta_2 = \beta_3 = 0<span class="sc">\\</span></span>
<span id="cb57-644"><a href="#cb57-644" aria-hidden="true" tabindex="-1"></a>  \ha&amp;: \text{not both } \beta_2 = 0 \text{ and } \beta_3 = 0</span>
<span id="cb57-645"><a href="#cb57-645" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb57-646"><a href="#cb57-646" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb57-647"><a href="#cb57-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-648"><a href="#cb57-648" aria-hidden="true" tabindex="-1"></a>Demo of design matrix interpretation and how constructed with interaction effects</span>
<span id="cb57-649"><a href="#cb57-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-652"><a href="#cb57-652" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-653"><a href="#cb57-653" aria-hidden="true" tabindex="-1"></a><span class="co"># specify each term individual -&gt; A + B + AB</span></span>
<span id="cb57-654"><a href="#cb57-654" aria-hidden="true" tabindex="-1"></a>mod_cat3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(breaks <span class="sc">~</span> wool <span class="sc">+</span> tension <span class="sc">+</span> wool <span class="sc">:</span> tension, <span class="at">data =</span> warpbreaks, <span class="at">x =</span> <span class="cn">TRUE</span>)</span>
<span id="cb57-655"><a href="#cb57-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-656"><a href="#cb57-656" aria-hidden="true" tabindex="-1"></a><span class="co"># equivalent shorthand notation to cross factors</span></span>
<span id="cb57-657"><a href="#cb57-657" aria-hidden="true" tabindex="-1"></a>mod_cat3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(breaks <span class="sc">~</span> wool <span class="sc">*</span> tension, <span class="at">data =</span> warpbreaks, <span class="at">x =</span> <span class="cn">TRUE</span>)</span>
<span id="cb57-658"><a href="#cb57-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-659"><a href="#cb57-659" aria-hidden="true" tabindex="-1"></a><span class="co"># extract design matrix</span></span>
<span id="cb57-660"><a href="#cb57-660" aria-hidden="true" tabindex="-1"></a>X_lm <span class="ot">&lt;-</span> mod_cat3<span class="sc">$</span>x</span>
<span id="cb57-661"><a href="#cb57-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-662"><a href="#cb57-662" aria-hidden="true" tabindex="-1"></a><span class="co"># check how to read indicators (ignoring replication)</span></span>
<span id="cb57-663"><a href="#cb57-663" aria-hidden="true" tabindex="-1"></a>warpbreaks <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="dv">1</span>) <span class="sc">%&gt;%</span> <span class="fu">bind_cols</span>(X_lm) <span class="sc">%&gt;%</span> unique</span>
<span id="cb57-664"><a href="#cb57-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-665"><a href="#cb57-665" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; R has levels - 1 indicators for each categorical variable</span></span>
<span id="cb57-666"><a href="#cb57-666" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; the "dropped" base level also isn't explicitly included in any interaction indicator terms</span></span>
<span id="cb57-667"><a href="#cb57-667" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; so interactions are taken into account with zeros for actual interactions terms and 0 or 1 for the second factor</span></span>
<span id="cb57-668"><a href="#cb57-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-669"><a href="#cb57-669" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-670"><a href="#cb57-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-671"><a href="#cb57-671" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>All higher order terms involving the base level are also dropped.</span>
<span id="cb57-672"><a href="#cb57-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-673"><a href="#cb57-673" aria-hidden="true" tabindex="-1"></a>Demo to visualize model with interactions</span>
<span id="cb57-674"><a href="#cb57-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-677"><a href="#cb57-677" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-678"><a href="#cb57-678" aria-hidden="true" tabindex="-1"></a><span class="co"># now use data with continuous predictor</span></span>
<span id="cb57-679"><a href="#cb57-679" aria-hidden="true" tabindex="-1"></a>mod_both_int <span class="ot">&lt;-</span> <span class="fu">lm</span>(Petal.Length <span class="sc">~</span> Petal.Width <span class="sc">*</span> Species, iris)</span>
<span id="cb57-680"><a href="#cb57-680" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_both_int)</span>
<span id="cb57-681"><a href="#cb57-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-682"><a href="#cb57-682" aria-hidden="true" tabindex="-1"></a><span class="co"># plot three different response functions</span></span>
<span id="cb57-683"><a href="#cb57-683" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; first get all points on there so zoom is correct</span></span>
<span id="cb57-684"><a href="#cb57-684" aria-hidden="true" tabindex="-1"></a>iris <span class="sc">%$%</span> <span class="fu">plot</span>(<span class="at">x =</span> Petal.Width, <span class="at">y =</span> Petal.Length, <span class="at">main =</span> <span class="st">"Different regression lines (different intercepts and slopes)"</span>)</span>
<span id="cb57-685"><a href="#cb57-685" aria-hidden="true" tabindex="-1"></a>iris <span class="sc">%&gt;%</span> </span>
<span id="cb57-686"><a href="#cb57-686" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Species <span class="sc">==</span> <span class="st">"setosa"</span>) <span class="sc">%$%</span> </span>
<span id="cb57-687"><a href="#cb57-687" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(<span class="at">x =</span> Petal.Width, <span class="at">y =</span> Petal.Length, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb57-688"><a href="#cb57-688" aria-hidden="true" tabindex="-1"></a>iris <span class="sc">%&gt;%</span> </span>
<span id="cb57-689"><a href="#cb57-689" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Species <span class="sc">==</span> <span class="st">"versicolor"</span>) <span class="sc">%$%</span> </span>
<span id="cb57-690"><a href="#cb57-690" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(<span class="at">x =</span> Petal.Width, <span class="at">y =</span> Petal.Length, <span class="at">col =</span> <span class="st">"green"</span>)</span>
<span id="cb57-691"><a href="#cb57-691" aria-hidden="true" tabindex="-1"></a>iris <span class="sc">%&gt;%</span> </span>
<span id="cb57-692"><a href="#cb57-692" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Species <span class="sc">==</span> <span class="st">"virginica"</span>) <span class="sc">%$%</span> </span>
<span id="cb57-693"><a href="#cb57-693" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(<span class="at">x =</span> Petal.Width, <span class="at">y =</span> Petal.Length, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb57-694"><a href="#cb57-694" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fu">coef</span>(mod_both_int)[<span class="dv">1</span>], <span class="at">b =</span> <span class="fu">coef</span>(mod_both_int)[<span class="dv">2</span>], <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb57-695"><a href="#cb57-695" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fu">sum</span>(<span class="fu">coef</span>(mod_both_int)[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)]), <span class="at">b =</span> <span class="fu">sum</span>(<span class="fu">coef</span>(mod_both_int)[<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">5</span>)]), <span class="at">col =</span> <span class="st">"green"</span>)</span>
<span id="cb57-696"><a href="#cb57-696" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fu">sum</span>(<span class="fu">coef</span>(mod_both_int)[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span>)]), <span class="at">b =</span> <span class="fu">sum</span>(<span class="fu">coef</span>(mod_both_int)[<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">6</span>)]), <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb57-697"><a href="#cb57-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-698"><a href="#cb57-698" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to ggplot</span></span>
<span id="cb57-699"><a href="#cb57-699" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> iris,</span>
<span id="cb57-700"><a href="#cb57-700" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> Petal.Width,</span>
<span id="cb57-701"><a href="#cb57-701" aria-hidden="true" tabindex="-1"></a>           <span class="at">y =</span> Petal.Length)) <span class="sc">+</span> </span>
<span id="cb57-702"><a href="#cb57-702" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> Species)) <span class="sc">+</span> </span>
<span id="cb57-703"><a href="#cb57-703" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">color =</span> Species),</span>
<span id="cb57-704"><a href="#cb57-704" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">FALSE</span>,</span>
<span id="cb57-705"><a href="#cb57-705" aria-hidden="true" tabindex="-1"></a>              <span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb57-706"><a href="#cb57-706" aria-hidden="true" tabindex="-1"></a>              <span class="at">fullrange =</span> <span class="cn">TRUE</span>)</span>
<span id="cb57-707"><a href="#cb57-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-708"><a href="#cb57-708" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-709"><a href="#cb57-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-712"><a href="#cb57-712" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-713"><a href="#cb57-713" aria-hidden="true" tabindex="-1"></a><span class="co"># test if only slopes are different</span></span>
<span id="cb57-714"><a href="#cb57-714" aria-hidden="true" tabindex="-1"></a>mod_full <span class="ot">&lt;-</span> mod_both_int</span>
<span id="cb57-715"><a href="#cb57-715" aria-hidden="true" tabindex="-1"></a>mod_reduced <span class="ot">&lt;-</span> mod_both</span>
<span id="cb57-716"><a href="#cb57-716" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_full, mod_reduced)</span>
<span id="cb57-717"><a href="#cb57-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-718"><a href="#cb57-718" aria-hidden="true" tabindex="-1"></a><span class="co"># test if entire regression lines are different</span></span>
<span id="cb57-719"><a href="#cb57-719" aria-hidden="true" tabindex="-1"></a>mod_full <span class="ot">&lt;-</span> mod_both_int</span>
<span id="cb57-720"><a href="#cb57-720" aria-hidden="true" tabindex="-1"></a>mod_reduced <span class="ot">&lt;-</span> <span class="fu">update</span>(mod_both, . <span class="sc">~</span> . <span class="sc">-</span>Species)</span>
<span id="cb57-721"><a href="#cb57-721" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_full, mod_reduced)</span>
<span id="cb57-722"><a href="#cb57-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-723"><a href="#cb57-723" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-724"><a href="#cb57-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-725"><a href="#cb57-725" aria-hidden="true" tabindex="-1"></a><span class="fu">### Miscellaneous topics with qualitative predictors {#sec-misc-topics-quals}</span></span>
<span id="cb57-726"><a href="#cb57-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-727"><a href="#cb57-727" aria-hidden="true" tabindex="-1"></a>Qualitative predictors only</span>
<span id="cb57-728"><a href="#cb57-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-729"><a href="#cb57-729" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Regression models containing only qualitative predictor variables can also be constructed.</span>
<span id="cb57-730"><a href="#cb57-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-731"><a href="#cb57-731" aria-hidden="true" tabindex="-1"></a><span class="ss">     - </span>Models in which all explanatory variables are qualitative are called *analysis of variance models (ANOVA)*.</span>
<span id="cb57-732"><a href="#cb57-732" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb57-733"><a href="#cb57-733" aria-hidden="true" tabindex="-1"></a><span class="ss">     - </span>Models containing some quantitative and some qualitative explanatory variables, where the chief explanatory variables of interest are qualitative and the quantitative variables are introduced primarily to reduce the variance of the error terms, are called *analysis of covariance models (ANCOVA)*.</span>
<span id="cb57-734"><a href="#cb57-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-735"><a href="#cb57-735" aria-hidden="true" tabindex="-1"></a>Indicator variables vs quantitative variables</span>
<span id="cb57-736"><a href="#cb57-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-737"><a href="#cb57-737" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Indicator variables can be used even if the predictor variable is quantitative. </span>
<span id="cb57-738"><a href="#cb57-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-739"><a href="#cb57-739" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>For instance, the quantitative variable age may be transformed by grouping ages into classes such as under 21, 21-34, 35-49, etc. Indicator variables are then used for the classes of this new predictor variable. </span>
<span id="cb57-740"><a href="#cb57-740" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-741"><a href="#cb57-741" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>This is called *discretizing* the variable.</span>
<span id="cb57-742"><a href="#cb57-742" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-743"><a href="#cb57-743" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>At first sight, this may seem to be a questionable approach because information about the actual ages is thrown away. Furthermore, additional parameters are placed into the model, which leads to a reduction of the degrees of freedom associated with $MSE$. Nevertheless, there are occasions when replacement of a quantitative variable by indicator variables may be appropriate.</span>
<span id="cb57-744"><a href="#cb57-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-745"><a href="#cb57-745" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For large data sets, use of indicator variables can serve as an alternative to lowess and other nonparametric fits of the response function.</span>
<span id="cb57-746"><a href="#cb57-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-747"><a href="#cb57-747" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Cost: For say 1000 observations, the loss of 10 or 20 degrees of freedom is immaterial.</span>
<span id="cb57-748"><a href="#cb57-748" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-749"><a href="#cb57-749" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Gain: If you are very much in doubt about the shape of the regression function, which could be highly complex, you could utilize the indicator variable approach in order to obtain information about the shape ofthe response function without making any assumptions about its functional form (not assuming linear or quadratic for example).</span>
<span id="cb57-750"><a href="#cb57-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-751"><a href="#cb57-751" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb57-752"><a href="#cb57-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-755"><a href="#cb57-755" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb57-756"><a href="#cb57-756" aria-hidden="true" tabindex="-1"></a><span class="co"># plot data</span></span>
<span id="cb57-757"><a href="#cb57-757" aria-hidden="true" tabindex="-1"></a>diamonds <span class="sc">%$%</span> <span class="fu">plot</span>(<span class="at">x =</span> carat, <span class="at">y =</span> price)</span>
<span id="cb57-758"><a href="#cb57-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-759"><a href="#cb57-759" aria-hidden="true" tabindex="-1"></a><span class="co"># fit linear model to see</span></span>
<span id="cb57-760"><a href="#cb57-760" aria-hidden="true" tabindex="-1"></a>mod_linear <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> carat, diamonds)</span>
<span id="cb57-761"><a href="#cb57-761" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod_linear, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb57-762"><a href="#cb57-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-763"><a href="#cb57-763" aria-hidden="true" tabindex="-1"></a><span class="co"># think a more complex function would be better</span></span>
<span id="cb57-764"><a href="#cb57-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-765"><a href="#cb57-765" aria-hidden="true" tabindex="-1"></a><span class="co"># discretize x variable and fit model with indicator variables</span></span>
<span id="cb57-766"><a href="#cb57-766" aria-hidden="true" tabindex="-1"></a>mod_discretized <span class="ot">&lt;-</span> <span class="fu">lm</span>(diamonds<span class="sc">$</span>price <span class="sc">~</span> <span class="fu">as.factor</span>(<span class="fu">cut_number</span>(diamonds<span class="sc">$</span>carat, <span class="at">n =</span> <span class="dv">10</span>)))</span>
<span id="cb57-767"><a href="#cb57-767" aria-hidden="true" tabindex="-1"></a>mod_discretized <span class="sc">%&gt;%</span> tidy</span>
<span id="cb57-768"><a href="#cb57-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-769"><a href="#cb57-769" aria-hidden="true" tabindex="-1"></a><span class="co"># fully discretize model</span></span>
<span id="cb57-770"><a href="#cb57-770" aria-hidden="true" tabindex="-1"></a>mod_full_discretized <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> <span class="fu">as.factor</span>(diamonds<span class="sc">$</span>carat), diamonds)</span>
<span id="cb57-771"><a href="#cb57-771" aria-hidden="true" tabindex="-1"></a>mod_full_discretized <span class="sc">%&gt;%</span> tidy <span class="sc">%&gt;%</span> nrow</span>
<span id="cb57-772"><a href="#cb57-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-773"><a href="#cb57-773" aria-hidden="true" tabindex="-1"></a><span class="co"># add complex models to plot for comparison</span></span>
<span id="cb57-774"><a href="#cb57-774" aria-hidden="true" tabindex="-1"></a>diamonds <span class="sc">%$%</span> <span class="fu">plot</span>(<span class="at">x =</span> carat, <span class="at">y =</span> price)</span>
<span id="cb57-775"><a href="#cb57-775" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod_linear, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb57-776"><a href="#cb57-776" aria-hidden="true" tabindex="-1"></a>diamonds <span class="sc">%&gt;%</span> </span>
<span id="cb57-777"><a href="#cb57-777" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">x =</span> mod_discretized, <span class="at">data =</span> .) <span class="sc">%&gt;%</span> </span>
<span id="cb57-778"><a href="#cb57-778" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(carat) <span class="sc">%$%</span> </span>
<span id="cb57-779"><a href="#cb57-779" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="at">x =</span> carat, <span class="at">y =</span> .fitted, <span class="at">col =</span> <span class="st">"blue"</span>) <span class="co"># step function because x values in between cutoffs with same predicted y value</span></span>
<span id="cb57-780"><a href="#cb57-780" aria-hidden="true" tabindex="-1"></a>diamonds <span class="sc">%$%</span> <span class="fu">lines</span>(<span class="fu">lowess</span>(<span class="at">x =</span> carat, <span class="at">y =</span> price), <span class="at">col =</span> <span class="st">"green"</span>)</span>
<span id="cb57-781"><a href="#cb57-781" aria-hidden="true" tabindex="-1"></a>diamonds <span class="sc">%&gt;%</span> </span>
<span id="cb57-782"><a href="#cb57-782" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">x =</span> mod_full_discretized, <span class="at">data =</span> .) <span class="sc">%&gt;%</span> </span>
<span id="cb57-783"><a href="#cb57-783" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(carat) <span class="sc">%$%</span> </span>
<span id="cb57-784"><a href="#cb57-784" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="at">x =</span> carat, <span class="at">y =</span> .fitted, <span class="at">col =</span> <span class="st">"yellow"</span>) <span class="co"># when no replication, gets predicted exactly -&gt; but this is still a smooth curve because covers each unique value</span></span>
<span id="cb57-785"><a href="#cb57-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-786"><a href="#cb57-786" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb57-787"><a href="#cb57-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-788"><a href="#cb57-788" aria-hidden="true" tabindex="-1"></a>Comparison of two or more regression functions</span>
<span id="cb57-789"><a href="#cb57-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-790"><a href="#cb57-790" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>To formally test if these two regression lines are different (e.g. if data come from two different populations, such as males vs females), we can use indicator variables and partial $F$-tests.</span>
<span id="cb57-791"><a href="#cb57-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-792"><a href="#cb57-792" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We simply consider the different populations as classes of a predictor variable, define indicator variables for the different populations, and develop a regression model containing appropriate interaction terms</span>
<span id="cb57-793"><a href="#cb57-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-794"><a href="#cb57-794" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>If just testing the heights, then just need additive indicator variables for the qualitative predictor. </span>
<span id="cb57-795"><a href="#cb57-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-796"><a href="#cb57-796" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>If also want to consider different slopes (i.e. not assume a common slope among the two populations), then include interaction terms for the continuous predictor(s) and the indicator variable(s).</span>
<span id="cb57-797"><a href="#cb57-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-798"><a href="#cb57-798" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>All of the above scenarios require assume that the populations have equal error term variances.</span>
<span id="cb57-799"><a href="#cb57-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-800"><a href="#cb57-800" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>If the error vanances are not equal, transformations of the response variable may equalize them at least approximately.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>