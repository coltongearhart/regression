<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.517">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Regression - 2&nbsp; Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./part2-mlr.html" rel="next">
<link href="./notes-slr.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="site_libs/kePrint-0.0.1/kePrint.js"></script><link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part1-slr.html">Simple linear regression</a></li><li class="breadcrumb-item"><a href="./notes-inference.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inference</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><header id="title-block-header" class="quarto-title-block default page-columns page-full"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part1-slr.html">Simple linear regression</a></li><li class="breadcrumb-item"><a href="./notes-inference.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inference</span></a></li></ol></nav><div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><span id="sec-inference" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inference</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Regression</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part1-slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple linear regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notes-inference.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part2-mlr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple linear regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./placeholder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Placeholder</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#inferences-concerning-beta_1" id="toc-inferences-concerning-beta_1" class="nav-link active" data-scroll-target="#inferences-concerning-beta_1"><span class="header-section-number">2.1</span> Inferences concerning <span class="math inline">\(\beta_1\)</span></a>
  <ul class="collapse">
<li><a href="#sampling-distribution-of-hatbeta_1" id="toc-sampling-distribution-of-hatbeta_1" class="nav-link" data-scroll-target="#sampling-distribution-of-hatbeta_1"><span class="header-section-number">2.1.1</span> Sampling distribution of <span class="math inline">\(\hat{\beta}_1\)</span></a></li>
  <li><a href="#sampling-distribution-of-hatbeta_1---beta_1-s_hatbeta_1" id="toc-sampling-distribution-of-hatbeta_1---beta_1-s_hatbeta_1" class="nav-link" data-scroll-target="#sampling-distribution-of-hatbeta_1---beta_1-s_hatbeta_1"><span class="header-section-number">2.1.2</span> Sampling distribution of <span class="math inline">\((\hat{\beta}_1 - \beta_1) / S_{\hat{\beta}_1}\)</span></a></li>
  <li><a href="#confidence-interval-for-beta_1" id="toc-confidence-interval-for-beta_1" class="nav-link" data-scroll-target="#confidence-interval-for-beta_1"><span class="header-section-number">2.1.3</span> Confidence interval for <span class="math inline">\(\beta_1\)</span></a></li>
  <li><a href="#tests-concerning-beta_1" id="toc-tests-concerning-beta_1" class="nav-link" data-scroll-target="#tests-concerning-beta_1"><span class="header-section-number">2.1.4</span> Tests concerning <span class="math inline">\(\beta_1\)</span></a></li>
  </ul>
</li>
  <li><a href="#some-considerations-when-making-inferences" id="toc-some-considerations-when-making-inferences" class="nav-link" data-scroll-target="#some-considerations-when-making-inferences"><span class="header-section-number">2.2</span> Some considerations when making inferences</a></li>
  <li>
<a href="#interval-estimation-of-ey_h" id="toc-interval-estimation-of-ey_h" class="nav-link" data-scroll-target="#interval-estimation-of-ey_h"><span class="header-section-number">2.3</span> Interval estimation of <span class="math inline">\(E(Y_h)\)</span></a>
  <ul class="collapse">
<li><a href="#sampling-distribution-of-haty_h" id="toc-sampling-distribution-of-haty_h" class="nav-link" data-scroll-target="#sampling-distribution-of-haty_h"><span class="header-section-number">2.3.1</span> Sampling distribution of <span class="math inline">\(\hat{Y_h}\)</span></a></li>
  <li><a href="#sampling-distribution-of-haty_h---ey_h-s_haty_h" id="toc-sampling-distribution-of-haty_h---ey_h-s_haty_h" class="nav-link" data-scroll-target="#sampling-distribution-of-haty_h---ey_h-s_haty_h"><span class="header-section-number">2.3.2</span> Sampling distribution of <span class="math inline">\((\hat{Y_h} - E(Y_h)) / S_{\hat{Y_h}}\)</span></a></li>
  <li><a href="#confidence-interval-for-ey_h" id="toc-confidence-interval-for-ey_h" class="nav-link" data-scroll-target="#confidence-interval-for-ey_h"><span class="header-section-number">2.3.3</span> Confidence interval for <span class="math inline">\(E(Y_h)\)</span></a></li>
  </ul>
</li>
  <li>
<a href="#prediction-of-new-observation" id="toc-prediction-of-new-observation" class="nav-link" data-scroll-target="#prediction-of-new-observation"><span class="header-section-number">2.4</span> Prediction of new observation</a>
  <ul class="collapse">
<li><a href="#prediction-interval-for-y_hnew-when-parameters-are-known" id="toc-prediction-interval-for-y_hnew-when-parameters-are-known" class="nav-link" data-scroll-target="#prediction-interval-for-y_hnew-when-parameters-are-known"><span class="header-section-number">2.4.1</span> Prediction interval for <span class="math inline">\(Y_{h(new)}\)</span> when parameters are known</a></li>
  <li><a href="#prediction-interval-for-y_hnew-when-parameters-are-unknown" id="toc-prediction-interval-for-y_hnew-when-parameters-are-unknown" class="nav-link" data-scroll-target="#prediction-interval-for-y_hnew-when-parameters-are-unknown"><span class="header-section-number">2.4.2</span> Prediction interval for <span class="math inline">\(Y_{h(new)}\)</span> when parameters are unknown</a></li>
  <li><a href="#prediction-of-mean-of-m-observations-for-given-x_h" id="toc-prediction-of-mean-of-m-observations-for-given-x_h" class="nav-link" data-scroll-target="#prediction-of-mean-of-m-observations-for-given-x_h"><span class="header-section-number">2.4.3</span> Prediction of mean of <span class="math inline">\(m\)</span> observations for given <span class="math inline">\(X_h\)</span></a></li>
  </ul>
</li>
  <li><a href="#confidence-band-for-regression-line" id="toc-confidence-band-for-regression-line" class="nav-link" data-scroll-target="#confidence-band-for-regression-line"><span class="header-section-number">2.5</span> Confidence band for regression line</a></li>
  <li>
<a href="#analysis-of-variance-approach-to-regression" id="toc-analysis-of-variance-approach-to-regression" class="nav-link" data-scroll-target="#analysis-of-variance-approach-to-regression"><span class="header-section-number">2.6</span> Analysis of variance approach to regression</a>
  <ul class="collapse">
<li><a href="#partitioning-of-total-sum-of-squares" id="toc-partitioning-of-total-sum-of-squares" class="nav-link" data-scroll-target="#partitioning-of-total-sum-of-squares"><span class="header-section-number">2.6.1</span> Partitioning of total sum of squares</a></li>
  <li><a href="#breakdown-of-degrees-of-freedom" id="toc-breakdown-of-degrees-of-freedom" class="nav-link" data-scroll-target="#breakdown-of-degrees-of-freedom"><span class="header-section-number">2.6.2</span> Breakdown of degrees of freedom</a></li>
  <li><a href="#mean-squares" id="toc-mean-squares" class="nav-link" data-scroll-target="#mean-squares"><span class="header-section-number">2.6.3</span> Mean squares</a></li>
  <li><a href="#anova-table" id="toc-anova-table" class="nav-link" data-scroll-target="#anova-table"><span class="header-section-number">2.6.4</span> ANOVA table</a></li>
  <li><a href="#expected-mean-squares" id="toc-expected-mean-squares" class="nav-link" data-scroll-target="#expected-mean-squares"><span class="header-section-number">2.6.5</span> Expected mean squares</a></li>
  </ul>
</li>
  <li><a href="#f-test-of-beta_1-0-vs-beta_1-ne-0" id="toc-f-test-of-beta_1-0-vs-beta_1-ne-0" class="nav-link" data-scroll-target="#f-test-of-beta_1-0-vs-beta_1-ne-0"><span class="header-section-number">2.7</span> <span class="math inline">\(F\)</span> test of <span class="math inline">\(\beta_1 = 0\)</span> vs <span class="math inline">\(\beta_1 \ne 0\)</span></a></li>
  <li><a href="#general-linear-test-approach" id="toc-general-linear-test-approach" class="nav-link" data-scroll-target="#general-linear-test-approach"><span class="header-section-number">2.8</span> General linear test approach</a></li>
  <li>
<a href="#descriptive-measures-of-linear-association-between-x-and-y" id="toc-descriptive-measures-of-linear-association-between-x-and-y" class="nav-link" data-scroll-target="#descriptive-measures-of-linear-association-between-x-and-y"><span class="header-section-number">2.9</span> Descriptive measures of linear association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></a>
  <ul class="collapse">
<li><a href="#coefficient-of-determination" id="toc-coefficient-of-determination" class="nav-link" data-scroll-target="#coefficient-of-determination"><span class="header-section-number">2.9.1</span> Coefficient of determination</a></li>
  <li><a href="#coefficient-of-correlation" id="toc-coefficient-of-correlation" class="nav-link" data-scroll-target="#coefficient-of-correlation"><span class="header-section-number">2.9.2</span> Coefficient of correlation</a></li>
  </ul>
</li>
  <li><a href="#considerations-in-applying-regression-analysis" id="toc-considerations-in-applying-regression-analysis" class="nav-link" data-scroll-target="#considerations-in-applying-regression-analysis"><span class="header-section-number">2.10</span> Considerations in applying regression analysis</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content"><!-- % define LaTeX macros (/shortcuts) --><!-- % define vector (without parentheses, so when writing out in like a definition) of the form X_1, ..., X_n, where X and n are variable. NOTE: to call use $\vecn{X}{n}$ --><!-- % shortcut for ~ 'Named dist ' in normal font with space before parameters would go --><!-- % (followsp is short for 'follow special') shortcut that can be used for iid or ind ~ 'Named dist ' in normal font with space before parameters would go --><!-- % define independence symbol (it basically makes two orthogonal symbols very close to each other. The number of \! controls the space between each of the orthogonal symbols) --><!-- % shortcut for Cov(X,Y) with formatting for Cov --><!-- % shortcut for Corr(X,Y) with formatting for Corr --><!-- % shortcut for non-italic e in math mode --><p>For the rest of this section, assume the normal error regression model is applicable:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \hspace{20pt} \text{where} \hspace{10pt} \epsilon_i \overset{iid}\sim \text{N}\,(0,\sigma^2)
\]</span></p>
<section id="inferences-concerning-beta_1" class="level2" data-number="2.1"><h2 data-number="2.1" class="anchored" data-anchor-id="inferences-concerning-beta_1">
<span class="header-section-number">2.1</span> Inferences concerning <span class="math inline">\(\beta_1\)</span>
</h2>
<p>Overview</p>
<ul>
<li>
<p>Test on slope <span class="math inline">\(\beta_1\)</span> and the implications</p>
<ul>
<li><p>We often want to make inferences about <span class="math inline">\(\beta_1\)</span>. A common test on <span class="math inline">\(\beta_1\)</span> has the form below.</p></li>
<li><p>If <span class="math inline">\(\beta_1 = 0\)</span> <span class="math inline">\(\Longrightarrow\)</span> Regression line in horizontal, which means there is no linear association between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, and even more no relation of any type because all probability distributions of <span class="math inline">\(Y\)</span> are identical at all levels of <span class="math inline">\(X\)</span>: normal with <span class="math inline">\(E(Y) = \beta_0 + (0) X = \beta_0\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.</p></li>
</ul>
</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  H_0 &amp;: \beta_1 = 0 \\
  H_A &amp;: \beta_1 \ne 0
\end{align*}
\]</span></p>
<p><img src="files/images/zero-slope.png" class="img-fluid" style="width:50.0%"></p>
<section id="sampling-distribution-of-hatbeta_1" class="level3" data-number="2.1.1"><h3 data-number="2.1.1" class="anchored" data-anchor-id="sampling-distribution-of-hatbeta_1">
<span class="header-section-number">2.1.1</span> Sampling distribution of <span class="math inline">\(\hat{\beta}_1\)</span>
</h3>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>Sampling distribution of <span class="math inline">\(\hat{\beta}_1\)</span></p>
<ul>
<li><p>Refers to distribution of <span class="math inline">\(\hat{\beta}_1\)</span> from repeated sampling when the levels of the predictor variable <span class="math inline">\(X\)</span> are held constant from sample to sample.</p></li>
<li><p>Recall <span class="math inline">\(\displaystyle \hat{\beta}_1 = \frac{\sum(X_i - \bar{X})(Y_i - \bar{Y})}{\sum(X_i - \bar{X})^2}\)</span>; this is the point estimator.</p></li>
<li><p>Distribution of <span class="math inline">\(\hat{\beta}_1\)</span> is Normal with mean and variance:</p></li>
</ul>
<p><span class="math display">\[
\begin{align*}
   E(\hat{\beta}_1) &amp;= \beta_1 \\
  V (\hat{\beta}_1) &amp;= \frac{\sigma^2}{\sum(X_i - \bar{X})^2}
\end{align*}
\]</span></p>
<ul>
<li>Then we can estimate the variance by replacing the parameter <span class="math inline">\(\sigma^2\)</span> with <span class="math inline">\(MSE\)</span>, the unbiased estimator of <span class="math inline">\(\sigma^2\)</span>. This gives us <span class="math inline">\(S^2_{\hat{\beta}_1}\)</span>, which is an unbiased estimator for the variance of the sampling distribution of <span class="math inline">\(\hat{\beta}_1\)</span>. And we can take the positive square root to give us <span class="math inline">\(S_{\hat{\beta}_1}\)</span>, which is the point estimator of <span class="math inline">\(\sigma_{\hat{\beta}_1}\)</span>.</li>
</ul>
<p><span class="math display">\[
  S^2_{\hat{\beta}_1} = \frac{MSE}{\sum(X_i - \bar{X})^2} = \frac{MSE}{S_{XX}} \hspace{20pt} \longrightarrow \hspace{20pt} s_{\hat{\beta}_1} = \sqrt{\frac{MSE}{S_{XX}}} = \frac{S}{\sqrt{S_{XX}}}
  \]</span></p>
<ul>
<li>
<p>Thus, <span class="math inline">\(S^2_{\hat{\beta}_1}\)</span> is an unbiased estimator for the variance of the sampling distribution of <span class="math inline">\(\hat{\beta}_1\)</span> and</p>
<ul>
<li>This is also called the <strong>standard error</strong> (another way to think about it is the standard deviation of the sampling distribution) → <span class="math inline">\(S_{\hat{\beta}_1} = SE(\hat{\beta}_1)\)</span>
</li>
</ul>
</li>
</ul>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>Main result for normal, mean and variance</p>
<ul>
<li>
<span class="math inline">\(\hat{\beta}_1\)</span> can be written as a linear combination of the observations <span class="math inline">\(Y_i\)</span>:</li>
</ul>
<p><span class="math display">\[
\hat{\beta_1}=\sum k_i Y_i, \hspace{20pt} \text{where} \hspace{10pt} k_i = \frac{X_i - \bar{X}}{\sum(X_i - \bar{X})^2}
\]</span></p>
<ul>
<li><p><span class="math inline">\(\sum \text{Normal} \sim \text{Normal}\,\)</span>, so we know <span class="math inline">\(\hat{\beta}_1\)</span> must be Normal. Then properties of the coefficients <span class="math inline">\(k_i\)</span> can be used to show the mean and variance.</p></li>
<li><p>Note that <span class="math inline">\(k_i\)</span>’s are fixed quantities because they are a function of only <span class="math inline">\(X_i\)</span>’s (which are fixed quantities). Therefore, <span class="math inline">\(\hat{\beta}_1\)</span> is a linear combination of <span class="math inline">\(Y_i\)</span>, where the coefficients are solely a function of the fixed <span class="math inline">\(X_i\)</span> (this is why <span class="math inline">\(\hat{\beta}_1\)</span> is a <em>linear estimator</em>).</p></li>
</ul>
<p>Properties of coefficients <span class="math inline">\(k_i\)</span>:</p>
<p><img src="files/images/ki-properties.png" class="img-fluid" style="width:20.0%"></p>
<p>Proof of linear combination:</p>
<p><img src="files/images/proof-linear-combination.png" class="img-fluid" style="width:50.0%"></p>
<p>Proofs of properties of <span class="math inline">\(k_i\)</span>:</p>
<p><img src="files/images/proof-ki-properties.png" class="img-fluid" style="width:50.0%"></p>
<p>Proof of mean:</p>
<p><img src="files/images/proof-mean.png" class="img-fluid" style="width:50.0%"></p>
<p>Proof of variance:</p>
<p><img src="files/images/proof-variance.png" class="img-fluid" style="width:50.0%"></p>
<p>Can also prove that <span class="math inline">\(\hat{\beta}_1\)</span> has minimum variance among all unbiased linear estimators.</p>
<!-- page 43 of textbook, not hard to follow -->
</div>
</div>
</div>
</section><section id="sampling-distribution-of-hatbeta_1---beta_1-s_hatbeta_1" class="level3" data-number="2.1.2"><h3 data-number="2.1.2" class="anchored" data-anchor-id="sampling-distribution-of-hatbeta_1---beta_1-s_hatbeta_1">
<span class="header-section-number">2.1.2</span> Sampling distribution of <span class="math inline">\((\hat{\beta}_1 - \beta_1) / S_{\hat{\beta}_1}\)</span>
</h3>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p><span class="math display">\[
\frac{\hat{\beta}_1 - \beta_1}{S_{\hat{\beta}_1}} = \frac{\hat{\beta}_1 - \beta_1}{\sqrt{MSE / S_{XX}}} \sim \text{t}\,_{n - 2}
\]</span></p>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>Deriving the distribution of the standardized slope → <span class="math inline">\(\displaystyle \frac{\hat{\beta}_1 - E(\hat{\beta}_1)}{SE(\hat{\beta}_1)}\)</span></p>
<ul>
<li>Technically when standardizing with an estimated standard deviation it is referred to as <em>studentized</em> statistic.</li>
</ul>
<p><img src="files/images/placeholder.png" class="img-fluid" style="width:50.0%"></p>
<!-- Can show the coefficients ki for model with intercept as well (written out in regression notes, probably not necessary); and my proofs have a bit more steps for extra clarity -->
</div>
</div>
</div>
</section><section id="confidence-interval-for-beta_1" class="level3" data-number="2.1.3"><h3 data-number="2.1.3" class="anchored" data-anchor-id="confidence-interval-for-beta_1">
<span class="header-section-number">2.1.3</span> Confidence interval for <span class="math inline">\(\beta_1\)</span>
</h3>
<p>Forming interval</p>
<p><span class="math display">\[
\begin{align*}
  &amp; P(-t_{\alpha/2, n-2} \le \frac{\hat{\beta}_1 - \beta_1}{S_{\hat{\beta}_1}} \le t_{\alpha/2, n-2}) = 1 - \alpha \\
  &amp; \Longleftrightarrow \hspace{20pt} P(\hat{\beta}_1 - t_{\alpha/2, n-2} \cdot S_{\hat{\beta}_1} \le \frac{ - \beta_1}{S_{\hat{\beta}_1}} \le \hat{\beta}_1 + t_{\alpha/2, n-2} \cdot S_{\hat{\beta}_1}) = 1 - \alpha \\
  &amp; \Longleftrightarrow \hspace{20pt}  100(1 - \alpha)\% \text{ CI } = \hat{\beta}_1 \pm t_{\alpha/2, n-2} \cdot S_{\hat{\beta}_1} \hspace{10pt} = \hspace{10pt} \hat{\beta}_1 \pm t_{\alpha/2, n-2} \cdot \sqrt{MSE / S_{XX}}
\end{align*}
\]</span></p>
<p>Interpretation</p>
<ul>
<li><p>With &lt; <span class="math inline">\(100(1 - \alpha)\)</span> &gt;% confidence, we estimate that the average &lt; <span class="math inline">\(Y\)</span> context &gt; increases by between &lt; lower bound &gt; and &lt; upper bound &gt; for each additional unit increase in &lt; <span class="math inline">\(X\)</span> context &gt;.</p></li>
<li><p>Remember the scope of the regression model is restricted to some range of values of the predictor variable → May not be reasonable to use these slope estimates outside this range as the regression relation may not be linear then.</p></li>
</ul>
<p>Demo:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Manual</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># simulate sample dataset for normal error regression model</span></span>
<span><span class="co"># -&gt; E ~ Normal(0, sigma^2)</span></span>
<span><span class="co"># -&gt; Y = B0 + B1*X + E</span></span>
<span><span class="co"># -&gt; Y | X ~ Normal(B0 + B1*X, sigma^2)</span></span>
<span></span>
<span><span class="co"># initialize items</span></span>
<span><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">50</span></span>
<span><span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="fl">5</span></span>
<span><span class="va">sigma2</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># generate X values</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">5</span>, max <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># generate error terms</span></span>
<span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">sigma2</span><span class="op">)</span><span class="op">)</span></span>
<span>      </span>
<span><span class="co"># calculate observations Y | X ~ Normal(B0 + B1*X, sigma^2)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span></span>
<span></span>
<span><span class="co"># plot sample data with regression line</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-inference_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># display error terms</span></span>
<span><span class="va">x_plot</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span><span class="fl">3</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">sigma2</span><span class="op">)</span>, to <span class="op">=</span> <span class="fl">3</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">sigma2</span><span class="op">)</span>, by <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">epsilon</span>, freq <span class="op">=</span> <span class="cn">FALSE</span>, xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="va">epsilon</span> <span class="op">*</span> <span class="st">"~ Normal ("</span> <span class="op">*</span> <span class="va">mu</span> <span class="op">*</span> <span class="st">","</span> <span class="op">*</span> <span class="va">sigma</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="st">")"</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">""</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_plot</span>,</span>
<span>      y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_plot</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">sigma2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-inference_files/figure-html/unnamed-chunk-2-2.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># fit model</span></span>
<span><span class="va">mod_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display only coefficient summaries of slope</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> <span class="co"># Estimate is the middle of the interval</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  Estimate                 Std. Error 
 5.22587398756125764975877  0.40211009692893356914922 
                   t value                   Pr(&gt;|t|) 
12.99612724841586341995026  0.00000000000000002457706 </code></pre>
</div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate confidence interval for slope</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">mod_normal</span>, parm <span class="op">=</span> <span class="st">"x"</span>, level <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     2.5 %   97.5 %
x 4.417377 6.034371</code></pre>
</div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># using R functions to get the needed values (can reference how to calculate these manually above)</span></span>
<span></span>
<span><span class="co"># extract / calculate needed items</span></span>
<span><span class="co"># -&gt; point estimate = beta1-hat</span></span>
<span><span class="co"># -&gt; critical value = t_alpha/2, n-2</span></span>
<span><span class="co"># -&gt; SE(beta1-hat) = MSE / S_XX = S / sqrt(S_XX)</span></span>
<span><span class="va">pe</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span><span class="op">[</span><span class="st">"x"</span><span class="op">]</span><span class="op">)</span> <span class="co"># SIDENOTE -&gt; as.numeric() just to remove the named number data type</span></span>
<span><span class="va">t_crit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span>p <span class="op">=</span> <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="va">mod_normal</span><span class="op">$</span><span class="va">df.residual</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span></span>
<span><span class="va">s_xx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">se_beta1_hat</span> <span class="op">&lt;-</span> <span class="va">s</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">s_xx</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare to Std. Error from summary of model coefficients</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="st">"x"</span>,<span class="st">"Std. Error"</span><span class="op">]</span>, <span class="va">se_beta1_hat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`summary(mod_normal)$coefficients["x", "Std. Error"]`
[1] 0.4021101

$se_beta1_hat
[1] 0.4021101</code></pre>
</div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate confidence interval for beta1</span></span>
<span><span class="va">ci_limits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="va">pe</span> <span class="op">-</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_beta1_hat</span>, upper <span class="op">=</span> <span class="va">pe</span> <span class="op">+</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_beta1_hat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare to results from confint(lm())</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">mod_normal</span>, parm <span class="op">=</span> <span class="st">"x"</span>, level <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span><span class="op">)</span>, <span class="va">ci_limits</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
  2.5 % 97.5 %
x  TRUE   TRUE

$`confint(mod_normal, parm = "x", level = 1 - alpha)`
     2.5 %   97.5 %
x 4.417377 6.034371

$ci_limits
   lower    upper 
4.417377 6.034371 </code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section id="tests-concerning-beta_1" class="level3" data-number="2.1.4"><h3 data-number="2.1.4" class="anchored" data-anchor-id="tests-concerning-beta_1">
<span class="header-section-number">2.1.4</span> Tests concerning <span class="math inline">\(\beta_1\)</span>
</h3>
<p>Overview</p>
<ul>
<li><p>The test shown below is called a test of utility of the model.</p></li>
<li><p>If reject → We conclude that <span class="math inline">\(X\)</span> does contribute information for the prediction of <span class="math inline">\(Y\)</span> when using the straight-line model.</p></li>
<li>
<p>If fail to reject → Then we conclude there is no linear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> (horizontal model). But keep in mind:</p>
<ul>
<li><p>Additional data might indicate that <span class="math inline">\(\beta_1\)</span> differs from zero.</p></li>
<li><p>A more complex relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> may exist, which would require fitting a model other than the straight-line model.</p></li>
</ul>
</li>
<li><p>All assumptions about the error terms (<span class="math inline">\(\epsilon_i \overset{iid}\sim \text{Normal}\,(0,\sigma^2)\)</span>) should be satisfied.</p></li>
</ul>
<p>Two-tailed test (most common)</p>
<ul>
<li>Hypotheses</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  H_0 &amp;: \beta_1 = 0 \\
  H_A &amp;: \beta_1 \ne 0
\end{align*}
\]</span></p>
<ul>
<li>Test statistic</li>
</ul>
<p><span class="math display">\[
TS = t^* = \frac{\hat{\beta}_1 - 0}{S_{\hat{\beta}_1}} = \frac{\hat{\beta}_1}{\sqrt{MSE / S_{XX}}}
\]</span></p>
<ul>
<li>Rejection region and p-value</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  RR &amp;= \{\lvert t^* \rvert &gt; t_{\alpha/2, n - 2}\} \\
  p\text{-value} &amp;= 2 \cdot P(t_{n-2} \ge \lvert t^* \rvert)
\end{align*}
\]</span></p>
<ul>
<li>
<p>Decision</p>
<ul>
<li><p>Reject <span class="math inline">\(H_0\)</span> and conclude <span class="math inline">\(H_A\)</span> if <span class="math inline">\(\hspace{10pt}\)</span> <span class="math inline">\(TS \in RR \hspace{10pt} \Longleftrightarrow \hspace{10pt} p\text{-value} \le \alpha\)</span></p></li>
<li><p>Fail to reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(\hspace{10pt}\)</span> <span class="math inline">\(TS \notin RR \hspace{10pt} \Longleftrightarrow \hspace{10pt} p\text{-value} &gt; \alpha\)</span></p></li>
<li><p>Can also look at the <span class="math inline">\(100(1 - \alpha)\%\)</span> CI for <span class="math inline">\(\beta_1\)</span> to see if contains 0.</p></li>
</ul>
</li>
<li>
<p>Conclusion / Interpretation</p>
<ul>
<li>At the <span class="math inline">\(\alpha\)</span> significance level, we &lt; have / do not have &gt; sufficient evidence of a significant linear relationship between &lt; <span class="math inline">\(Y\)</span> context &gt; and &lt; <span class="math inline">\(X\)</span> context &gt;. &lt; if yes… &gt; This is a &lt; positive / negative &gt; linear relationship, indicating that as &lt; <span class="math inline">\(X\)</span> context &gt; increases, &lt; <span class="math inline">\(Y\)</span> context &gt; &lt; increases / decreases &gt;, on average.</li>
</ul>
</li>
</ul>
<p>Other tests</p>
<ul>
<li>
<p>One-tailed tests</p>
<ul>
<li><p><span class="math inline">\(H_A: \beta_1 &lt; 0 \hspace{10pt} \Longrightarrow \hspace{10pt} RR = \{t^*&lt; t_{\alpha, n - 2}\} \hspace{10pt} \text{and} \hspace{10pt} p\text{-value} = P(t_{n-2} \le t^*)\)</span></p></li>
<li><p><span class="math inline">\(H_A: \beta_1 &gt; 0 \hspace{10pt} \Longrightarrow \hspace{10pt} RR = \{t^* &gt; t_{\alpha, n - 2}\} \hspace{10pt} \text{and} \hspace{10pt} p\text{-value} = P(t_{n-2} \ge t^*)\)</span></p></li>
</ul>
</li>
<li>
<p>Tests against specified nonzero value of <span class="math inline">\(\beta_{1,0}\)</span></p>
<ul>
<li><p><span class="math inline">\(TS = t^* = \frac{\hat{\beta}_1 - \beta_{1,0}}{S_{\hat{\beta}_1}}\)</span></p></li>
<li><p>RR, <span class="math inline">\(p\)</span>-value and decisions are the same, just based on new <span class="math inline">\(t^*\)</span>.</p></li>
</ul>
</li>
</ul>
<p>Demo:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Manual</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false">Simulation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># using same model from the confidence interval for beta1 demo</span></span>
<span></span>
<span><span class="co"># display model summary, focusing on coefficient summaries for slope</span></span>
<span><span class="co"># -&gt; looking for t value (if doing traditional method test with RR) and Pr(&gt;|t|) = p-value</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span> <span class="co"># compare p-value to alpha</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.5868 -2.4928 -0.4756  2.9264 11.0773 

Coefficients:
            Estimate Std. Error t value            Pr(&gt;|t|)    
(Intercept)   0.7398     3.1431   0.235               0.815    
x             5.2259     0.4021  12.996 &lt;0.0000000000000002 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 4.125 on 48 degrees of freedom
Multiple R-squared:  0.7787,    Adjusted R-squared:  0.7741 
F-statistic: 168.9 on 1 and 48 DF,  p-value: &lt; 0.00000000000000022</code></pre>
</div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate test statistic t* = beta1-hat / SE(beta1-hat)</span></span>
<span><span class="va">beta1_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">se_beta1_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="st">"x"</span>,<span class="st">"Std. Error"</span><span class="op">]</span></span>
<span><span class="va">t_star</span> <span class="op">&lt;-</span> <span class="va">beta1_hat</span> <span class="op">/</span> <span class="va">se_beta1_hat</span></span>
<span></span>
<span><span class="co"># compare to result from summary(lm())</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="st">"x"</span>,<span class="st">"t value"</span><span class="op">]</span>, <span class="va">t_star</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`summary(mod_normal)$coefficients["x", "t value"]`
[1] 12.99613

$t_star
[1] 12.99613</code></pre>
</div>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate p-value = 2 * P(t_(n-2) &gt;= |t*|)</span></span>
<span><span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span>q <span class="op">=</span> <span class="va">t_star</span>, df <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare to results from summary(lm())</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_normal</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="st">"x"</span>,<span class="st">"Pr(&gt;|t|)"</span><span class="op">]</span>, <span class="va">p_value</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`summary(mod_normal)$coefficients["x", "Pr(&gt;|t|)"]`
[1] 0.00000000000000002457706

$p_value
[1] 0.00000000000000002457706</code></pre>
</div>
</div>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<p>Simulation to determine how the magnitude of <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma\)</span> affect the resulting significance of the <span class="math inline">\(X\)</span> variable in SLR when simulating data. For example, suppose <span class="math inline">\(\beta_1 = 1a\)</span> and <span class="math inline">\(\sigma = 3a\)</span>, where <span class="math inline">\(a = 1, 2, 3\)</span>. Is there the same resulting significance for all values of <span class="math inline">\(a\)</span>?</p>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># initialize simulation settings</span></span>
<span><span class="co"># -&gt; first the parameters of interest (that are variable)</span></span>
<span><span class="co"># -&gt; create all combos</span></span>
<span><span class="co"># -&gt; add in the constant settings</span></span>
<span><span class="co"># -&gt; arrange in a good order</span></span>
<span><span class="co"># -&gt; add simulation id column</span></span>
<span><span class="co"># -&gt; set row names equal to id (helps keep track of results later)</span></span>
<span><span class="va">params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span>beta_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">5</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>                      ratio <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,<span class="fl">5</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sigma <span class="op">=</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">ratio</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">30</span>,</span>
<span>         beta_0 <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">beta_1</span>, <span class="va">ratio</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">bind_cols</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>sim_id <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">params</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"sim"</span>, <span class="va">params</span><span class="op">$</span><span class="va">sim_id</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define function to run on each unique simulation setting</span></span>
<span><span class="va">simulation</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">vec</span>, <span class="va">vec_names</span>, <span class="va">m</span> <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># set names of parameter vector for clearer reference</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">vec</span><span class="op">)</span> <span class="op">=</span> <span class="va">vec_names</span></span>
<span>  </span>
<span>  <span class="co"># initialize results vector</span></span>
<span>  <span class="va">results</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">m</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># loop to simulate m models and extract summaries</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">m</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="co"># generate data</span></span>
<span>    <span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">vec</span><span class="op">[</span><span class="st">"n"</span><span class="op">]</span>, min <span class="op">=</span> <span class="fl">5</span>, max <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span>    <span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">vec</span><span class="op">[</span><span class="st">"n"</span><span class="op">]</span>, mean <span class="op">=</span> <span class="va">vec</span><span class="op">[</span><span class="st">"beta_0"</span><span class="op">]</span> <span class="op">+</span> <span class="va">vec</span><span class="op">[</span><span class="st">"beta_1"</span><span class="op">]</span> <span class="op">*</span> <span class="va">x</span>, sd <span class="op">=</span> <span class="va">vec</span><span class="op">[</span><span class="st">"sigma"</span><span class="op">]</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># fit model</span></span>
<span>    <span class="va">mod</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># get summaries</span></span>
<span>    <span class="co"># -&gt; just want t-stat</span></span>
<span>    <span class="va">results</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="st">"x"</span>, <span class="st">"t value"</span><span class="op">]</span></span>
<span>    </span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">results</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># run simulation for each parameter settings</span></span>
<span><span class="co"># -&gt; have to transpose so that now each column is a parameter settings and convert to dataframe so can pass to map(), which needs a list</span></span>
<span><span class="va">results_raw</span> <span class="op">&lt;-</span> <span class="va">params</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">t</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">data.frame</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">map</span><span class="op">(</span>\<span class="op">(</span><span class="va">vec</span><span class="op">)</span> <span class="fu">simulation</span><span class="op">(</span><span class="va">vec</span>, vec_names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">params</span><span class="op">)</span>, m <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span>, .progress <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># reformat results</span></span>
<span><span class="co"># -&gt; combine results into a dataframe</span></span>
<span><span class="co"># -&gt; convert to long so have one column for which simulation settings and one for the results</span></span>
<span><span class="co"># -&gt; attach the simulation settings to the results</span></span>
<span><span class="co"># --&gt; for the plot, want all parameters as factors -&gt; so before joining convert all</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="va">results_raw</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">bind_rows</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">pivot_longer</span><span class="op">(</span>cols <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">params</span><span class="op">)</span>,</span>
<span>               names_to <span class="op">=</span> <span class="st">"sim_id"</span>,</span>
<span>               values_to <span class="op">=</span> <span class="st">"t"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sim_id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="fu">str_sub</span><span class="op">(</span><span class="va">sim_id</span>, start <span class="op">=</span> <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">left_join</span><span class="op">(</span><span class="fu">mutate</span><span class="op">(</span><span class="va">params</span>, <span class="fu">across</span><span class="op">(</span><span class="fu">everything</span><span class="op">(</span><span class="op">)</span>, <span class="va">as_factor</span><span class="op">)</span><span class="op">)</span>, by <span class="op">=</span> <span class="st">"sim_id"</span><span class="op">)</span> <span class="co"># levels are slightly out of order....</span></span>
<span></span>
<span><span class="co"># create a plot facetted by beta value, with density curves for the sampling distributions of the t-stats for each value of the sigma / beta1 ratio</span></span>
<span><span class="co"># -&gt; add reference line for significance cutoff</span></span>
<span></span>
<span><span class="co"># set more informative labels for the facets</span></span>
<span><span class="va">labels_beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"1"</span> <span class="op">=</span> <span class="st">"beta1 = 1"</span>,</span>
<span>                 <span class="st">"5"</span> <span class="op">=</span> <span class="st">"beta1 = 5"</span>,</span>
<span>                 <span class="st">"10"</span> <span class="op">=</span> <span class="st">"beta1 = 10"</span><span class="op">)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_density</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">t</span>,</span>
<span>                   group <span class="op">=</span> <span class="va">ratio</span>,</span>
<span>                   color <span class="op">=</span> <span class="va">ratio</span>,</span>
<span>                   fill <span class="op">=</span> <span class="va">ratio</span><span class="op">)</span>,</span>
<span>               data <span class="op">=</span> <span class="va">results</span>,</span>
<span>               alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">t</span><span class="op">)</span>,</span>
<span>             data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>t <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.025</span>, df <span class="op">=</span> <span class="va">params</span><span class="op">[</span><span class="fl">1</span>,<span class="st">"n"</span><span class="op">]</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>             color <span class="op">=</span> <span class="st">"darkgrey"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">facet_grid</span><span class="op">(</span><span class="va">beta_1</span> <span class="op">~</span> <span class="va">.</span>,</span>
<span>             labeller <span class="op">=</span> <span class="fu">as_labeller</span><span class="op">(</span><span class="va">labels_beta</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">guides</span><span class="op">(</span></span>
<span>    fill <span class="op">=</span> <span class="fu">guide_legend</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="va">sigma</span> <span class="op">*</span>  <span class="st">"/"</span> <span class="op">*</span> <span class="va">beta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">*</span> <span class="st">" ratio"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    color <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-inference_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Based on the sampling distributions, it appears that the relative magnitude is what is important. And if it is the same even for different values, then will get similar results.</p>
</div>
</div>
</div>
<!-- ### Inferences concerning $\beta_0$ --- infrequent that this is ever done, so skipping -->
</section></section><section id="some-considerations-when-making-inferences" class="level2" data-number="2.2"><h2 data-number="2.2" class="anchored" data-anchor-id="some-considerations-when-making-inferences">
<span class="header-section-number">2.2</span> Some considerations when making inferences</h2>
<p>Effects of departures from normality:</p>
<ul>
<li><p>If the probability distributions of <span class="math inline">\(Y\)</span> are not exactly normal but do not depart seriously <span class="math inline">\(\Longrightarrow\)</span> Sampling distribution of <span class="math inline">\(\hat{\beta_1}\)</span> <span class="math inline">\(\approx\)</span> normal <span class="math inline">\(\Longrightarrow\)</span> Using the <span class="math inline">\(t\)</span> distribution will provide <span class="math inline">\(\approx\)</span> <span class="math inline">\((100 - \alpha)\%\)</span> CIs and <span class="math inline">\(\alpha\)</span>-level tests.</p></li>
<li><p>The estimator <span class="math inline">\(\hat{\beta_1}\)</span> generally has the property of <strong>asymptotic normality</strong> (i.e.&nbsp;it’s distribution approaches normality under very general conditions as the sample size increases). So with a sufficiently large sample size, inference procedures are still valid even if distributions of <span class="math inline">\(Y\)</span> have large departures from normality. Can switch from <span class="math inline">\(t\)</span>-based procedures to <span class="math inline">\(Z\)</span>-based with large <span class="math inline">\(n\)</span>.</p></li>
</ul>
<!-- does R do this implicitly?? ; doubt it, but difference in marginal--><p>Interpretation of confidence coefficient and risks of errors</p>
<ul>
<li><p>Our regression model assumes that the <span class="math inline">\(X_i\)</span> are known constants. So the confidence coefficient and risks of errors are interpreted with respect to taking repeated samples where the <span class="math inline">\(X\)</span> observations are kept at the same levels as in the observed sample.</p></li>
<li><p>For example, confidence interval for <span class="math inline">\(\beta_1\)</span> with confidence coefficient 95% → If many independent samples are taken <em>where the levels of</em> <span class="math inline">\(X\)</span> are the same as in the dataset, approximately 95% of the constructed confidence intervals would capture the true value of <span class="math inline">\(\beta_1\)</span>.</p></li>
</ul>
<p>Spacing of the <span class="math inline">\(X\)</span> levels</p>
<ul>
<li>For a given <span class="math inline">\(n\)</span> and <span class="math inline">\(\sigma^2\)</span>, the variance of <span class="math inline">\(\hat{\beta_1}\)</span> is affected by the spacing of the <span class="math inline">\(X\)</span> levels in the observed data. As the spread in the <span class="math inline">\(X\)</span> levels increases, <span class="math inline">\(S_{xx}\)</span> increases and therefore <span class="math inline">\(V(\hat{\beta_1})\)</span> decreases.</li>
</ul>
<!-- Power of tests; skipping--></section><section id="interval-estimation-of-ey_h" class="level2" data-number="2.3"><h2 data-number="2.3" class="anchored" data-anchor-id="interval-estimation-of-ey_h">
<span class="header-section-number">2.3</span> Interval estimation of <span class="math inline">\(E(Y_h)\)</span>
</h2>
<p>Overview</p>
<ul>
<li><p>A common objective is to estimate the mean of one or more probability distributions of <span class="math inline">\(Y\)</span>.</p></li>
<li>
<p>Setup</p>
<ul>
<li><p>Let <span class="math inline">\(X_h\)</span> = level of <span class="math inline">\(X\)</span> that we wish to estimate the mean response for (may be a value which occurred in the sample, or some other value within the scope of the model).</p></li>
<li><p>Mean response when <span class="math inline">\(X = X_h\)</span> is <span class="math inline">\(E(Y_h)\)</span>; this is what we are estimating.</p></li>
</ul>
</li>
</ul>
<section id="sampling-distribution-of-haty_h" class="level3" data-number="2.3.1"><h3 data-number="2.3.1" class="anchored" data-anchor-id="sampling-distribution-of-haty_h">
<span class="header-section-number">2.3.1</span> Sampling distribution of <span class="math inline">\(\hat{Y_h}\)</span>
</h3>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<p>Sampling distribution of <span class="math inline">\(\hat{Y_h}\)</span></p>
<ul>
<li><p>Again, this refers to the different of <span class="math inline">\(\hat{Y_h}\)</span> from repeated sampling when the levels of the predictor variable <span class="math inline">\(X\)</span> are held constant from sample to sample.</p></li>
<li><p>Point estimator for <span class="math inline">\(E(Y_h)\)</span> → <span class="math inline">\(\hat{Y_h} = \hat{\beta}_0 + \hat{\beta}_1 X_h\)</span></p></li>
<li><p>Distribution of <span class="math inline">\(\hat{Y_h}\)</span> is Normal with mean and variance:</p></li>
</ul>
<p><span class="math display">\[
  \begin{align*}
    E(\hat{Y_h}) &amp;= E(Y_h) \\
    V(\hat{Y_h}) &amp;= \sigma^2 \bigg[\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg]
  \end{align*}
  \]</span></p>
<ul>
<li>Estimate variance (and standard deviation) by substituting <span class="math inline">\(MSE\)</span>. This gives us:</li>
</ul>
<p><span class="math display">\[
  S^2_{\hat{Y_h}} = MSE \bigg[\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg] \hspace{20pt} \longrightarrow \hspace{20pt} S_{\hat{Y_h}} = \sqrt{S^2_{\hat{Y_h}}} = S \sqrt{\frac{1}{n} + \frac{(X_h - \bar{X})^2}{S_{XX}}}
  \]</span> Notes</p>
<ul>
<li><p>The variability of the sampling distribution of <span class="math inline">\(Y_h\)</span> is affected by how far <span class="math inline">\(X_h\)</span> is from <span class="math inline">\(\bar{X}\)</span> (from the numerator of second term in <span class="math inline">\(V(\hat{Y_h})\)</span>) <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(V(\hat{Y_h})\)</span> increases the further <span class="math inline">\(X_h\)</span> is from <span class="math inline">\(\bar{X}\)</span>.</p></li>
<li>
<p>Intuitive / visual explanation of this affect</p>
<ul>
<li>In the picture below, two regression lines are assumed to go through the same <span class="math inline">\((\bar{X}, \bar{Y})\)</span> point to isolate the effect of variation in the estimated slope <span class="math inline">\(\hat{\beta}_1\)</span> from sample to sample.</li>
</ul>
<p><img src="files/images/variance-y-hat.png" class="img-fluid" style="width:40.0%"></p>
<ul>
<li>We see the difference between estimated responses is much smaller when <span class="math inline">\(X\)</span> is near the mean <span class="math inline">\(\bar{X}\)</span>. So the variation in slope from sample to sample has a much more pronounced effect for <span class="math inline">\(X\)</span> levels far from the mean.</li>
</ul>
</li>
<li><p>When <span class="math inline">\(X_h = 0\)</span> <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(V(\hat{Y_h})\)</span> reduces to <span class="math inline">\(V(\hat{\beta}_0)\)</span> (likewise for the estimated variances). This is because when <span class="math inline">\(X_h = 0\)</span>, <span class="math inline">\(\hat{Y_h} = \hat{\beta}_0 + \hat{\beta}_1 (0) = \hat{\beta}_0\)</span>.</p></li>
</ul>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<p><img src="files/images/placeholder.png" class="img-fluid" style="width:50.0%"></p>
</div>
</div>
</div>
</section><section id="sampling-distribution-of-haty_h---ey_h-s_haty_h" class="level3" data-number="2.3.2"><h3 data-number="2.3.2" class="anchored" data-anchor-id="sampling-distribution-of-haty_h---ey_h-s_haty_h">
<span class="header-section-number">2.3.2</span> Sampling distribution of <span class="math inline">\((\hat{Y_h} - E(Y_h)) / S_{\hat{Y_h}}\)</span>
</h3>
<p><span class="math display">\[
\frac{\hat{Y_h} - E(Y_h)}{S_{\hat{Y_h}}} = \frac{\hat{Y_h} - E(Y_h)}{\sqrt{MSE \bigg[\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg]}} \sim \text{t}\,_{n - 2}
\]</span></p>
</section><section id="confidence-interval-for-ey_h" class="level3" data-number="2.3.3"><h3 data-number="2.3.3" class="anchored" data-anchor-id="confidence-interval-for-ey_h">
<span class="header-section-number">2.3.3</span> Confidence interval for <span class="math inline">\(E(Y_h)\)</span>
</h3>
<ul>
<li><p>Goal → Estimate the mean value of <span class="math inline">\(Y\)</span> for a given value of <span class="math inline">\(X\)</span>.</p></li>
<li><p>Results → Using the same general format / derivation of a <span class="math inline">\(t\)</span> interval, we have</p></li>
</ul>
<p><span class="math display">\[
100(1 - \alpha)\% \text{ CI } = \hat{Y_h} \pm t_{\alpha/2, n-2} \cdot S_{\hat{Y_h}} \hspace{10pt} = \hspace{10pt} \hat{Y_h} \pm t_{\alpha/2, n-2} \cdot \sqrt{MSE \bigg[\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg]}
\]</span></p>
<ul>
<li>Interpretation → With &lt; <span class="math inline">\(1 - \alpha\)</span> &gt;% confidence, we estimate that the true mean value of &lt; <span class="math inline">\(Y\)</span> context &gt; for all individuals with an &lt; <span class="math inline">\(X\)</span> context &gt; of &lt; <span class="math inline">\(X_h\)</span> &gt; to be between &lt; lower bound &gt; and &lt; upper bound &gt;.</li>
</ul>
<p>Notes</p>
<ul>
<li><p>Interpretations → Same interpretation rules about repeated sampling for constant <span class="math inline">\(X\)</span> levels (because <span class="math inline">\(X_i\)</span> are known constants in the regression model).</p></li>
<li>
<p>Confidence interval width is the smallest when <span class="math inline">\(X_h = \bar{X}\)</span> (assuming everything else remains equal).</p>
<ul>
<li>Design of experiments → Thus in an experiment to estimate the mean response at a particular level <span class="math inline">\(X_h\)</span>, the precision of the estimate will be best if (everything else remaining equal) the observations on <span class="math inline">\(X\)</span> are spaced so that <span class="math inline">\(\bar{X} = X_h\)</span>.</li>
</ul>
</li>
<li><p>Tests → Can use the CI to perform a two-sided test as well.</p></li>
<li>
<p>Robust → Confidence limits shown here for <span class="math inline">\(\hat{Y_h}\)</span> are not sensitive to moderate departures from the assumption that the error terms are normally distributed. If there is substantial departures from normality, still not sensitive if large <span class="math inline">\(n\)</span>; this robustness comes from robustness of CIs for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<ul>
<li>Can also think of these CIs as robust because they are only concerned with the center (location) of the distribution of <span class="math inline">\(Y_h\)</span>.</li>
</ul>
</li>
<li><p>Multiple intervals → ** CIs apply when a estimating <em>a single mean response</em> from the study. Will show later how to adjust when estimating several mean responses. **</p></li>
</ul>
<p>Demo</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Manual</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-3" role="tab" aria-controls="tabset-6-3" aria-selected="false">Properties</a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># simulate sample dataset for normal error regression model</span></span>
<span></span>
<span><span class="co"># initialize items</span></span>
<span><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="fl">5</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">10</span> </span>
<span></span>
<span><span class="co"># generate X values</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">5</span>, max <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># generate response Y | X ~ Normal(B0 + B1*X, sigma^2)</span></span>
<span><span class="co"># -&gt; specify the conditional means and then incorporate the random error</span></span>
<span><span class="co"># -&gt; rnorm() can take a vector of means and iterates through them</span></span>
<span><span class="co"># --&gt; if there n &gt; length(means), then the means get recycled from the start</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">x</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># fit model</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># specify new X level (X range is 5 - 15)</span></span>
<span><span class="co"># -&gt; newdata frame should have columns with same name as data for the model</span></span>
<span><span class="va">x_h</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">12</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate just the point estimate of estimated E(Y_h)</span></span>
<span><span class="co"># -&gt; technically using the predict() function for class lm(), so just calling predict() is masking predict.lm() --&gt; other classes like predict.glm() have slightly different argument options</span></span>
<span><span class="co"># -&gt; by default predict() returns the fits (regression line) for all of the obs (X values) used in the model fit, can specify new data points with newdata = &lt; data_frame &gt;</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1 
60.87545 </code></pre>
</div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate lower and upper bounds of interval estimate for E(Y_h)</span></span>
<span><span class="co"># -&gt; by default does 95% CI and returns the point estimate (fit) as well</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"confidence"</span>, level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit      lwr      upr
1 60.87545 56.97016 64.78073</code></pre>
</div>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># show items related to standard error of estimation se(Y_h-hat)</span></span>
<span><span class="co"># -&gt; residual.scale = S = sqrt(MSE)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, se.fit <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$fit
       1 
60.87545 

$se.fit
[1] 1.906499

$df
[1] 28

$residual.scale
[1] 8.681483</code></pre>
</div>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># alternate way from ALSM package</span></span>
<span><span class="co"># -&gt; this is the package that goes with the textbook; provides some functions that are nowhere else, and some alternatives to common functions</span></span>
<span><span class="co"># --&gt; the implementation of this function is essentially what is done in the "manual" section</span></span>
<span><span class="co"># --&gt; type = "m" gives CI for mean observation; by default does CL of 95%, but specifies alpha</span></span>
<span><span class="co"># -&gt; SIDENOTE -&gt; formatting: original result is a dataframe which displays poorly, so convert to matrix</span></span>
<span><span class="fu">ALSM</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ALSM/man/6_ci.reg.html">ci.reg</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, type <span class="op">=</span> <span class="st">"m"</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">as.matrix</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   x      Fit Lower.Band Upper.Band
1 12 60.87545   56.97016   64.78073</code></pre>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate point estimate using estimated coefficients</span></span>
<span><span class="co"># -&gt; hat(Y_h) = hat(beta_0) + hat(beta_1) X_h</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">pe</span> <span class="op">&lt;-</span> <span class="va">b</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">b</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">x_h</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate critical value</span></span>
<span><span class="co"># -&gt; use lower.tail = FALSE to get the positive version of t_alpha/2</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span><span class="va">t_crit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span>p <span class="op">=</span> <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate se(Y_h-hat) = MSE (1/n (X_h - X-bar)^2 / S_XX) %&gt;% sqrt OR S * sqrt(1/n + S_XX)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">x_bar</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">s_xx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">x_bar</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">mse</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">mse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, se.fit <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">$</span><span class="va">residual.scale</span></span>
<span><span class="va">se_yh_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">mse</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="va">n</span> <span class="op">+</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">x_h</span><span class="op">)</span> <span class="op">-</span> <span class="va">x_bar</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="va">s_xx</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">se_yh_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="va">n</span> <span class="op">+</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">x_h</span><span class="op">)</span> <span class="op">-</span> <span class="va">x_bar</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="va">s_xx</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate CI for E(Y_h)</span></span>
<span><span class="va">ci_limits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="va">pe</span> <span class="op">-</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_yh_hat</span>, upper <span class="op">=</span> <span class="va">pe</span> <span class="op">+</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_yh_hat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare results to predict(lm(), type = "confidence")</span></span>
<span><span class="co"># -&gt; Y_h-hat and interval bounds</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"confidence"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"point estimate"</span> <span class="op">=</span> <span class="va">pe</span>, <span class="va">ci_limits</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
   fit  lwr  upr
1 TRUE TRUE TRUE

$`predict(mod, newdata = x_h, interval = "confidence")`
       fit      lwr      upr
1 60.87545 56.97016 64.78073

$`c(`point estimate` = pe, ci_limits)`
point estimate          lower          upper 
      60.87545       56.97016       64.78073 </code></pre>
</div>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># -&gt; se of estimation</span></span>
<span><span class="co"># --&gt; by default predict uses s = sqrt(mse) = residual standard error to get the se.fit (and the df as well = df.residual(mod)) ---&gt; assumes future obs have same error variance as originals used for fitting</span></span>
<span><span class="co"># --&gt; can specify a different variance to use for future obs with pred.var if desired</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, se.fit <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">$</span><span class="va">se.fit</span>, <span class="va">se_yh_hat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`predict(mod, newdata = x_h, se.fit = TRUE)$se.fit`
[1] 1.906499

$se_yh_hat
[1] 1.906499</code></pre>
</div>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># can return fit, bounds, and standard error info from predict using type = "terms"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, type <span class="op">=</span> <span class="st">"terms"</span>, interval <span class="op">=</span> <span class="st">"conf"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$fit
        x
1 9.87435
attr(,"constant")
[1] 51.0011

$se.fit
         x
1 1.059465

$lwr
         x
1 7.704134
attr(,"constant")
[1] 51.0011

$upr
         x
1 12.04457
attr(,"constant")
[1] 51.0011

$df
[1] 28

$residual.scale
[1] 8.681483</code></pre>
</div>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># -&gt; for the fit and bounds, for some reason this actually uses the alternate regression model -&gt; Y_h-hat = bar(y) + beta_1-hat (X_h - bar(x))</span></span>
<span><span class="co"># -&gt; results: constant = beta_1-hat (X_h - X-bar) and attr = Y-bar</span></span>
<span><span class="co"># -&gt; same process to get upper and lower too, add to Y-bar</span></span>
<span><span class="op">(</span><span class="va">x_star</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, type <span class="op">=</span> <span class="st">"terms"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        x
1 9.87435
attr(,"constant")
[1] 51.0011</code></pre>
</div>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">compare</span><span class="op">(</span><span class="va">pe</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">+</span> <span class="va">b</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">x_h</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$pe
[1] 60.87545

$`mean(y) + b[2] * (as.numeric(x_h) - mean(x))`
[1] 60.87545</code></pre>
</div>
</div>
</div>
<div id="tabset-6-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-3-tab">
<div class="cell">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare width of confidence intervals at two X levels</span></span>
<span></span>
<span><span class="co"># specify new X levels (X range is 5 - 15)</span></span>
<span><span class="co"># -&gt; optimal width will be at X = X-bar</span></span>
<span><span class="va">x_h_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x_h2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate width of intervals</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h_mean</span>, interval <span class="op">=</span> <span class="st">"confidence"</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">%&gt;%</span> <span class="va">diff</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.493511</code></pre>
</div>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h2</span>, interval <span class="op">=</span> <span class="st">"confidence"</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">%&gt;%</span> <span class="va">diff</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.988876</code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section><section id="prediction-of-new-observation" class="level2" data-number="2.4"><h2 data-number="2.4" class="anchored" data-anchor-id="prediction-of-new-observation">
<span class="header-section-number">2.4</span> Prediction of new observation</h2>
<p>Overview</p>
<ul>
<li><p>Goal → Predict a new observation <span class="math inline">\(Y\)</span> for a given <span class="math inline">\(X\)</span> value. This new observation is viewed as the result of a new trial, independent of the trials the model is based on.</p></li>
<li>
<p>Setup</p>
<ul>
<li><p>Again, <span class="math inline">\(X_h\)</span> is the <span class="math inline">\(X\)</span> level for the new trial. Still assuming the underlying regression model is appropriate for the new observation.</p></li>
<li><p>The new observation on <span class="math inline">\(Y\)</span> is <span class="math inline">\(Y_{h(new)}\)</span>; this is what we are estimating.</p></li>
</ul>
</li>
</ul>
<p>Distinction between (1) estimation of the mean response <span class="math inline">\(E(Y_h)\)</span> and (2) prediction of a new response <span class="math inline">\(Y_{h(new)}\)</span></p>
<ol type="1">
<li><p>We estimate the <em>mean</em> of the distribution of <span class="math inline">\(Y\)</span>.</p></li>
<li><p>We predict an <em>individual outcome</em> drawn from the distribution of <span class="math inline">\(Y\)</span>. Obviously, most outcomes deviate from the mean response; so this must be taken into account when predicting <span class="math inline">\(Y_{h(new)}\)</span>.</p></li>
</ol>
<ul>
<li>Prediction has extra variability <span class="math inline">\(\Longrightarrow\)</span> Less precision.</li>
</ul>
<section id="prediction-interval-for-y_hnew-when-parameters-are-known" class="level3" data-number="2.4.1"><h3 data-number="2.4.1" class="anchored" data-anchor-id="prediction-interval-for-y_hnew-when-parameters-are-known">
<span class="header-section-number">2.4.1</span> Prediction interval for <span class="math inline">\(Y_{h(new)}\)</span> when parameters are known</h3>
<p>Demonstration of prediction intervals</p>
<ul>
<li>For a simple example, assume the relevant parameters of the regression model are known:</li>
</ul>
<p><span class="math display">\[
\beta_0 = 0.10, \, \beta_1 = 0.95, \, \sigma = 0.12 \hspace{10pt} \longrightarrow \hspace{10pt} E(Y) = 0.10 + 0.95 X
\]</span></p>
<ul>
<li>If we have a new observation with <span class="math inline">\(X_h = 3.425\)</span> → <span class="math inline">\(E(Y_h) = 0.10 + 0.95 (3.5) = 3.425\)</span> (so we know the center of the normal distribution of <span class="math inline">\(Y_h\)</span>). Thus, using the empirical rule we have the following prediction interval:</li>
</ul>
<p><span class="math display">\[
99.7\% \text{ CI } = E(Y_h) \pm 3 \sigma \hspace{10pt} = \hspace{10pt} 3.425 \pm 3 (0.12) \hspace{10pt} \Longrightarrow \hspace{10pt} 3.065 \le Y_{h(new)} \le 3.785
\]</span></p>
<p><img src="files/images/simple-prediction-interval.png" class="img-fluid" style="width:30.0%"></p>
<p>Basic idea of prediction used here</p>
<ul>
<li><p>Choose a range in the distribution of <span class="math inline">\(Y\)</span> where most of the observations will fall and then declare that the next observation will fall in this range.</p></li>
<li><p>The usefulness of the prediction interval depends on the width of the interval and the needs for precision by the user.</p></li>
</ul>
<p>Generalizing for this simple scenario</p>
<ul>
<li>When the regression parameters of normal error regression model are known:</li>
</ul>
<p><span class="math display">\[
100(1 - \alpha)\% \text{ PI for } Y_{h(new)} = E(Y_h) \pm z_{\alpha / 2} \cdot \sigma
\]</span></p>
<ul>
<li>Centering the limits around <span class="math inline">\(E(Y_h)\)</span> results in the narrowest interval consistent with the specified probability of a correct prediction.</li>
</ul></section><section id="prediction-interval-for-y_hnew-when-parameters-are-unknown" class="level3" data-number="2.4.2"><h3 data-number="2.4.2" class="anchored" data-anchor-id="prediction-interval-for-y_hnew-when-parameters-are-unknown">
<span class="header-section-number">2.4.2</span> Prediction interval for <span class="math inline">\(Y_{h(new)}\)</span> when parameters are unknown</h3>
<p>Overview and demo</p>
<ul>
<li>
<p>When the regression parameters are unknown, they must be estimated.</p>
<ul>
<li><p>The mean of the distribution of <span class="math inline">\(Y\)</span> is estimated by <span class="math inline">\(\hat{Y_h}\)</span> as usual, and the variance of the distribution of <span class="math inline">\(Y\)</span> is estimated with <span class="math inline">\(MSE\)</span>.</p></li>
<li><p>However, we cannot simply use the previous PI with the parameters replaced by the corresponding point estimators. Here’s a demo of why:</p></li>
<li><p>The picture below shows two possible probability distributions of <span class="math inline">\(Y\)</span>, corresponding to the lower and upper limits of a CI for <span class="math inline">\(E(Y_h)\)</span>. In other words, the distribution of <span class="math inline">\(Y\)</span> could be located as far left as the one shown, as far right as the other one shown, or anywhere in between.</p></li>
</ul>
</li>
</ul>
<p><img src="files/images/possible-prediction-intervals.png" class="img-fluid" style="width:40.0%"></p>
<ul>
<li>
<p>Results</p>
<ul>
<li><p>Since we do not know the mean <span class="math inline">\(E(Y_h)\)</span> and only estimate it by a confidence interval, we cannot be certain of the location of the distribution of <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Because of this uncertainty, PIs for <span class="math inline">\(Y_{h(new)}\)</span> clearly must take into account two elements:</p></li>
</ul>
<ol type="1">
<li><p>Variation in possible location of the distribution of <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Variation within the probability distribution of <span class="math inline">\(Y\)</span>.</p></li>
</ol>
</li>
</ul>
<p>Prediction interval for <span class="math inline">\(Y_{h(new)}\)</span></p>
<ul>
<li>
<p>Sampling distribution</p>
<ul>
<li><p>Note that this studentized statistic uses the point estimator <span class="math inline">\(\hat{Y_h}\)</span> in the numerator rather than the true mean <span class="math inline">\(E(Y_h)\)</span> because the true mean is unknown and cannot be used in making a prediction.</p></li>
<li><p>For <span class="math inline">\(E(Y_h)\)</span> CIs shown earlier, we used <span class="math inline">\([\hat{Y_h} - E(Y_h)] / S_{\hat{Y_h}}\)</span>, which was okay because the only unknown was <span class="math inline">\(E(Y_h)\)</span> and it is what we are estimating. But now there are two layers of uncertainty (variability). So the reference value in the numerator is also an estimate, not the true value.</p></li>
</ul>
</li>
</ul>
<p><span class="math display">\[
\frac{Y_{h(new)} - \hat{Y_h}}{S_{pred}} \sim \text{t}\,_{n-2}
\]</span></p>
<ul>
<li>
<p>Prediction interval</p>
<ul>
<li>Interpretation → With &lt; <span class="math inline">\(1-\alpha\)</span> &gt;% confidence, we predict that the true value of &lt; <span class="math inline">\(Y\)</span> context &gt; for a single (or the next) &lt; <span class="math inline">\(X\)</span> context &gt; of &lt; <span class="math inline">\(X_h\)</span> &gt; to be between &lt; lower bound &gt; and &lt; upper bound &gt;.</li>
</ul>
</li>
</ul>
<p><span class="math display">\[
100(1 - \alpha)\% \text{ PI for } Y_{h(new)} = \hat{Y_h} \pm t_{\alpha/2, n-2} \cdot S_{pred}
\]</span></p>
<p>Standard deviation of prediction <span class="math inline">\(\sigma^2_{pred}\)</span></p>
<ul>
<li><p>The numerator of the studentized statistic represents how far the new observation will deviate from the estimated mean (based on the original <span class="math inline">\(n\)</span> cases in the study). This difference can be viewed as the prediction error, with <span class="math inline">\(\hat{Y_h}\)</span> serving as the best point estimate of the value of the new observation <span class="math inline">\(Y_{h(new)}\)</span>.</p></li>
<li><p>We can easily find the variance of this difference (because of independence of the new <span class="math inline">\(Y_{h(new)}\)</span> and original <span class="math inline">\(n\)</span> cases on which <span class="math inline">\(\hat{Y_h}\)</span> is based).</p></li>
</ul>
<p><span class="math display">\[
\sigma^2_{pred} = V(Y_{h(new)} - \hat{Y_h}) = V(Y_{h(new)}) + V(\hat{Y_h}) = \sigma^2 + \sigma^2_{\hat{Y_h}}.
\]</span></p>
<ul>
<li>
<p>This has two components:</p>
<ol type="1">
<li><p>Variance of the distribution of <span class="math inline">\(Y\)</span> at <span class="math inline">\(X = X_h\)</span> → <span class="math inline">\(\sigma^2\)</span></p></li>
<li><p>Variance of the sampling distribution of <span class="math inline">\(\hat{Y_h}\)</span> → <span class="math inline">\(\sigma^2_{\hat{Y_h}}\)</span></p></li>
</ol>
</li>
<li><p>The unbiased estimator of <span class="math inline">\(\sigma^2_{pred}\)</span> is</p></li>
</ul>
<p><span class="math display">\[
S^2_{pred} = MSE + S^2_{\hat{Y_h}} = MSE + MSE \bigg[\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg] = MSE \bigg[1 + \frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum (X_i - \bar{X})^2}\bigg] \hspace{20pt} \longrightarrow \hspace{20pt} S_{pred} = \sqrt{S^2_{pred}}
\]</span></p>
<p>Notes about prediction intervals</p>
<ul>
<li>
<p>Analogous results / interpretations to estimation</p>
<ul>
<li><p>Interpretation → Again, the confidence coefficient refers to taking repeated samples based on the same set of <span class="math inline">\(X\)</span> values, and calculating prediction limits for <span class="math inline">\(Y_{h(new)}\)</span> for each sample.</p></li>
<li><p>Precision → PI width is the smallest when <span class="math inline">\(X_h = \bar{X}\)</span> (assuming everything else remains equal).</p></li>
<li><p>One interval → PIs apply for a single prediction based on the sample data.</p></li>
</ul>
</li>
<li><p>Not robust → PIs (unlike CIs for the mean response) are sensitive to departures from normality of the error terms distribution. Can think of this non-robustness a result of having to take into account the center of the distribution of <span class="math inline">\(Y_h\)</span> (just like with CIs) AND also the tails (spread) of the distribution.</p></li>
<li>
<p>Precision → Even if PIs are too wide for useful predictions, they can still be informative for control / modelling purposes, specifically the estimated variance of prediction.</p>
<ul>
<li><p><span class="math inline">\(S^2_{pred} = MSE + S^2_{\hat{Y_h}} \hspace{10pt}\)</span> has two pieces: (1) <span class="math inline">\(MSE\)</span> measures <span class="math inline">\(X\)</span>-to-<span class="math inline">\(X\)</span> variation within the probability distribution for <span class="math inline">\(Y\)</span> (different response values for observations with same <span class="math inline">\(X\)</span> level) and (2) <span class="math inline">\(S^2_{\hat{Y_h}}\)</span> measures sample-to-sample variation (mean response of samples with overall same <span class="math inline">\(X\)</span> levels).</p></li>
<li><p>So if <span class="math inline">\(MSE\)</span> is very large compared to <span class="math inline">\(S^2_{\hat{Y_h}}\)</span>, e.g.&nbsp;<span class="math inline">\(\frac{MSE}{S^2_{pred}} \ge 0.8 \text{ or } 0.9\)</span>, then the majority of the variation is from sample-to-sample. This could reflect other factors that aren’t being taken into account by the model. So perhaps a multiple linear regression model should be used, which could result in more useful predictions.<mark> NOT SURE HOW THIS WORKS</mark></p></li>
</ul>
</li>
</ul>
<p>Estimation vs Prediction</p>
<ul>
<li><p>Location → For a particular <span class="math inline">\(X_h\)</span>, CIs and PIs have the same point estimate <span class="math inline">\(\hat{Y_h}\)</span>, which is the estimate of the mean <span class="math inline">\(E(Y_h)\)</span>.</p></li>
<li>
<p>Precision</p>
<ul>
<li><p>The difference between CIs and PIs then lies in the relative accuracy of the interval.</p></li>
<li><p>CIs are narrower than PIs at the same <span class="math inline">\(X_h\)</span>.</p></li>
<li><p>The only way to obtain more accurate prediction for a new value of <span class="math inline">\(Y\)</span> is to reduce the standard deviation of the regression model. This can be accomplished by using a curvilinear model, adding new independent variables, etc. or by collecting more data (width of both intervals decrease when the sample size increases).</p></li>
</ul>
</li>
<li><p>Conceptual difference → CIs resemble PIs, except: A CI represents an inference on a parameter and is an interval that is intended to cover the value of the parameter; and a PI is a statement about the value to be taken by a random variable, the new observation <span class="math inline">\(Y_{h(new)}\)</span>.</p></li>
</ul>
<p>Demo</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Manual</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-3" role="tab" aria-controls="tabset-7-3" aria-selected="false">Properties</a></li>
</ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># using the same model as the confidence interval for E(Y_h) demo</span></span>
<span></span>
<span><span class="co"># calculate just the point estimate of predicted Y_h(new)</span></span>
<span><span class="co"># -&gt; this is the same as the PE for a CI of E(Y_h) </span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1 
60.87545 </code></pre>
</div>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate lower and upper bounds of prediction interval Y_h(new)</span></span>
<span><span class="co"># -&gt; by default does 95% CI and returns the point estimate (fit) as well</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit      lwr      upr
1 60.87545 42.66847 79.08242</code></pre>
</div>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"co"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit      lwr      upr
1 60.87545 56.97016 64.78073</code></pre>
</div>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># show items related to standard error of ESTIMATION se(Y_h-hat)</span></span>
<span><span class="co"># -&gt; ALWAYS returns this, even if specify interval = "pred"...</span></span>
<span><span class="co"># --&gt; suppose it implicitly adds the extra MSE term (from residual.scale) to get the prediction lwr and upr</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, se.fit <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$fit
       1 
60.87545 

$se.fit
[1] 1.906499

$df
[1] 28

$residual.scale
[1] 8.681483</code></pre>
</div>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># alternative way using ALSM</span></span>
<span><span class="co"># -&gt; type = "n" gives PI for single new observation</span></span>
<span><span class="fu">ALSM</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ALSM/man/6_ci.reg.html">ci.reg</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, type <span class="op">=</span> <span class="st">"n"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">as.matrix</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   x      Fit Lower.Band Upper.Band
1 12 60.87545   42.66847   79.08242</code></pre>
</div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate point estimate and critical value</span></span>
<span><span class="co"># -&gt; same as for confidence interval</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">pe</span> <span class="op">&lt;-</span> <span class="va">b</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">b</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">x_h</span><span class="op">)</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span><span class="va">t_crit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span>p <span class="op">=</span> <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate standard error in prediction se(pred) = sqrt(MSE + var(Y-h-hat))</span></span>
<span><span class="co"># -&gt; save se(estimation = fit), shown earlier, then have to add in the extra MSE term</span></span>
<span><span class="va">se_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, se.fit <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">$</span><span class="va">se.fit</span></span>
<span><span class="va">se_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">se_fit</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">se_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">se_fit</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># OR calculate se(pred) using expanded formula se(pred) = MSE * (1 + 1/n (X_h - X-bar)^2 / S_XX) %&gt;% sqrt OR s * sqrt(...)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">x_bar</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">s_xx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">x_bar</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">)</span></span>
<span><span class="va">se_pred</span> <span class="op">&lt;-</span> <span class="va">s</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span> <span class="op">+</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">x_h</span><span class="op">)</span> <span class="op">-</span> <span class="va">x_bar</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="va">s_xx</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate PI for Y_h(new)</span></span>
<span><span class="va">pi_limits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="va">pe</span> <span class="op">-</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_pred</span>, upper <span class="op">=</span> <span class="va">pe</span> <span class="op">+</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_pred</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare results to predict(lm(), type = "prediction)</span></span>
<span><span class="co"># -&gt; Y_h-hat and interval bounds</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"point estimate"</span> <span class="op">=</span> <span class="va">pe</span>, <span class="va">pi_limits</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
   fit  lwr  upr
1 TRUE TRUE TRUE

$`predict(mod, newdata = x_h, interval = "prediction")`
       fit      lwr      upr
1 60.87545 42.66847 79.08242

$`c(`point estimate` = pe, pi_limits)`
point estimate          lower          upper 
      60.87545       42.66847       79.08242 </code></pre>
</div>
</div>
</div>
<div id="tabset-7-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-3-tab">
<div class="cell">
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare width of prediction intervals at two X levels</span></span>
<span></span>
<span><span class="co"># specify new X levels (X range is 5 - 15)</span></span>
<span><span class="co"># -&gt; optimal width will again be at X = X-bar</span></span>
<span><span class="va">x_h_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x_h2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate width of intervals</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h_mean</span>, interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">%&gt;%</span> <span class="va">diff</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 36.15434</code></pre>
</div>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h2</span>, interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">%&gt;%</span> <span class="va">diff</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 36.45261</code></pre>
</div>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare widths of CI vs PI at the same X level</span></span>
<span></span>
<span><span class="co"># calculate width of intervals</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"conf"</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">%&gt;%</span> <span class="va">diff</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.810573</code></pre>
</div>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"pred"</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">%&gt;%</span> <span class="va">diff</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 36.41395</code></pre>
</div>
</div>
<!-- question -->
</div>
</div>
</div>
</section><section id="prediction-of-mean-of-m-observations-for-given-x_h" class="level3" data-number="2.4.3"><h3 data-number="2.4.3" class="anchored" data-anchor-id="prediction-of-mean-of-m-observations-for-given-x_h">
<span class="header-section-number">2.4.3</span> Prediction of mean of <span class="math inline">\(m\)</span> observations for given <span class="math inline">\(X_h\)</span>
</h3>
<p>Overview</p>
<ul>
<li><p>Goal → Predict the mean of <span class="math inline">\(m\)</span> new observations on <span class="math inline">\(Y\)</span> for a given level of the predictor variable.</p></li>
<li><p>Setup → <span class="math inline">\(\bar{Y}_{h(new)}\)</span> represents the mean of the new <span class="math inline">\(Y\)</span> observations to be predicted.</p></li>
</ul>
<p>Results</p>
<ul>
<li>
<span class="math inline">\(100(1 - \alpha)\%\)</span> Prediction interval for <span class="math inline">\(\bar{Y}_{h(new)}\)</span> (assuming the new observations are independent):</li>
</ul>
<p><span class="math display">\[
\hat{Y_h} \pm t_{(1 - alpha /2, n - 2)} \cdot S_{predmean}
\]</span></p>
<ul>
<li>Standard deviation in prediction of a mean <span class="math inline">\(S_{predmean}\)</span>
</li>
</ul>
<p><span class="math display">\[
S^2_{predmean} = \frac{MSE}{m} + S^2_{\hat{Y_h}}  = MSE \bigg[\frac{1}{m} + \frac{1}{n} + \frac{(X_h - \bar{X})^2}{S_{XX}}\bigg]  \hspace{20pt} \longrightarrow \hspace{20pt} S_{predmean} = \sqrt{S^2_{predmean}}
\]</span></p>
<ul>
<li>
<p>This has two components:</p>
<ol type="1">
<li><p>Variance of the distribution mean of <span class="math inline">\(m\)</span> observations from the probability distrubtion of <span class="math inline">\(Y\)</span> at <span class="math inline">\(X = X_h\)</span> → <span class="math inline">\(\sigma^2 / m\)</span></p></li>
<li><p>Variance of the sampling distribution of <span class="math inline">\(\hat{Y_h}\)</span> → <span class="math inline">\(\sigma^2_{\hat{Y_h}}\)</span></p></li>
</ol>
</li>
</ul>
<p>Notes</p>
<ul>
<li><p>Interpretation → With &lt; <span class="math inline">\(1 - \alpha\)</span> &gt;% confidence, we predict that the true value of &lt; <span class="math inline">\(Y\)</span> context &gt; for &lt; <span class="math inline">\(m\)</span> &gt; &lt; <span class="math inline">\(X\)</span> context &gt; of &lt; <span class="math inline">\(X_h\)</span> &gt; to be between &lt; lower bound &gt; and &lt; upper bound &gt;.</p></li>
<li><p>Interval still has the same center as when estimating <span class="math inline">\(E(Y_h)\)</span> and predicting a single <span class="math inline">\(Y_{h(new)}\)</span>.</p></li>
<li><p>This prediction interval is narrower than when predicting for a single observation (because it involves the prediction of the mean for a group), but still wider than the confidence interval.</p></li>
<li>
<p>We can then obtain the prediction interval for the total of the <span class="math inline">\(m\)</span> observations by multiplying each limit by <span class="math inline">\(m\)</span>.</p>
<ul>
<li>e.g) For <span class="math inline">\(m = 4\)</span>, if <span class="math inline">\(5 \le \bar{Y}_{h(new)} \le 15 \hspace{10pt} \Longrightarrow \hspace{10pt} 5(4) = 20 \le \sum Y_{h(new)} \le 15(4)= 60\)</span>
</li>
</ul>
</li>
</ul>
<p>Demo</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Manual</a></li>
</ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<div class="cell">
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># using the same model as the confidence interval for E(Y_h) demo</span></span>
<span></span>
<span><span class="co"># calculate the predicted mean for m observations of Y_h(new)</span></span>
<span><span class="co"># -&gt; type = "nm" is gives PR for mean of m new observations at X_h</span></span>
<span><span class="fu">ALSM</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ALSM/man/6_ci.reg.html">ci.reg</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, type <span class="op">=</span> <span class="st">"nm"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">as.matrix</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   x      Fit Lower.Band Upper.Band
1 12 60.87545   42.66847   79.08242</code></pre>
</div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="cell">
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># set number of observations to predict at X_h</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span></span>
<span><span class="co"># calculate just the point estimate of predicted Y-bar_h(new) and critical value</span></span>
<span><span class="co"># -&gt; PE is the same as previous CI and PI</span></span>
<span><span class="va">pe</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span><span class="va">t_crit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span>p <span class="op">=</span> <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate standard error in prediction se(pred) = sqrt(MSE / m + var(Y-h-hat))</span></span>
<span><span class="co"># -&gt; save se(fit), shown earlier, then have to add in the extra MSE / m term</span></span>
<span><span class="va">se_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, se.fit <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">$</span><span class="va">se.fit</span></span>
<span><span class="va">se_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="va">m</span> <span class="op">+</span> <span class="va">se_fit</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate PI for Y-bar_h(new)</span></span>
<span><span class="op">(</span><span class="va">pi_limits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="va">pe</span> <span class="op">-</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_pred</span>, upper <span class="op">=</span> <span class="va">pe</span> <span class="op">+</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_pred</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   lower    upper 
51.16402 70.58688 </code></pre>
</div>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare to (widths) of previous types of intervals</span></span>
<span><span class="co"># -&gt; order from most to least precise: CI for E(Y_h), PI for Y-bar_h(new), PI for single Y_h-hat</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"conf"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit      lwr      upr
1 60.87545 56.97016 64.78073</code></pre>
</div>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, interval <span class="op">=</span> <span class="st">"pred"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit      lwr      upr
1 60.87545 42.66847 79.08242</code></pre>
</div>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># interval for sum (total) of m predictions at X_h</span></span>
<span><span class="co"># -&gt; depends on context if this is meaningful</span></span>
<span><span class="va">pi_limits</span> <span class="op">*</span> <span class="va">m</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   lower    upper 
204.6561 282.3475 </code></pre>
</div>
</div>
</div>
</div>
</div>
</section></section><section id="confidence-band-for-regression-line" class="level2" data-number="2.5"><h2 data-number="2.5" class="anchored" data-anchor-id="confidence-band-for-regression-line">
<span class="header-section-number">2.5</span> Confidence band for regression line</h2>
<p>Overview</p>
<ul>
<li><p>The goal is to obtain a confidence band for the entire regression line <span class="math inline">\(E(Y) = \beta_0 + \beta_1 X\)</span>.</p></li>
<li><p>This band enables us to see the region in which the entire regression line lies and is particularly useful for determining the appropriateness of a fitted regression function.</p></li>
</ul>
<p>Results</p>
<ul>
<li>
<p>This confidence band formula below the same form as the CI formula for <span class="math inline">\(E(Y_h)\)</span>, the mean response at <span class="math inline">\(X_h\)</span> (<span class="math inline">\(\hat{Y_h} \pm t_{\alpha/2, n-2} \cdot S_{\hat{Y_h}}\)</span>), except it uses a different multiplier to adjust for multiple comparisons <span class="math inline">\(\Longrightarrow\)</span> Same point estimate and standard error.</p>
<ul>
<li><p>Some alternative procedures for developing confidence bands have been developed.</p></li>
<li><p>The one shown below is the <em>Working-Hotelling confidence band</em> (more will be said about this method later).</p></li>
<li><p>The simplicity of this method is that it is a direct extension of the confidence limits for a single mean response <span class="math inline">\(E(Y_h)\)</span> shown earlier.</p></li>
</ul>
</li>
<li><p>The <span class="math inline">\(100(1 - \alpha)\%\)</span> confidence band for the regression line has boundaries at any level <span class="math inline">\(X_h\)</span>:</p></li>
</ul>
<p><span class="math display">\[
\hat{Y_h} \pm W \cdot S_{\hat{Y_h}} = \hat{Y_h} \pm W \cdot \sqrt{MSE \bigg[\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg]}
\]</span></p>
<ul>
<li><p>(Initial steps of deriving CI) → We are finding the two values such that <span class="math inline">\(P(\text{lower} \le \beta_0 + \beta_1 X_h \le \text{upper}) = 1- \alpha\)</span>; And <span class="math inline">\(\hat{Y_h}\)</span> is the point estimator for <span class="math inline">\(E(Y_h) = \beta_0 + \beta_1 X_h\)</span>.</p></li>
<li><p><span class="math inline">\(W\)</span> multiplier</p></li>
</ul>
<p><span class="math display">\[
W^2 = 2 \cdot F_{(1-\alpha; \, 2, n-2)}
\]</span></p>
<ul>
<li><p>We multiply by two for SLR becuase there are two estimated coefficients.</p></li>
<li><p>The <span class="math inline">\(W\)</span>-multiplier is larger than the <span class="math inline">\(t\)</span> multiplier because the confidence band must encompass the entire regression line, whereas the confidence limits for <span class="math inline">\(E(Y_h)\)</span> at <span class="math inline">\(X_h\)</span> apply only at the single level <span class="math inline">\(X_h\)</span>.</p></li>
</ul>
<p>Notes</p>
<ul>
<li>
<p>Confidence band confidence level</p>
<ul>
<li><p>Interpretation → Indicates the proportion of time that the estimating procedure will yield a band that covers the entire line, in a long series of samples in which the <span class="math inline">\(X\)</span> observations are kept at the same level as in the actual study.</p></li>
<li><p>Technical application → The confidence band applies to the entire regression line over all real-numbered values of <span class="math inline">\(X\)</span> from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>.</p></li>
<li><p>Practical application → In practice, the confidence band is ignored for that part of the regression line which is not of interest, so the confidence coefficient for this limited segment is somewhat higher than <span class="math inline">\(1-\alpha\)</span>. Thus, <span class="math inline">\(1-\alpha\)</span> serves as a lower bound to the confidence coefficient.</p></li>
</ul>
</li>
<li><p>Things to look for → Can see if the slope is clearly positive or negative, can look at the levels of the regression line at different levels of <span class="math inline">\(X\)</span> to gauge relative precision, etc.</p></li>
<li>
<p>Precision</p>
<ul>
<li><p>With the somewhat wider limits for the entire regression line, we are able to draw conclusions about any and all mean responses for the entire regression line and not just about the mean response at a given <span class="math inline">\(X\)</span> level.</p></li>
<li><p>Although, generally confidence band lines at any value <span class="math inline">\(X_h\)</span> often are not substantially wider than the confidence limits for the mean response at that single <span class="math inline">\(X_h\)</span> level.</p></li>
<li><p>Just like with the CI for <span class="math inline">\(E(Y_h)\)</span>, the boundary points of the confidence band for the regression line are wider apart the further <span class="math inline">\(X_h\)</span> is from the mean <span class="math inline">\(\bar{X}\)</span> of the <span class="math inline">\(X\)</span> observations.</p></li>
</ul>
</li>
<li><p>Formula → The lower and upper bounds together actually define a hyperbola.</p></li>
</ul>
<p>Demo</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-9-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-2" role="tab" aria-controls="tabset-9-2" aria-selected="false">Manual</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-9-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-3" role="tab" aria-controls="tabset-9-3" aria-selected="false">Other functions</a></li>
</ul>
<div class="tab-content">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<div class="cell">
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># using the same model as the confidence interval for E(Y_h) demo</span></span>
<span></span>
<span><span class="co"># calculate confidence band limits across scope of model</span></span>
<span><span class="co"># -&gt; initialize many x_h values covering min to max of original sample</span></span>
<span><span class="va">x_h</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, to <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, length <span class="op">=</span> <span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate confidence bands</span></span>
<span><span class="co"># -&gt; type = "w" uses the Working-Hotelling method with the W multiplier</span></span>
<span><span class="va">conf_band</span> <span class="op">&lt;-</span> <span class="fu">ALSM</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ALSM/man/6_ci.reg.html">ci.reg</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, type <span class="op">=</span> <span class="st">"w"</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display results</span></span>
<span><span class="fu">kable</span><span class="op">(</span><span class="va">conf_band</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span>, format <span class="op">=</span> <span class="st">"html"</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">kable_styling</span><span class="op">(</span>full_width <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                position <span class="op">=</span> <span class="st">"left"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">x</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Fit</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Lower.Band</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Upper.Band</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">5.075</td>
<td style="text-align: right;">25.452</td>
<td style="text-align: right;">17.268</td>
<td style="text-align: right;">33.637</td>
</tr>
<tr class="even">
<td style="text-align: right;">5.564</td>
<td style="text-align: right;">27.953</td>
<td style="text-align: right;">20.361</td>
<td style="text-align: right;">35.545</td>
</tr>
<tr class="odd">
<td style="text-align: right;">6.053</td>
<td style="text-align: right;">30.454</td>
<td style="text-align: right;">23.436</td>
<td style="text-align: right;">37.472</td>
</tr>
<tr class="even">
<td style="text-align: right;">6.542</td>
<td style="text-align: right;">32.955</td>
<td style="text-align: right;">26.488</td>
<td style="text-align: right;">39.423</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7.031</td>
<td style="text-align: right;">35.456</td>
<td style="text-align: right;">29.509</td>
<td style="text-align: right;">41.403</td>
</tr>
</tbody>
</table>
</div>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare width when estimating a single E(X_h) to the confidence bands</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x_h</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_h</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">)</span>, interval <span class="op">=</span> <span class="st">"conf"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_names</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="st">"fit"</span>, <span class="st">"lwr"</span>, <span class="st">"upr"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        x       fit       lwr       upr 
 5.075098 25.452401 18.966137 31.938664 </code></pre>
</div>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot fitted line and confidence bands on scatterplot</span></span>
<span><span class="co"># -&gt; also add reference line for X-bar showing where the most precision is</span></span>
<span><span class="va">conf_band</span> <span class="op">%$%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/matplot.html">matplot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">Fit</span>, <span class="va">Lower.Band</span>, <span class="va">Upper.Band</span><span class="op">)</span>, type <span class="op">=</span>  <span class="st">"l"</span>, lty <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>, <span class="st">"blue"</span>, <span class="st">"blue"</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="va">h</span><span class="op">]</span><span class="op">)</span>, ylab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span><span class="op">[</span><span class="va">h</span><span class="op">]</span><span class="op">)</span>, main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="fu">.</span><span class="op">(</span><span class="fl">100</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="st">"% Confidence band"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"lightgrey"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.5</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu">bar</span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">)</span> , col <span class="op">=</span> <span class="st">"darkgrey"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-inference_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-9-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-9-2-tab">
<div class="cell">
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate W multiplier = 2 F_crit(regression = of coefficients, residual)</span></span>
<span><span class="co"># degrees of freedom</span></span>
<span><span class="co"># -&gt; numerator -&gt; = df regression (# of coefficients) = 2 for SLR</span></span>
<span><span class="co"># -&gt; denominator -&gt; df residual (n - # of coefficients) = n - 2 for SLR</span></span>
<span><span class="co"># probability -&gt; F is right-tailed, so need to use 1 - alpha now</span></span>
<span><span class="co"># -&gt; no dividing by two or taking absolute value</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span><span class="op">(</span><span class="va">W</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span>, df1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span>, df2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.584719</code></pre>
</div>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare W to t at a specific X_h</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.048407</code></pre>
</div>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate confidence bands</span></span>
<span><span class="co"># -&gt; use seq of x values from before</span></span>
<span><span class="co"># -&gt; get the fits and se(estimation) for each new x</span></span>
<span><span class="co"># -&gt; calculate lower and upper confidence band limits = Y_h-hat +- W * se(estimation)</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">se_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, se.fit <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">$</span><span class="va">se.fit</span></span>
<span><span class="va">lower</span> <span class="op">&lt;-</span> <span class="va">fit</span> <span class="op">-</span> <span class="va">W</span> <span class="op">*</span> <span class="va">se_fit</span></span>
<span><span class="va">upper</span> <span class="op">&lt;-</span> <span class="va">fit</span> <span class="op">+</span> <span class="va">W</span> <span class="op">*</span> <span class="va">se_fit</span></span>
<span></span>
<span><span class="co"># combine above info</span></span>
<span><span class="va">data_conf_band</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x_h <span class="op">=</span> <span class="va">x_h</span><span class="op">$</span><span class="va">x</span>, <span class="va">fit</span>, <span class="va">se_fit</span>, <span class="va">lower</span>, <span class="va">upper</span>, width <span class="op">=</span> <span class="va">upper</span> <span class="op">-</span> <span class="va">lower</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># illustrate process of confidence bands over X range</span></span>
<span><span class="va">data_conf_band</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">kable</span><span class="op">(</span>col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"X_h"</span>, <span class="st">"fit = Y_h-hat"</span>, <span class="st">"SE(fit) = S_{Y_h-hat}"</span>, <span class="st">"LB = Y_h-hat - W x S_{Y_h-hat}"</span>, <span class="st">"UB = $Y_h-hat + W x S_{Y_h-hat}$"</span>, <span class="st">"Width"</span><span class="op">)</span>,</span>
<span>        digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">kable_styling</span><span class="op">(</span>full_width <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                position <span class="op">=</span> <span class="st">"left"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">X_h</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">fit = Y_h-hat</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">SE(fit) = S_{Y_h-hat}</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">LB = Y_h-hat - W x S_{Y_h-hat}</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">UB = $Y_h-hat + W x S_{Y_h-hat}$</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Width</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">5.075</td>
<td style="text-align: right;">25.452</td>
<td style="text-align: right;">3.166</td>
<td style="text-align: right;">17.268</td>
<td style="text-align: right;">33.637</td>
<td style="text-align: right;">16.369</td>
</tr>
<tr class="even">
<td style="text-align: right;">5.564</td>
<td style="text-align: right;">27.953</td>
<td style="text-align: right;">2.937</td>
<td style="text-align: right;">20.361</td>
<td style="text-align: right;">35.545</td>
<td style="text-align: right;">15.184</td>
</tr>
<tr class="odd">
<td style="text-align: right;">6.053</td>
<td style="text-align: right;">30.454</td>
<td style="text-align: right;">2.715</td>
<td style="text-align: right;">23.436</td>
<td style="text-align: right;">37.472</td>
<td style="text-align: right;">14.036</td>
</tr>
<tr class="even">
<td style="text-align: right;">6.542</td>
<td style="text-align: right;">32.955</td>
<td style="text-align: right;">2.502</td>
<td style="text-align: right;">26.488</td>
<td style="text-align: right;">39.423</td>
<td style="text-align: right;">12.935</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7.031</td>
<td style="text-align: right;">35.456</td>
<td style="text-align: right;">2.301</td>
<td style="text-align: right;">29.509</td>
<td style="text-align: right;">41.403</td>
<td style="text-align: right;">11.894</td>
</tr>
<tr class="even">
<td style="text-align: right;">7.520</td>
<td style="text-align: right;">37.957</td>
<td style="text-align: right;">2.114</td>
<td style="text-align: right;">32.492</td>
<td style="text-align: right;">43.423</td>
<td style="text-align: right;">10.931</td>
</tr>
<tr class="odd">
<td style="text-align: right;">8.009</td>
<td style="text-align: right;">40.458</td>
<td style="text-align: right;">1.947</td>
<td style="text-align: right;">35.425</td>
<td style="text-align: right;">45.491</td>
<td style="text-align: right;">10.066</td>
</tr>
<tr class="even">
<td style="text-align: right;">8.498</td>
<td style="text-align: right;">42.959</td>
<td style="text-align: right;">1.805</td>
<td style="text-align: right;">38.295</td>
<td style="text-align: right;">47.624</td>
<td style="text-align: right;">9.329</td>
</tr>
<tr class="odd">
<td style="text-align: right;">8.986</td>
<td style="text-align: right;">45.460</td>
<td style="text-align: right;">1.693</td>
<td style="text-align: right;">41.085</td>
<td style="text-align: right;">49.836</td>
<td style="text-align: right;">8.751</td>
</tr>
<tr class="even">
<td style="text-align: right;">9.475</td>
<td style="text-align: right;">47.961</td>
<td style="text-align: right;">1.618</td>
<td style="text-align: right;">43.778</td>
<td style="text-align: right;">52.144</td>
<td style="text-align: right;">8.365</td>
</tr>
<tr class="odd">
<td style="text-align: right;">9.964</td>
<td style="text-align: right;">50.462</td>
<td style="text-align: right;">1.586</td>
<td style="text-align: right;">46.362</td>
<td style="text-align: right;">54.562</td>
<td style="text-align: right;">8.199</td>
</tr>
<tr class="even">
<td style="text-align: right;">10.453</td>
<td style="text-align: right;">52.963</td>
<td style="text-align: right;">1.599</td>
<td style="text-align: right;">48.830</td>
<td style="text-align: right;">57.096</td>
<td style="text-align: right;">8.266</td>
</tr>
<tr class="odd">
<td style="text-align: right;">10.942</td>
<td style="text-align: right;">55.464</td>
<td style="text-align: right;">1.656</td>
<td style="text-align: right;">51.184</td>
<td style="text-align: right;">59.744</td>
<td style="text-align: right;">8.559</td>
</tr>
<tr class="even">
<td style="text-align: right;">11.431</td>
<td style="text-align: right;">57.965</td>
<td style="text-align: right;">1.752</td>
<td style="text-align: right;">53.436</td>
<td style="text-align: right;">62.494</td>
<td style="text-align: right;">9.058</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11.920</td>
<td style="text-align: right;">60.466</td>
<td style="text-align: right;">1.882</td>
<td style="text-align: right;">55.600</td>
<td style="text-align: right;">65.331</td>
<td style="text-align: right;">9.731</td>
</tr>
<tr class="even">
<td style="text-align: right;">12.409</td>
<td style="text-align: right;">62.967</td>
<td style="text-align: right;">2.040</td>
<td style="text-align: right;">57.695</td>
<td style="text-align: right;">68.239</td>
<td style="text-align: right;">10.544</td>
</tr>
<tr class="odd">
<td style="text-align: right;">12.898</td>
<td style="text-align: right;">65.468</td>
<td style="text-align: right;">2.218</td>
<td style="text-align: right;">59.734</td>
<td style="text-align: right;">71.202</td>
<td style="text-align: right;">11.468</td>
</tr>
<tr class="even">
<td style="text-align: right;">13.387</td>
<td style="text-align: right;">67.969</td>
<td style="text-align: right;">2.414</td>
<td style="text-align: right;">61.730</td>
<td style="text-align: right;">74.208</td>
<td style="text-align: right;">12.478</td>
</tr>
<tr class="odd">
<td style="text-align: right;">13.876</td>
<td style="text-align: right;">70.470</td>
<td style="text-align: right;">2.622</td>
<td style="text-align: right;">63.692</td>
<td style="text-align: right;">77.247</td>
<td style="text-align: right;">13.555</td>
</tr>
<tr class="even">
<td style="text-align: right;">14.365</td>
<td style="text-align: right;">72.971</td>
<td style="text-align: right;">2.841</td>
<td style="text-align: right;">65.629</td>
<td style="text-align: right;">80.313</td>
<td style="text-align: right;">14.684</td>
</tr>
</tbody>
</table>
</div>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare results to ci.reg(type = "w)</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu">ALSM</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ALSM/man/6_ci.reg.html">ci.reg</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">x_h</span>, type <span class="op">=</span> <span class="st">"w"</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">data_conf_band</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">4</span>,<span class="fl">5</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
     x  Fit Lower.Band Upper.Band
1 TRUE TRUE       TRUE       TRUE
2 TRUE TRUE       TRUE       TRUE
3 TRUE TRUE       TRUE       TRUE
4 TRUE TRUE       TRUE       TRUE
5 TRUE TRUE       TRUE       TRUE
6 TRUE TRUE       TRUE       TRUE

$`head(ALSM::ci.reg(mod, newdata = x_h, type = "w", alpha = 0.05))`
         x      Fit Lower.Band Upper.Band
1 5.075098 25.45240   17.26791   33.63689
2 5.564014 27.95336   20.36136   35.54535
3 6.052930 30.45432   23.43627   37.47237
4 6.541846 32.95528   26.48768   39.42287
5 7.030762 35.45624   29.50908   41.40339
6 7.519678 37.95719   32.49188   43.42251

$`head(data_conf_band[, c(1, 2, 4, 5)])`
       x_h      fit    lower    upper
1 5.075098 25.45240 17.26791 33.63689
2 5.564014 27.95336 20.36136 35.54535
3 6.052930 30.45432 23.43627 37.47237
4 6.541846 32.95528 26.48768 39.42287
5 7.030762 35.45624 29.50908 41.40339
6 7.519678 37.95719 32.49188 43.42251</code></pre>
</div>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">data_conf_band</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       x_h      fit   se_fit    lower    upper    width
1 5.075098 25.45240 3.166491 17.26791 33.63689 16.36898
2 5.564014 27.95336 2.937262 20.36136 35.54535 15.18399
3 6.052930 30.45432 2.715209 23.43627 37.47237 14.03610
4 6.541846 32.95528 2.502244 26.48768 39.42287 12.93519
5 7.030762 35.45624 2.300891 29.50908 41.40339 11.89431
6 7.519678 37.95719 2.114471 32.49188 43.42251 10.93063</code></pre>
</div>
</div>
</div>
<div id="tabset-9-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-9-3-tab">
<div class="cell">
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># demo to verify what geom_smooth() gives</span></span>
<span></span>
<span><span class="co"># results</span></span>
<span><span class="co"># -&gt; lm regression lines line up as expected, BUT...</span></span>
<span><span class="co"># -&gt; the confidence bands using se = TRUE are actually the lower and upper **pointwise** confidence interval around the mean</span></span>
<span><span class="co"># -&gt; ** this means it is plotting ALL of the INDIVIDUAL CIs for E(Y_h), whereas Working-Hotelling confidence bands represent a confidence "interval" for the ENTIRE regression line</span></span>
<span></span>
<span><span class="co"># create dataframe of original observations the model was built on</span></span>
<span><span class="va">data_original</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># set t multiplier for making single interval estimates of E(Y_h)</span></span>
<span><span class="va">t_crit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create confidence band demo plotting dataset</span></span>
<span><span class="co"># -&gt; rename current lower and upper to have an indication of W multiplier</span></span>
<span><span class="co"># -&gt; calculate new lower and upper bounds based on t multiplier</span></span>
<span><span class="co"># -&gt; remove unneeded columns for plot</span></span>
<span><span class="co"># -&gt; reshaoe to long with to long with and columns for type of bound and value</span></span>
<span><span class="co"># -&gt; create indicator variable for type of multiplier used in calculating the lower and upper bounds (check what suffix is of bound) and then remove multiplier indication from bound column (just take off suffix)</span></span>
<span><span class="va">data_conf_band_plot</span> <span class="op">&lt;-</span> <span class="va">data_conf_band</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">rename</span><span class="op">(</span>lower_w <span class="op">=</span> <span class="va">lower</span>,</span>
<span>         upper_w <span class="op">=</span> <span class="va">upper</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>lower_t <span class="op">=</span> <span class="va">fit</span> <span class="op">-</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_fit</span>,</span>
<span>         upper_t <span class="op">=</span> <span class="va">fit</span> <span class="op">+</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="va">se_fit</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">width</span>, <span class="va">se_fit</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">pivot_longer</span><span class="op">(</span>cols <span class="op">=</span> <span class="fu">starts_with</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lower"</span>, <span class="st">"upper"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>               names_to <span class="op">=</span> <span class="st">"bound"</span>,</span>
<span>               values_to <span class="op">=</span> <span class="st">"value"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>multiplier <span class="op">=</span> </span>
<span>           <span class="fu">case_when</span><span class="op">(</span></span>
<span>             <span class="fu">str_sub</span><span class="op">(</span><span class="va">bound</span>, start <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">==</span> <span class="st">"t"</span> <span class="op">~</span> <span class="st">"t"</span>,</span>
<span>             <span class="cn">TRUE</span> <span class="op">~</span> <span class="st">"W"</span><span class="op">)</span>,</span>
<span>         bound <span class="op">=</span> <span class="fu">str_sub</span><span class="op">(</span><span class="va">bound</span>, end <span class="op">=</span> <span class="op">-</span><span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create demo plot</span></span>
<span><span class="co"># layer:  geom_smooth()</span></span>
<span><span class="co"># -&gt; this adds regression line</span></span>
<span><span class="co"># -&gt; se + TRUE adds the shaded ribbon representing "confidence bands"</span></span>
<span><span class="co"># layer: geom_line() first one</span></span>
<span><span class="co"># -&gt; add manually calculated regression line, should line up exactly with above</span></span>
<span><span class="co"># layer: geom_line() second and third ones</span></span>
<span><span class="co"># -&gt; confidence bands for both multipliers</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>,</span>
<span>                  y <span class="op">=</span> <span class="va">y</span><span class="op">)</span>,</span>
<span>              data <span class="op">=</span> <span class="va">data_original</span>,</span>
<span>              method <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>              formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span>,</span>
<span>              level <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span>,</span>
<span>              se <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>              color <span class="op">=</span> <span class="st">"yellow"</span>,</span>
<span>              linewidth <span class="op">=</span> <span class="fl">1</span>,</span>
<span>              alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_h</span>,</span>
<span>                y <span class="op">=</span> <span class="va">fit</span><span class="op">)</span>,</span>
<span>            data <span class="op">=</span> <span class="va">data_conf_band_plot</span>,</span>
<span>            color <span class="op">=</span> <span class="st">"red"</span>,</span>
<span>            linewidth <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_h</span>,</span>
<span>                y <span class="op">=</span> <span class="va">value</span>,</span>
<span>                color <span class="op">=</span> <span class="va">multiplier</span><span class="op">)</span>,</span>
<span>            data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">data_conf_band_plot</span>, <span class="va">bound</span> <span class="op">==</span> <span class="st">"lower"</span><span class="op">)</span>,</span>
<span>            linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_h</span>,</span>
<span>                y <span class="op">=</span> <span class="va">value</span>,</span>
<span>                color <span class="op">=</span> <span class="va">multiplier</span><span class="op">)</span>,</span>
<span>            data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">data_conf_band_plot</span>, <span class="va">bound</span> <span class="op">==</span> <span class="st">"upper"</span><span class="op">)</span>,</span>
<span>            linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span>name <span class="op">=</span> <span class="st">"Multiplier"</span>, values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>t <span class="op">=</span> <span class="st">"purple"</span>, W <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Demo of confidence bands"</span>,</span>
<span>       x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="va">h</span><span class="op">]</span><span class="op">)</span>,</span>
<span>       y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span><span class="op">[</span><span class="va">h</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-inference_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Where the multipliers are <span class="math inline">\(t_{\alpha / 2, n - p}\)</span> and <span class="math inline">\(W = 2 \cdot F_{1 - \alpha; p, n - p}\)</span>.</p>
</div>
</div>
</div>
</section><section id="analysis-of-variance-approach-to-regression" class="level2" data-number="2.6"><h2 data-number="2.6" class="anchored" data-anchor-id="analysis-of-variance-approach-to-regression">
<span class="header-section-number">2.6</span> Analysis of variance approach to regression</h2>
<ul>
<li>This approach is very useful for multiple linear regression and other types of linear statistical models.</li>
</ul>
<section id="partitioning-of-total-sum-of-squares" class="level3" data-number="2.6.1"><h3 data-number="2.6.1" class="anchored" data-anchor-id="partitioning-of-total-sum-of-squares">
<span class="header-section-number">2.6.1</span> Partitioning of total sum of squares</h3>
<p>Overview</p>
<ul>
<li><p>In a regression setting, analysis of variance (ANOVA) allows us to capture the different sources of variability in the model.</p></li>
<li><p>We do this by partitioning the sums of squares and degrees of freedom associated with the the response variable <span class="math inline">\(Y\)</span>.</p></li>
</ul>
<p><img src="files/images/ss-breakdown.png" class="img-fluid" style="width:100.0%"></p>
<p>Types of sum of squares</p>
<ul>
<li>Total sum of squares → Measured in terms of the deviations of the <span class="math inline">\(Y_i\)</span> around their mean <span class="math inline">\(\bar{Y}\)</span>.</li>
</ul>
<p><span class="math display">\[
SSTO = \sum (Y_i - \bar{Y})^2 = S_{YY}
\]</span></p>
<ul>
<li><p>Measures the total variation of <span class="math inline">\(Y\)</span>, which tells us the uncertainty related to <span class="math inline">\(Y\)</span> when the predictor variable <span class="math inline">\(X\)</span> is <em>not</em> taken into account.</p></li>
<li><p>If all observations are the same, then <span class="math inline">\(SSTO = 0\)</span>. More variation in <span class="math inline">\(Y_i\)</span>, the larger <span class="math inline">\(SSTO\)</span> is.</p></li>
<li><p>Sum of squares error → Measured in terms of the deviations of the <span class="math inline">\(Y_i\)</span> around the fitted regression line <span class="math inline">\(\hat{Y_i}\)</span> (i.e.&nbsp;the residuals <span class="math inline">\(e_i\)</span>).</p></li>
</ul>
<p><span class="math display">\[
SSE = \sum (Y_i - \hat{Y_i})^2
\]</span></p>
<ul>
<li><p>Measures the remaining variation / uncertainty in the <span class="math inline">\(Y_i\)</span>’s after we utilize the predictor variable <span class="math inline">\(X\)</span> (i.e.&nbsp;“unexplained” variation).</p></li>
<li><p>If all observations fall on the fitted line, <span class="math inline">\(SSE = 0\)</span>. More variation in <span class="math inline">\(Y\)</span> around the fitted line, the larger <span class="math inline">\(SSE\)</span> is.</p></li>
<li><p>Sum of squares regression → Measured in terms of the deviations of the fitted <span class="math inline">\(\hat{Y_i}\)</span> around their mean <span class="math inline">\(\bar{Y}\)</span>.</p></li>
</ul>
<p><span class="math display">\[
SSR = \sum (\hat{Y_i} - \bar{Y})^2
\]</span></p>
<ul>
<li><p>Measures the variation in the <span class="math inline">\(Y_i\)</span>’s that is associated with the regression line.</p></li>
<li><p>In other words, it measures the variation in the <span class="math inline">\(Y_i\)</span>’s that is accounted for by the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> (i.e.&nbsp;“explained” variation). We are essentially upgrading our original prediction for <span class="math inline">\(Y\)</span> from <span class="math inline">\(\bar{Y}\)</span> to now <span class="math inline">\(\hat{Y}\)</span>; so this <span class="math inline">\(\approx\)</span> (conceptually) measures how much better the predictions become.</p></li>
<li><p>So, the larger <span class="math inline">\(SSR\)</span> is in relation to <span class="math inline">\(SSTO\)</span>, the greater is the effect of the regression relation in accounting for the total variation in the <span class="math inline">\(Y_i\)</span> observations.</p></li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-10-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-1" role="tab" aria-controls="tabset-10-1" aria-selected="true">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-10-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-2" role="tab" aria-controls="tabset-10-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-10-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-10-1-tab">
<ul>
<li>Partitioning individual deviations</li>
</ul>
<p><img src="files/images/partitioning-deviations.png" class="img-fluid" style="width:30.0%"></p>
<ul>
<li>
<p>The two components are:</p>
<ol type="1">
<li>The deviation of the fitted value <span class="math inline">\(\hat{Y_i}\)</span> around the mean <span class="math inline">\(\bar{Y}\)</span>.</li>
<li>The deviation of the observation <span class="math inline">\(Y_i\)</span> around the fitted regression line.</li>
</ol>
</li>
<li><p>This relationship holds for the sum of the squared deviations as well:</p></li>
</ul>
<p><span class="math display">\[
\begin{align*}
  \sum (Y_i - \bar{Y})^2 &amp;= \sum (\hat{Y_i} - \bar{Y})^2 + \sum (Y_i - \hat{Y_i})^2\\
  SSTO &amp;= SSR + SSE
\end{align*}
\]</span></p>
</div>
<div id="tabset-10-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-10-2-tab">
<ul>
<li>Partitioning total sum of squares</li>
</ul>
<p><img src="files/images/partition-ss-proof.png" class="img-fluid" style="width:50.0%"></p>
<ul>
<li>The formulas for <span class="math inline">\(SSTO\)</span>, <span class="math inline">\(SSE\)</span> and <span class="math inline">\(SSR\)</span> above are best for computations. But an alternate form of <span class="math inline">\(SSR\)</span> is useful for deriving analytical results is shown below:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  SSR &amp;= \sum [\hat{Y_i} - \bar{Y}]^2 \\
      &amp;= \sum [(\hat{\beta}_0 + \hat{\beta}_1 X_i) - \bar{Y}]^2 \\
      &amp;= \sum [(\bar{Y} - \hat{\beta}_1 \bar{X}) + \hat{\beta}_1 X_i - \bar{Y}]^2 \\
      &amp;= \hat{\beta}_1^2 \sum [X_i - \bar{X}]^2
\end{align*}
\]</span></p>
</div>
</div>
</div>
</section><section id="breakdown-of-degrees-of-freedom" class="level3" data-number="2.6.2"><h3 data-number="2.6.2" class="anchored" data-anchor-id="breakdown-of-degrees-of-freedom">
<span class="header-section-number">2.6.2</span> Breakdown of degrees of freedom</h3>
<p>Degrees of freedom for each sum of square</p>
<ul>
<li>
<p><span class="math inline">\(SSTO\)</span> → Has <span class="math inline">\(n-1\)</span> degrees of freedom associated with it.</p>
<ul>
<li><p>One degree of freedom is lost because the deviations <span class="math inline">\(Y_i - \bar{Y}\)</span> are subject to one constraint: they must sum to zero (<span class="math inline">\(\sum (Y_i - \bar{Y}) = 0\)</span>).</p></li>
<li><p>Equivalently, one degree of freedom is lost because the sample mean <span class="math inline">\(\bar{Y}\)</span> is used to estimate the population mean.</p></li>
</ul>
</li>
<li>
<p><span class="math inline">\(SSE\)</span> → Has <span class="math inline">\(n-2\)</span> degrees of freedom associated with it.</p>
<ul>
<li>Two degrees of freedom are lost because the two parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are estimated in obtaining the fitted values <span class="math inline">\(\hat{Y_i}\)</span>.</li>
</ul>
</li>
<li>
<p><span class="math inline">\(SSR\)</span> → Has 1 degrees of freedom associated with it.</p>
<ul>
<li><p>Although there are <span class="math inline">\(n\)</span> deviations <span class="math inline">\(\hat{Y_i} - \bar{Y}\)</span>, all fitted values are calculated from the same estimated regression line. So the regression line just has two degrees of freedom (corresponding to the slope and intercept, for SLR <span class="math inline">\(p = 2\)</span>)…</p></li>
<li><p>BUT then, one degree of freedom is lost because again we have to estimate the mean in order to calculate <span class="math inline">\(\sum (\hat{Y_i} - \bar{Y})^2\)</span>, thus <span class="math inline">\(p - 1\)</span> <span class="math inline">\(\Longleftrightarrow\)</span> the deviations <span class="math inline">\(\hat{Y_i} - \bar{Y}\)</span> are subject to one constraint: they must sum to zero.</p></li>
</ul>
</li>
<li><p>(Note: The constraints on the deviations come from the properties of the fitted LSE line.)</p></li>
</ul>
<p>Property of degrees of freedom</p>
<ul>
<li>Dfs are additive</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  n - 1 &amp;= 1 + (n-2) \\
  df_{TO} &amp;= df_{R} +df_{E}
\end{align*}
\]</span></p>
</section><section id="mean-squares" class="level3" data-number="2.6.3"><h3 data-number="2.6.3" class="anchored" data-anchor-id="mean-squares">
<span class="header-section-number">2.6.3</span> Mean squares</h3>
<ul>
<li><p>General definition → A sum of squares divided by its associated degrees of freedom is called a mean square (<span class="math inline">\(MS\)</span>).</p></li>
<li>
<p>Two mean squares</p>
<ul>
<li>Mean square regression:</li>
</ul>
<p><span class="math display">\[MSR = \frac{SSR}{df_R} = \frac{SSR}{1}\]</span></p>
<ul>
<li>Mean square error:</li>
</ul>
<p><span class="math display">\[MSE = \frac{SSR}{df_E} = \frac{SSE}{n-2}\]</span></p>
</li>
<li><p>Note → Mean squares are not additive <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(MSR + MSE \ne MSTO\)</span></p></li>
</ul></section><section id="anova-table" class="level3" data-number="2.6.4"><h3 data-number="2.6.4" class="anchored" data-anchor-id="anova-table">
<span class="header-section-number">2.6.4</span> ANOVA table</h3>
<ul>
<li><p>The breakdowns of the total sum of squares and associated degrees of freedom are displayed in the form of an analysis of variance table.</p></li>
<li><p>Below shows an extra column for expected mean squares, which will be needed for inference (usual ANOVA tables have everything except this column).</p></li>
</ul>
<table class="table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">Source of Variation</th>
<th style="text-align: left;"><span class="math inline">\(df\)</span></th>
<th style="text-align: left;"><span class="math inline">\(SS\)</span></th>
<th style="text-align: left;"><span class="math inline">\(MS\)</span></th>
<th style="text-align: left;"><span class="math inline">\(E(MS)\)</span></th>
<th style="text-align: left;"><span class="math inline">\(F\)</span></th>
<th>
<span class="math inline">\(p\)</span>-value</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Regression</td>
<td style="text-align: left;"><span class="math inline">\(df_R = 1\)</span></td>
<td style="text-align: left;">
<span class="math inline">\(SSR = \sum (\hat{Y_i} - \bar{Y})^2\)</span> 1</td>
<td style="text-align: left;"><span class="math inline">\(MSR = \frac{SSR}{1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\sigma^2 + \beta_1 \sum (X_i - \bar{X})^2\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\frac{MSR}{MSE}\)</span></td>
<td><span class="math inline">\(P(F_{(df_R, df_E)} &gt; F)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Error</td>
<td style="text-align: left;"><span class="math inline">\(df_E = n - 2\)</span></td>
<td style="text-align: left;"><span class="math inline">\(SSE = \sum (Y_i - \hat{Y_i})^2\)</span></td>
<td style="text-align: left;"><span class="math inline">\(MSE = \frac{SSE}{n-2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\sigma^2\)</span></td>
<td style="text-align: left;"></td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: left;"><span class="math inline">\(df_{TO} = n -1\)</span></td>
<td style="text-align: left;"><span class="math inline">\(SSTO = \sum (Y_i - \bar{Y})^2\)</span></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><p>Could convert <span class="math inline">\(SSTO = S_{YY}\)</span> to a mean square as well by dividing by <span class="math inline">\(df_{TO} = n - 1\)</span> → This gives us <span class="math inline">\(\frac{1}{n - 1}{\sum (Y_i - \bar{Y})^2}\)</span> = Sample variance of <span class="math inline">\(Y_i\)</span> (totally unrelated to the regression line; just the variance of a set of numbers, which is technically a mean square).</p></li>
<li><p>This is different than the regression <span class="math inline">\(S^2 = MSE\)</span> which is an estimate of the error variance which is found by taking the deviations relative to the fitted line (not <span class="math inline">\(bar{Y}\)</span>).</p></li>
</ul>
<p>Demo</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-11-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-1" role="tab" aria-controls="tabset-11-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-11-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-2" role="tab" aria-controls="tabset-11-2" aria-selected="false">Manual</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-11-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-3" role="tab" aria-controls="tabset-11-3" aria-selected="false">Properties</a></li>
</ul>
<div class="tab-content">
<div id="tabset-11-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-11-1-tab">
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb85"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># initialize items</span></span>
<span><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span>; <span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">2</span>; <span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="fl">3</span>; <span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">15</span> </span>
<span></span>
<span><span class="co"># generate data</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">5</span>, max <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">x</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># now introducing another function to fit models and the different results / outputs from each</span></span>
<span></span>
<span><span class="co"># fit equivalent models</span></span>
<span><span class="co"># -&gt; lm() fits linear models</span></span>
<span><span class="co"># --&gt; also one-way anova (ancova) models, but aov() works better with anova analyses</span></span>
<span><span class="va">mod_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="va">mod_aov</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aov.html">aov</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># the main difference between lm() and aov() is mainly in the form of the output</span></span>
<span></span>
<span><span class="co"># calling (printing) the model object</span></span>
<span><span class="co"># -&gt; for lm object gives estimated coefficients</span></span>
<span><span class="va">mod_lm</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Coefficients:
(Intercept)            x  
     -3.457        3.308  </code></pre>
</div>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># -&gt; for aov object it gives breakdown of SS and df for each variable and sigma estimate</span></span>
<span><span class="va">mod_aov</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call:
   aov(formula = y ~ x)

Terms:
                       x Residuals
Sum of Squares  2797.647  3092.719
Deg. of Freedom        1        28

Residual standard error: 10.50972
Estimated effects may be unbalanced</code></pre>
</div>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># summary() function</span></span>
<span><span class="co"># -&gt; for lm it gives regression-style output, i.e. regression coefficients with standard errors and t-tests</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_lm</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-19.456  -7.245  -1.550   6.543  23.120 

Coefficients:
            Estimate Std. Error t value  Pr(&gt;|t|)    
(Intercept)  -3.4569     6.8870  -0.502      0.62    
x             3.3079     0.6573   5.033 0.0000254 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 10.51 on 28 degrees of freedom
Multiple R-squared:  0.475, Adjusted R-squared:  0.4562 
F-statistic: 25.33 on 1 and 28 DF,  p-value: 0.00002536</code></pre>
</div>
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># -&gt; for aov it gives anova table,which is the same information but represented as sums of squares estimates with F ratios</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_aov</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
x            1   2798  2797.6   25.33 0.0000254 ***
Residuals   28   3093   110.5                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># can switch between the two summaries by calling a summary method</span></span>
<span><span class="co"># -&gt; get anova table from lm object</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/summary.aov.html">summary.aov</a></span><span class="op">(</span><span class="va">mod_lm</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
x            1   2798  2797.6   25.33 0.0000254 ***
Residuals   28   3093   110.5                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># -&gt; get regression-style output from aov object</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/summary.lm.html">summary.lm</a></span><span class="op">(</span><span class="va">mod_aov</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
aov(formula = y ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-19.456  -7.245  -1.550   6.543  23.120 

Coefficients:
            Estimate Std. Error t value  Pr(&gt;|t|)    
(Intercept)  -3.4569     6.8870  -0.502      0.62    
x             3.3079     0.6573   5.033 0.0000254 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 10.51 on 28 degrees of freedom
Multiple R-squared:  0.475, Adjusted R-squared:  0.4562 
F-statistic: 25.33 on 1 and 28 DF,  p-value: 0.00002536</code></pre>
</div>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># alternative (more straight-forward) way to get anova table </span></span>
<span><span class="co"># -&gt; use anova() on lm object &lt;==&gt; anova.lm() -&gt; this is one of the two main uses of this function</span></span>
<span><span class="co"># -&gt; looking for Df, Sum Sq, and Mean Sq</span></span>
<span><span class="co"># --&gt; gives sequential SS (will look into more later)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_lm</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">as.matrix</span> <span class="co"># could do anova(mod_aov), but makes for sense just to do summary() if already have aov object</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Df   Sum Sq   Mean Sq  F value        Pr(&gt;F)
x          1 2797.647 2797.6474 25.32856 0.00002535802
Residuals 28 3092.719  110.4543       NA            NA</code></pre>
</div>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># save usual lm model as another object to simplify notation</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="va">mod_lm</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-11-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-11-2-tab">
<div class="cell">
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># recreating each value in the anova table output</span></span>
<span></span>
<span><span class="co"># degrees of freedom </span></span>
<span><span class="co"># -&gt; regression: each individual coefficient gets 1 df, then lose 1; so for SLR df = 2 - 1 = 1</span></span>
<span><span class="co"># -&gt; error: df = n - # of predictors (p) as usual</span></span>
<span><span class="va">df_e</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="va">df.residual</span></span>
<span><span class="va">df_r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span></span>
<span><span class="co"># sums of squares</span></span>
<span><span class="co"># -&gt; SSR = explained error (improved prediction) -&gt; Y-hat - Y-bar</span></span>
<span><span class="co"># -&gt; SSE = still unexplained error (residuals) -&gt; Y - Y-hat</span></span>
<span><span class="va">ssr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">sse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># mean squares = respective SS / df</span></span>
<span><span class="va">msr</span> <span class="op">&lt;-</span> <span class="va">ssr</span> <span class="op">/</span> <span class="va">df_r</span></span>
<span><span class="va">mse</span> <span class="op">&lt;-</span> <span class="va">sse</span> <span class="op">/</span> <span class="va">df_e</span></span>
<span></span>
<span><span class="co"># combine (organize) into anova table layout for comparison</span></span>
<span><span class="co"># -&gt; fill matrix by column</span></span>
<span><span class="va">at</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">df_r</span>, <span class="va">df_e</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">ssr</span>, <span class="va">sse</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">msr</span>, <span class="va">mse</span><span class="op">)</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span>, byrow <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">at</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"df"</span>, <span class="st">"SS"</span>, <span class="st">"MS"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">at</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="st">"error"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare results to relevant pieces of anova(lm())</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_lm</span><span class="op">)</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>, <span class="va">at</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
            Df Sum Sq Mean Sq
x         TRUE   TRUE    TRUE
Residuals TRUE   TRUE    TRUE

$`anova(mod_lm)[, 1:3]`
          Df Sum Sq Mean Sq
x          1 2797.7 2797.65
Residuals 28 3092.7  110.45

$at
      df       SS        MS
x      1 2797.647 2797.6474
error 28 3092.719  110.4543</code></pre>
</div>
</div>
</div>
<div id="tabset-11-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-11-3-tab">
<div class="cell">
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># demonstrate additive df and SS</span></span>
<span></span>
<span><span class="co"># df total = n - 1 (have to estimate pop mean, so lose 1)</span></span>
<span><span class="va">df_to</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span></span>
<span><span class="co"># SSTO = total deviation (S_YY) -&gt; Y - Y-bar</span></span>
<span><span class="va">ssto</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare pieces from anova to calculated totals</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">[</span>, <span class="st">"Df"</span><span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">[</span>, <span class="st">"Sum Sq"</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">df_to</span>, <span class="va">ssto</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE TRUE

$`c(sum(anova(mod)[, "Df"]), sum(anova(mod)[, "Sum Sq"]))`
[1]   29.000 5890.367

$`c(df_to, ssto)`
[1]   29.000 5890.367</code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section id="expected-mean-squares" class="level3" data-number="2.6.5"><h3 data-number="2.6.5" class="anchored" data-anchor-id="expected-mean-squares">
<span class="header-section-number">2.6.5</span> Expected mean squares</h3>
<p>Goal → In order to make inferences based on the analysis of variance approach, we need to know the expected value of each of the mean squares.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-12-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-1" role="tab" aria-controls="tabset-12-1" aria-selected="true">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-12-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-2" role="tab" aria-controls="tabset-12-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-12-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-12-1-tab">
<ul>
<li><p>The expected value of a mean square is the mean of its sampling distribution and tells us what is being estimated by the mean square.</p></li>
<li><p>It can be shown that:</p></li>
</ul>
<p><span class="math display">\[
\begin{align*}
  E(MSE) &amp;= \sigma^2 \\
  E(MSR) &amp;= \sigma^2 + \beta_1^2 \sum (X_i - \bar{X})^2
\end{align*}
\]</span></p>
<ul>
<li><p>Note that the first result goes with earlier statement that <span class="math inline">\(MSE\)</span> is an unbiased estimator of <span class="math inline">\(\sigma^2\)</span>.</p></li>
<li>
<p>Important implications</p>
<ol type="1">
<li><p>The mean of the sampling distribution of <span class="math inline">\(MSE\)</span> is <span class="math inline">\(\sigma^2\)</span> <em>whether or not</em> <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are linearly related (i.e.&nbsp;whether or not <span class="math inline">\(\beta_1 = 0\)</span>).</p></li>
<li><p>The mean of the sampling distribution of <span class="math inline">\(MSR\)</span> is also <span class="math inline">\(\sigma^2\)</span> when <span class="math inline">\(\beta_1 = 0\)</span>.</p></li>
</ol>
<ul>
<li><p>Thus, when <span class="math inline">\(\beta_1 = 0\)</span>, the sampling distributions of <span class="math inline">\(MSE\)</span> and <span class="math inline">\(MSR\)</span> are located identically and <span class="math inline">\(MSE\)</span> and <span class="math inline">\(MSR\)</span> will tend to be relatively close to each other.</p></li>
<li><p>But, when <span class="math inline">\(\beta_1 \ne 0\)</span>, the mean of the sampling distribution of <span class="math inline">\(MSR\)</span> will be greater than <span class="math inline">\(\sigma^2\)</span> (because <span class="math inline">\(\beta_1^2 \sum (X_i - \bar{X})^2\)</span> then must be positive) and therefore located to the right of that of <span class="math inline">\(MSE\)</span>. So, <span class="math inline">\(MSR\)</span> will tend to be larger than <span class="math inline">\(MSE\)</span>.</p></li>
<li><p>These results suggest that a comparison of <span class="math inline">\(MSR\)</span> and <span class="math inline">\(MSE\)</span> is useful for testing whether or not <span class="math inline">\(\beta_1 = 0\)</span>.</p></li>
</ul>
</li>
</ul>
</div>
<div id="tabset-12-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-12-2-tab">
<p><img src="files/images/placeholder.png" class="img-fluid" style="width:50.0%"></p>
</div>
</div>
</div>
</section></section><section id="f-test-of-beta_1-0-vs-beta_1-ne-0" class="level2" data-number="2.7"><h2 data-number="2.7" class="anchored" data-anchor-id="f-test-of-beta_1-0-vs-beta_1-ne-0">
<span class="header-section-number">2.7</span> <span class="math inline">\(F\)</span> test of <span class="math inline">\(\beta_1 = 0\)</span> vs <span class="math inline">\(\beta_1 \ne 0\)</span>
</h2>
<p>Overview</p>
<ul>
<li>The analysis of variance approach lets us perform very useful test for regression models (and other linear statistical models).</li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-13-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-1" role="tab" aria-controls="tabset-13-1" aria-selected="true">Results</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-13-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-2" role="tab" aria-controls="tabset-13-2" aria-selected="false">Derivation</a></li>
</ul>
<div class="tab-content">
<div id="tabset-13-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-13-1-tab">
<p>Test on slope</p>
<ul>
<li>Hypotheses → For the SLR, ANOVA gives us a test for:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  H_0 &amp;: \beta_1 = 0 \\
  H_A &amp;: \beta_1 \ne 0
\end{align*}
\]</span></p>
<ul>
<li>Test statistic → For ANOVA, the test statistic <span class="math inline">\(F^*\)</span> compares <span class="math inline">\(MSR\)</span> and <span class="math inline">\(MSE\)</span>
</li>
</ul>
<p><span class="math display">\[
TS = F^* = \frac{MSR}{MSE}
\]</span></p>
<ul>
<li><p>(see derivation) Under <span class="math inline">\(H_0: \beta_1 = 0\)</span> → <span class="math inline">\(F^* \sim \text{F}\,_{(1, n-2)}\)</span></p></li>
<li>
<p>Rejection region and p-value</p>
<ul>
<li>
<span class="math inline">\(F^*\)</span> values near 1 support <span class="math inline">\(H_0\)</span> and large <span class="math inline">\(F^*\)</span> values support <span class="math inline">\(H_A\)</span> (if the model is useful, we expect <span class="math inline">\(MSR\)</span> to be large compared to <span class="math inline">\(MSE\)</span>) <span class="math inline">\(\Longrightarrow\)</span> Upper-tailed test.</li>
</ul>
</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  RR &amp;= \{F^* &gt; F_{(1 - \alpha;\, 1, n - 2)}\} \\
  p\text{-value} &amp;= P(F_{(1, n-2)} \ge F^*)
\end{align*}
\]</span></p>
<ul>
<li><p>Note → <span class="math inline">\(F_{(1-\alpha;\,1,n-2)}\)</span> is the <span class="math inline">\(100 (1-\alpha)\)</span> percentile of the appropriate <span class="math inline">\(F\)</span> distribution (different notation meaning than <span class="math inline">\(t_{\alpha / 2}\)</span> because not a symmetric distribution now).</p></li>
<li>
<p>Decision → Same rules as usual, now just with <span class="math inline">\(F\)</span>-distribution</p>
<ul>
<li>Reject <span class="math inline">\(H_0\)</span> and conclude <span class="math inline">\(H_A\)</span> if <span class="math inline">\(\hspace{10pt}\)</span> <span class="math inline">\(TS \in RR \hspace{10pt} \Longleftrightarrow \hspace{10pt} p\text{-value} \le \alpha\)</span>; Fail to reject <span class="math inline">\(H_0\)</span> if previous not true.</li>
</ul>
</li>
<li>
<p>Conclusion / Interpretation</p>
<ul>
<li>At the <span class="math inline">\(\alpha\)</span> significance level, we &lt; have / do not have &gt; sufficient evidence of a significant linear relationship between &lt; <span class="math inline">\(Y\)</span> context &gt; and &lt; <span class="math inline">\(X\)</span> context &gt;.</li>
</ul>
</li>
</ul>
<p>Equivalence of <span class="math inline">\(F\)</span> test and <span class="math inline">\(t\)</span> test</p>
<ul>
<li>
<p>The <span class="math inline">\(F\)</span>-test is algebraically equivalent to the <em>two-tailed</em> <span class="math inline">\(t\)</span> test → <span class="math inline">\(F^* = (t^*)^2\)</span></p>
<ul>
<li>Same relationship for the critical values when defining the rejection region / p-value → <span class="math inline">\(F_{(1-\alpha; \, 1, n-2)} = t_{\alpha/2, n-2}^2\)</span>.</li>
</ul>
</li>
<li><p>Will get same conclusion either way, but the <span class="math inline">\(t\)</span> test is more flexible because it can be used for one-sided alternatives involving <span class="math inline">\(\beta_1\)</span>, while the <span class="math inline">\(F\)</span> test cannot.</p></li>
</ul>
</div>
<div id="tabset-13-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-13-2-tab">
<p>Sampling distribution of <span class="math inline">\(F^*\)</span></p>
<ul>
<li><p>Goal → In order to be able to construct a statistical decision rule and examine its properties, we need to know the sampling distribution of <span class="math inline">\(F^*\)</span>.</p></li>
<li>
<p>Derivation → Start by considering the sampling distribution of <span class="math inline">\(F^*\)</span> under <span class="math inline">\(H_0: \beta_1 = 0\)</span>. We will use the following theorem:</p>
<ul>
<li>
<strong>Cochran’s theorem</strong> → Let <span class="math inline">\(Y_1, \ldots, Y_{n}\)</span> represent a random sample from the same normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Suppose <span class="math inline">\(SSTO = \sum (Y_i - \bar{Y})^2\)</span> is partitioned into <span class="math inline">\(k\)</span> sums of squares <span class="math inline">\(SS_r\)</span>, each with degrees of freedom <span class="math inline">\(df_r\)</span>. If <span class="math inline">\(\displaystyle \sum_{r=1}^k df_{r} = n - 1\)</span>, then each of the <span class="math inline">\(\frac{SS_r}{\sigma^2}\)</span> terms are independent <span class="math inline">\(\chi^2\)</span> random variables with <span class="math inline">\(df_r\)</span> degrees of freedom.</li>
</ul>
</li>
</ul>
<p><img src="files/images/placeholder.png" class="img-fluid" style="width:50.0%"></p>
<ul>
<li>
<p>Under <span class="math inline">\(H_A: \beta_1 \ne 0\)</span></p>
<ul>
<li>
<span class="math inline">\(F^* \sim \text{Non-central F}\,_{(1, n - 2)}\)</span> with non-centrality parameter <span class="math inline">\(\lambda\)</span>.</li>
<li>Still <span class="math inline">\(SSR \perp \!\!\! \perp SSE\)</span> and <span class="math inline">\(SSE / \sigma^2 \sim \chi^2_{n-2}\)</span>. But the condition that both <span class="math inline">\(SSR / \sigma^2\)</span> and <span class="math inline">\(SSE / \sigma^2\)</span> are <span class="math inline">\(\chi^2\)</span> random variables requires <span class="math inline">\(\beta_1 = 0\)</span>.</li>
</ul>
</li>
</ul>
<p>Equivalence of <span class="math inline">\(F\)</span> test and <span class="math inline">\(t\)</span> test</p>
<p><img src="files/images/placeholder.png" class="img-fluid" style="width:50.0%"></p>
</div>
</div>
</div>
<p>Demo</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-14-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-14-1" role="tab" aria-controls="tabset-14-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-14-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-14-2" role="tab" aria-controls="tabset-14-2" aria-selected="false">Manual</a></li>
</ul>
<div class="tab-content">
<div id="tabset-14-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-14-1-tab">
<div class="cell">
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># continuing previous anova table demo</span></span>
<span></span>
<span><span class="co"># show anova table</span></span>
<span><span class="co"># -&gt; looking for F value` and Pr(&gt;F)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">as.matrix</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Df   Sum Sq   Mean Sq  F value        Pr(&gt;F)
x          1 2797.647 2797.6474 25.32856 0.00002535802
Residuals 28 3092.719  110.4543       NA            NA</code></pre>
</div>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># equivalence of F test and two sided t-test</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">[</span><span class="st">"x"</span>,<span class="st">"F value"</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="st">"x"</span>,<span class="st">"t value"</span><span class="op">]</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`anova(mod)["x", "F value"]`
[1] 25.32856

$`summary(mod)$coefficients["x", "t value"]^2`
[1] 25.32856</code></pre>
</div>
</div>
</div>
<div id="tabset-14-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-14-2-tab">
<div class="cell">
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># continuing to recreate each value in the anova table output</span></span>
<span></span>
<span><span class="co"># calculate F and p-value</span></span>
<span><span class="co"># -&gt; TS F* = MSR / MSE</span></span>
<span><span class="co"># -&gt; p-value = P(F(df reg, df error) &gt; F*)</span></span>
<span><span class="va">F_star</span> <span class="op">&lt;-</span> <span class="va">msr</span> <span class="op">/</span> <span class="va">mse</span></span>
<span><span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">pf</a></span><span class="op">(</span>q <span class="op">=</span> <span class="va">F_star</span>, df1 <span class="op">=</span> <span class="va">df_r</span>, df2 <span class="op">=</span> <span class="va">df_e</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare results to relevant pieces of anova(lm())</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_lm</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">4</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">F_star</span>, <span class="va">p_value</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
  F value Pr(&gt;F)
x    TRUE   TRUE

$`anova(mod_lm)[1, 4:5]`
  F value     Pr(&gt;F)    
x  25.329 0.00002536 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

$`c(F_star, p_value)`
[1] 25.32855920502  0.00002535802</code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section id="general-linear-test-approach" class="level2" data-number="2.8"><h2 data-number="2.8" class="anchored" data-anchor-id="general-linear-test-approach">
<span class="header-section-number">2.8</span> General linear test approach</h2>
<p>Overview</p>
<ul>
<li>
<p>The ANOVA <span class="math inline">\(F\)</span> test above is an example of a <strong>General Linear Test (GLT)</strong> (also called a <strong>global</strong> or an <strong>omnibus</strong> test) for a statistical model, which is an approach that can be used for highly complex tests of linear statistical models, as well as for simple tests.</p>
<ul>
<li>For SLR, the global test (the significance of a model test), the ANVOA <span class="math inline">\(F\)</span> test, and the <span class="math inline">\(t\)</span> test for the linear impact are all equivalent.</li>
</ul>
</li>
<li>
<p>It has three basic steps, which are described in more detail below:</p>
<ol type="1">
<li><p>Fit the full model and obtain the error sum of squares <span class="math inline">\(SSE(F)\)</span>.</p></li>
<li><p>Fit the reduced model under Ho and obtain the error sum of squares <span class="math inline">\(SSE(R)\)</span>.</p></li>
<li><p>Use test statistic / p-value to make decision.</p></li>
</ol>
</li>
</ul>
<p>Full model</p>
<ul>
<li>
<p>Start with the model considered to be appropriate for the data (or the model with all available predictors); this is called the <strong>full / unrestricted model</strong>.</p>
<ul>
<li>For SLR, the full model is just the normal error regression model:</li>
</ul>
</li>
</ul>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \hspace{20pt} \text{Full model}
\]</span></p>
<ul>
<li>We need to fit the full model and get the error sum of squares, denoted <span class="math inline">\(SSE(F)\)</span> (deviations of <span class="math inline">\(Y_i\)</span> and its estimated expected value <span class="math inline">\(\hat{Y_i}\)</span>, which is the fitted regression line). For the full model, we have:</li>
</ul>
<p><span class="math display">\[
SSE(F) = \sum (Y_i - \hat{Y_i})^2 = \sum [Y_i - (\hat{\beta}_0  + \hat{\beta}_1 X_i)]^2 = SSE
\]</span></p>
<ul>
<li>
<em>With a SLR full model</em>, the error sum of squares is the usual <span class="math inline">\(SSE\)</span>.</li>
</ul>
<p>Reduced model</p>
<ul>
<li>Next we consider <span class="math inline">\(H_0\)</span>. For SLR, we have:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  H_0 &amp;: \beta_1 = 0 \hspace{20pt} \text{Reduced model is appropriate} \\
  H_A &amp;: \beta_1 \ne 0 \hspace{20pt} \text{Full model is appropriate}
\end{align*}
\]</span></p>
<ul>
<li>The model under <span class="math inline">\(H_0\)</span> is called the <strong>reduced / restricted model</strong>. When <span class="math inline">\(\beta_1 = 0\)</span>, the full model reduces to:</li>
</ul>
<p><span class="math display">\[
Y_i = \beta_0 + 0 \cdot X_i + \epsilon_i = \beta_0 + \epsilon_i \hspace{20pt} \text{Reduced model}
\]</span></p>
<ul>
<li>
<p>Then we fit the reduced model and again get the error sum of squares, now denoted <span class="math inline">\(SSE(R)\)</span>.</p>
<ul>
<li>
<em>For this particular (a SLR) reduced model</em>, it can easily be shown that the LSE and MLE estimator of <span class="math inline">\(\beta_0\)</span> is <span class="math inline">\(\bar{Y}\)</span>. Thus the estimated expected value of each observation is <span class="math inline">\(\hat{\beta}_0 = \bar{Y}\)</span> and we can get the error sum of squares with:</li>
</ul>
</li>
</ul>
<p><span class="math display">\[
SSE(R) = \sum (Y_i - \hat{Y_i})^2 = \sum (Y_i - \hat{\beta}_0)^2 = \sum (Y_i - \bar{Y})^2 = SSTO
\]</span></p>
<ul>
<li>Thus, <em>for any intercept-only reducted model</em> <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(SSE(R) = SSTO\)</span>.</li>
</ul>
<p>Test statistic and decision</p>
<ul>
<li>
<p>Logic → Now we compare the two sum of squares from the full and reduced model using the fact that the reduced <span class="math inline">\(SSE\)</span> is always greater than or equal to the full <span class="math inline">\(SSE\)</span>.</p>
<ul>
<li>
<span class="math inline">\(SSE(R) \ge SSE(F)\)</span> → More parameters in the model ALWAYS leads to a better fit (i.e.&nbsp;<em>less unexplained</em> variability = <em>more explained</em> variability) <span class="math inline">\(\Longrightarrow\)</span> Smaller are the deviations around the fitted regression function.</li>
</ul>
</li>
<li>
<p>Comparison scenarios</p>
<ol type="1">
<li>
<span class="math inline">\(SSE(F)\)</span> are close <span class="math inline">\(SSE(R)\)</span>
</li>
</ol>
<ul>
<li>Using the full model does not account for much more unexplained variability than does the reduced model <span class="math inline">\(\Longrightarrow\)</span> Added parameters in the full model <em>do not</em> really help to reduce the unexplained variation <span class="math inline">\(\Longrightarrow\)</span> Reduced model is adequate and <span class="math inline">\(H_0\)</span> holds.</li>
</ul>
<ol start="2" type="1">
<li><span class="math inline">\(SSE(R) &lt;&lt; SSE(F)\)</span></li>
</ol>
<ul>
<li>The additional parameters in the full model <em>do</em> help to substantially reduce the unexplained variability in <span class="math inline">\(Y_i\)</span>, which means <span class="math inline">\(H_A\)</span> holds.</li>
</ul>
</li>
<li><p>Test statistic is a function of the difference in two <span class="math inline">\(SSE\)</span>s, relative to the full <span class="math inline">\(SSE\)</span>:</p></li>
</ul>
<p><span class="math display">\[
TS = F^* = \frac{SSE(R) - SSE(F)}{df_R - df_F} \Big/ \frac{SSE(F)}{df_F} = \frac{SSE(R) - SSE(F)}{df_R - df_F}  \Big/ MSE(F)
\]</span></p>
<ul>
<li><p>Under <span class="math inline">\(H_0: \beta_1 = 0 \hspace{10pt} \text{Reduced model}\)</span> → <span class="math inline">\(F^* \sim \text{F}\,_{(df_R - df_F, df_F)}\)</span></p></li>
<li>
<p>Rejection region and p-value</p>
<ul>
<li>Again, we reject for large values of <span class="math inline">\(F^*\)</span> (large difference <span class="math inline">\(SSE(R) - SSE(F)\)</span> supports <span class="math inline">\(H_A\)</span>).</li>
</ul>
</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  RR &amp;= \{F^* &gt; F_{(1 - \alpha;\, df_R - df_F, \, df_F)}\} \\
  p\text{-value} &amp;= P(F_{(df_R - df_F, \, df_F} \ge F^*)
\end{align*}
\]</span></p>
<ul>
<li>For SLR (testing whether or not <span class="math inline">\(\beta_1 = 0\)</span>), we have:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  SSE(R) &amp;= SSTO \hspace{20pt} SSE(F) = SSE \\
  f_R &amp;= n - 1 \hspace{45pt} df_F = n - 2
\end{align*}
\]</span></p>
<ul>
<li>So the test statistic becomes</li>
</ul>
<p><span class="math display">\[
F^* = \frac{SSTO - SSE}{(n - 1) - (n - 2)} \Big/ \frac{SSE}{n - 2} = \frac{SSR}{1} \Big/ \frac{SSE}{n - 2} = \frac{MSR}{MSE}
\]</span></p>
<ul>
<li>This is equivalent to the ANOVA <span class="math inline">\(F\)</span> test shown earlier.</li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-15-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-15-1" role="tab" aria-controls="tabset-15-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-15-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-15-2" role="tab" aria-controls="tabset-15-2" aria-selected="false">Manual</a></li>
</ul>
<div class="tab-content">
<div id="tabset-15-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-15-1-tab">
<div class="cell">
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># using the same data as anova table demos</span></span>
<span></span>
<span><span class="co"># fit full model</span></span>
<span><span class="co"># -&gt; for SLR, full model is E(Y) = B0 + B1 X</span></span>
<span><span class="va">mod_full</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit reduced model</span></span>
<span><span class="co"># -&gt; for SLR, full model is E(Y) = B0</span></span>
<span><span class="co"># -&gt; to fit an intercept-only model, specify 1 on the RHS</span></span>
<span><span class="va">mod_reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># perform general linear test of reduced vs full model</span></span>
<span><span class="co"># -&gt; testing H0: beta_1 = 0 (reduced model) vs HA: beta_1 != 0 (full model)</span></span>
<span><span class="co"># function call</span></span>
<span><span class="co"># -&gt; anova() on multiple lm objects &lt;==&gt; anova.lmlist() -&gt; this is the second main uses of this function</span></span>
<span><span class="co"># -&gt; typically will supply models smallest to largest (this makes for a natural interpretation of the results); but it works regardless</span></span>
<span><span class="co"># -&gt; models MUST BE nested AND fit on the same dataset in order for results to make statistical sense</span></span>
<span><span class="co"># results</span></span>
<span><span class="co"># -&gt; sequentially gives the change in dfs and SS from mod 1 to mod 2 (then from mod 2 to mod 3, and so on...)</span></span>
<span><span class="co"># -&gt; so it is df_1 - df_2 and SS_1 - SS_2 ==&gt; if nested from smallest to largest model, results will all be positive and interpreted as "additional reductions"</span></span>
<span><span class="co"># -&gt; by default, performs F test comparing models in the order specified (again sequentially)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_reduced</span>, <span class="va">mod_full</span>, test <span class="op">=</span> <span class="st">"F"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">as.matrix</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Res.Df      RSS Df Sum of Sq        F        Pr(&gt;F)
1     29 5890.367 NA        NA       NA            NA
2     28 3092.719  1  2797.647 25.32856 0.00002535802</code></pre>
</div>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># demo with more than two models</span></span>
<span><span class="va">mod_squared</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_reduced</span>, <span class="va">mod_full</span>, <span class="va">mod_squared</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">as.matrix</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Res.Df      RSS Df  Sum of Sq          F        Pr(&gt;F)
1     29 5890.367 NA         NA         NA            NA
2     28 3092.719  1 2797.64739 24.6187028 0.00003375526
3     27 3068.256  1   24.46354  0.2152739 0.64638394821</code></pre>
</div>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># demo showing how the sequential comparison works</span></span>
<span><span class="co"># -&gt; above compared mod 1 to mod 2 and then mod 2 to mod 3</span></span>
<span><span class="co"># -&gt; now comparing mod 1 directly to mod 3</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_reduced</span>, <span class="va">mod_squared</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">as.matrix</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Res.Df      RSS Df Sum of Sq        F       Pr(&gt;F)
1     29 5890.367 NA        NA       NA           NA
2     27 3068.256  2  2822.111 12.41699 0.0001500081</code></pre>
</div>
</div>
</div>
<div id="tabset-15-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-15-2-tab">
<div class="cell">
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># general linear test of reduced vs full model</span></span>
<span></span>
<span><span class="co"># using the same data as anova table demos</span></span>
<span></span>
<span><span class="co"># for full model -&gt;  get the corresponding SSE and df </span></span>
<span><span class="co"># -&gt; for SLR, full model is E(Y) = B0 + B1 X</span></span>
<span><span class="va">sse_f</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">mod_full</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">%&gt;%</span> <span class="va">sum</span></span>
<span><span class="va">df_f</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod_full</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># for reduced model -&gt; get the corresponding SSE and df</span></span>
<span><span class="va">sse_r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">mod_reduced</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">%&gt;%</span> <span class="va">sum</span></span>
<span><span class="va">df_r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">mod_reduced</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate F stat and p-value</span></span>
<span><span class="co"># -&gt; using the shortcut for second term: F* = [(SSE(R) - SSE(F)) / (df_R - df_F)] / MSE(F)</span></span>
<span><span class="va">mse_f</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_full</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">F_star</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">(</span><span class="va">sse_r</span> <span class="op">-</span> <span class="va">sse_f</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">df_r</span> <span class="op">-</span> <span class="va">df_f</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="va">mse_f</span></span>
<span><span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">pf</a></span><span class="op">(</span>q <span class="op">=</span> <span class="va">F_star</span>, df1 <span class="op">=</span> <span class="va">df_r</span> <span class="op">-</span> <span class="va">df_f</span>, df2 <span class="op">=</span> <span class="va">df_f</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># combine (organize) into anova table layout for comparison</span></span>
<span><span class="va">at</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">df_r</span>, <span class="va">df_f</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">sse_r</span>, <span class="va">sse_f</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">df_r</span> <span class="op">-</span> <span class="va">df_f</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">sse_r</span> <span class="op">-</span> <span class="va">sse_f</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">F_star</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">p_value</span><span class="op">)</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span>, byrow <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">at</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"df_E Original"</span>, <span class="st">"SSE Original"</span>, <span class="st">"Change df"</span>, <span class="st">"Change SSE"</span>, <span class="st">"F*"</span>, <span class="st">"p-value"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">at</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Mod 1 - Reduced"</span>, <span class="st">"Mod 2 - Full"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare to results from anova(reduced mod, full model)</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_reduced</span>, <span class="va">mod_full</span><span class="op">)</span>, <span class="va">at</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
  Res.Df  RSS   Df Sum of Sq    F Pr(&gt;F)
1   TRUE TRUE   NA        NA   NA     NA
2   TRUE TRUE TRUE      TRUE TRUE   TRUE

$`anova(mod_reduced, mod_full)`
Analysis of Variance Table

Model 1: y ~ 1
Model 2: y ~ x
  Res.Df    RSS Df Sum of Sq      F     Pr(&gt;F)    
1     29 5890.4                                   
2     28 3092.7  1    2797.7 25.329 0.00002536 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

$at
                df_E Original SSE Original Change df Change SSE       F*
Mod 1 - Reduced            29     5890.367        NA         NA       NA
Mod 2 - Full               28     3092.719         1   2797.647 25.32856
                      p-value
Mod 1 - Reduced            NA
Mod 2 - Full    0.00002535802</code></pre>
</div>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># for SLR ==&gt; equivalent to F test on beta 1</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_reduced</span>, <span class="va">mod_full</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span>, <span class="st">"F"</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod_full</span><span class="op">)</span><span class="op">[</span><span class="st">"x"</span>, <span class="st">"F value"</span><span class="op">]</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`anova(mod_reduced, mod_full)[2, "F"]`
[1] 25.32856

$`anova(mod_full)["x", "F value"]`
[1] 25.32856</code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section id="descriptive-measures-of-linear-association-between-x-and-y" class="level2" data-number="2.9"><h2 data-number="2.9" class="anchored" data-anchor-id="descriptive-measures-of-linear-association-between-x-and-y">
<span class="header-section-number">2.9</span> Descriptive measures of linear association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>
</h2>
<p>Overview</p>
<ul>
<li><p>There is no <em>one single measure</em> to completely describe the usefulness of a regression model for a particular application.</p></li>
<li><p>If the goal is estimation of parameters and means and predicting new observations, usefulness of estimates or predictions depends upon the width of the interval and the user’s needs for precision. This can vary from one application to another.</p></li>
<li><p>Rather than making inferences, goals could be to describe the degree of linear association between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>. Again the usefulness of which measure and its value depend on the application.</p></li>
</ul>
<section id="coefficient-of-determination" class="level3" data-number="2.9.1"><h3 data-number="2.9.1" class="anchored" data-anchor-id="coefficient-of-determination">
<span class="header-section-number">2.9.1</span> Coefficient of determination</h3>
<p>Overview</p>
<ul>
<li>A very common measure because of its simplicity is the coefficient of determination <span class="math inline">\(R^2\)</span>, which is a measure of the effect of <span class="math inline">\(X\)</span> in reducing the uncertainty in predicting <span class="math inline">\(Y\)</span>. This reduction in sum of squares (<span class="math inline">\(SSTO - SSE = SSR\)</span>) gets expressed as a proportion:</li>
</ul>
<p><span class="math display">\[
R^2 = \frac{SSR}{SSTO} = 1-\frac{SSE}{SSTO}, \hspace{20pt} \text{range:} \hspace{10pt} 0 \le R^2 \le 1
\]</span> Interpretation</p>
<ul>
<li>
<p>&lt; <span class="math inline">\(R^2 *100\)</span> &gt;% of the variation in &lt; <span class="math inline">\(Y\)</span> context &gt; can be explained by the <em>linear</em> relationship between &lt; <span class="math inline">\(Y\)</span> context &gt; and &lt; <span class="math inline">\(X\)</span> context &gt;.</p>
<ul>
<li>So, the larger <span class="math inline">\(R^2\)</span> is, the more the total variation of <span class="math inline">\(Y\)</span> is reduced by introducing the predictor variable <span class="math inline">\(X\)</span> <span class="math inline">\(\Longleftrightarrow\)</span> greater degree of linear association between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</li>
</ul>
</li>
<li><p>Practically, this indicates the quality of the fit by measuring the proportion of variability explained by the fitted model.</p></li>
<li>
<p>Limiting values</p>
<ul>
<li><p>When the fitted regression line is horizontal (<span class="math inline">\(\hat{\beta}_1 = 0\)</span> and <span class="math inline">\(\hat{Y_i} = \bar{Y}\)</span>) <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(SSE = SSTO\)</span> and <span class="math inline">\(R^2 = 0\)</span>.</p></li>
<li><p>When there is a perfect fit (all of the points lie on the fitted regression line) <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(SSE = 0\)</span> and <span class="math inline">\(R^2 = 1\)</span>.</p></li>
<li><p>In practice, unlikely to be exactly equal to either of these. Also note that context of data (scientific field of the application) has a big impact on general values of <span class="math inline">\(R^2\)</span> and consequently what is interpreted as “strong”.</p></li>
<li><p>If <span class="math inline">\(R^2\)</span> is small, we can consider adding other independent variables that can explain a significant portion of the remaining unexplained variability in the model.</p></li>
</ul>
</li>
</ul>
<p>Limitations of <span class="math inline">\(R^2\)</span></p>
<ul>
<li>
<p>Usefulness in prediction → A high coefficient of determination does not necessarily indicate that useful (precise) predictions can be made.</p>
<ul>
<li>This is because <span class="math inline">\(R^2\)</span> measures only a relative reduction from <span class="math inline">\(SSTO\)</span> and provides no information about absolute precision for estimating a mean response or predicting a new observation.</li>
</ul>
</li>
<li>
<p>Quality of fit → A high coefficient of determination does not necessarily indicate that the estimated regression line is a good fit and similarly an <span class="math inline">\(R^2\)</span> near zero does not necessarily indicate that <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are not related.</p>
<ul>
<li>This is because <span class="math inline">\(R^2\)</span> measures the degree of <em>linear</em> association between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, whereas the actual regression relation may be curvilinear. So make sure to look at the scatterplot.</li>
</ul>
</li>
</ul>
<p><img src="files/images/r2-limitations.png" class="img-fluid" style="width:50.0%"></p>
<p>Inflating <span class="math inline">\(R^2\)</span></p>
<ul>
<li>
<p><span class="math inline">\(X\)</span> level spacing → The value taken by <span class="math inline">\(R^2\)</span> in a given sample tends to be affected by the spacing of the <span class="math inline">\(X\)</span> observations: Wider spacing in <span class="math inline">\(X_i\)</span> <span class="math inline">\(\Longrightarrow\)</span> higher <span class="math inline">\(R^2\)</span>. Here’s why:</p>
<ul>
<li><p>Wider spacing (larger spread) in <span class="math inline">\(X_i\)</span> in the sample when <span class="math inline">\(\hat{\beta}_1 \ne 0\)</span> <span class="math inline">\(\Longrightarrow\)</span> larger spread of the observed <span class="math inline">\(Y_i\)</span> around <span class="math inline">\(\bar{Y}\)</span> <span class="math inline">\(\Longrightarrow\)</span> Larger <span class="math inline">\(SSTO\)</span>.</p></li>
<li><p>And since <span class="math inline">\(SSE\)</span> is unaffected (<span class="math inline">\(V(Y_i) = \sigma^2\)</span> for all <span class="math inline">\(X_i\)</span>), <span class="math inline">\(SSR\)</span> has to increase. Then we can see from either representation <span class="math inline">\(R_2 = SSR/ SSTO = 1 - SSE / SSTO\)</span>, that <span class="math inline">\(R^2\)</span> will increase.</p></li>
<li>
<p>Overfitting → <span class="math inline">\(R^2\)</span> can be artificially inflated by including additional model terms (adding extra predictors).</p>
<ul>
<li><p>This is because <span class="math inline">\(SSR\)</span> always increases with more predictors, even if they are completely unrelated to the response variable.</p></li>
<li><p>Later <span class="math inline">\(R^2_{adj}\)</span> will be discussed which corrects for the inclusion of extra predictors.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Demo</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-16-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-16-1" role="tab" aria-controls="tabset-16-1" aria-selected="true">R functions</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-16-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-16-2" role="tab" aria-controls="tabset-16-2" aria-selected="false">Manual</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-16-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-16-3" role="tab" aria-controls="tabset-16-3" aria-selected="false">Properties</a></li>
</ul>
<div class="tab-content">
<div id="tabset-16-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-16-1-tab">
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb121"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># initialize items</span></span>
<span><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span>; <span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">2</span>; <span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="fl">5</span>; <span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># generate data</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">5</span>, max <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">x</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># fit model</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display summary</span></span>
<span><span class="co"># -&gt; looking for Multiple R-squared</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-35.481  -7.421   0.067   9.760  24.381 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  11.7649     9.6903   1.214 0.234854    
x             3.9357     0.9168   4.293 0.000191 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 13.4 on 28 degrees of freedom
Multiple R-squared:  0.3969,    Adjusted R-squared:  0.3754 
F-statistic: 18.43 on 1 and 28 DF,  p-value: 0.0001909</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot x and y with regression line</span></span>
<span><span class="co"># -&gt; add annotation for R^2 value</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">mod</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">14</span>, y <span class="op">=</span> <span class="fl">30</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="va">R</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="st">" = "</span> <span class="op">*</span> <span class="fu">.</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">r.squared</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-inference_files/figure-html/unnamed-chunk-32-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-16-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-16-2-tab">
<div class="cell">
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># get anova table for model</span></span>
<span><span class="va">at</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">at</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Df   Sum Sq   Mean Sq  F value       Pr(&gt;F)
x          1 3306.803 3306.8030 18.42694 0.0001908607
Residuals 28 5024.734  179.4548       NA           NA</code></pre>
</div>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate R^2 from sums of squares from anova table</span></span>
<span><span class="co"># R^2 = SSR / SSTO = SSR / (SSR + SSE) = 1 - SSE / SSTO</span></span>
<span><span class="va">ssr</span> <span class="op">&lt;-</span> <span class="va">at</span><span class="op">[</span><span class="st">"x"</span>, <span class="st">"Sum Sq"</span><span class="op">]</span></span>
<span><span class="va">sse</span> <span class="op">&lt;-</span> <span class="va">at</span><span class="op">[</span><span class="st">"Residuals"</span>, <span class="st">"Sum Sq"</span><span class="op">]</span></span>
<span><span class="va">r_squared</span> <span class="op">&lt;-</span> <span class="va">ssr</span> <span class="op">/</span> <span class="op">(</span><span class="va">ssr</span> <span class="op">+</span> <span class="va">sse</span><span class="op">)</span></span>
<span><span class="va">r_squared</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">sse</span> <span class="op">/</span> <span class="op">(</span><span class="va">ssr</span> <span class="op">+</span> <span class="va">sse</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare results from summary(lm())</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">r.squared</span>, <span class="va">r_squared</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`summary(mod)$r.squared`
[1] 0.3969019

$r_squared
[1] 0.3969019</code></pre>
</div>
</div>
</div>
<div id="tabset-16-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-16-3-tab">
<div class="cell">
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># demo to show how more spacing of X levels increases R^2 value</span></span>
<span></span>
<span><span class="co"># initialize items</span></span>
<span><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span>; <span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">2</span>; <span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="fl">3</span>; <span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">5</span> </span>
<span></span>
<span><span class="co"># generate two datasets</span></span>
<span><span class="co"># -&gt; generate common error terms, so the only difference is the spacing of the X levels</span></span>
<span><span class="co"># -&gt; generate two X vectors, one with larger spread of X values</span></span>
<span><span class="co"># -&gt; calculate Y</span></span>
<span><span class="co"># -&gt; add indicator for spread and then combine into one dataframe</span></span>
<span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="va">data_samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">8</span>, max <span class="op">=</span> <span class="fl">12</span><span class="op">)</span>,</span>
<span>                     <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, min <span class="op">=</span> <span class="fl">2</span>, max <span class="op">=</span> <span class="fl">16</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">map</span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>,</span>
<span>                      y <span class="op">=</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">map2</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"smaller"</span>, <span class="st">"larger"</span><span class="op">)</span>, \<span class="op">(</span><span class="va">df</span>, <span class="va">spread</span><span class="op">)</span> <span class="fu">mutate</span><span class="op">(</span><span class="va">df</span>, spread <span class="op">=</span> <span class="va">spread</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">bind_rows</span></span>
<span></span>
<span><span class="co"># confirm same error terms</span></span>
<span><span class="co"># -&gt; calculate epsilon as Y - E(Y) and then add observation number column to sort by</span></span>
<span><span class="va">data_samples</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>epsilon <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="op">(</span><span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>observation <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span>, .by <span class="op">=</span> <span class="va">spread</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">observation</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">6</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">display_nice</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table data-quarto-disable-processing="true" class="table table-striped" style="width: auto !important; ">
<thead><tr>
<th style="text-align:right;"> x </th>
   <th style="text-align:right;"> y </th>
   <th style="text-align:left;"> spread </th>
   <th style="text-align:right;"> epsilon </th>
   <th style="text-align:right;"> observation </th>
  </tr></thead>
<tbody>
<tr>
<td style="text-align:right;"> 8.809 </td>
   <td style="text-align:right;"> 25.438 </td>
   <td style="text-align:left;"> smaller </td>
   <td style="text-align:right;"> -2.988 </td>
   <td style="text-align:right;"> 1 </td>
  </tr>
<tr>
<td style="text-align:right;"> 9.987 </td>
   <td style="text-align:right;"> 28.973 </td>
   <td style="text-align:left;"> larger </td>
   <td style="text-align:right;"> -2.988 </td>
   <td style="text-align:right;"> 1 </td>
  </tr>
<tr>
<td style="text-align:right;"> 10.771 </td>
   <td style="text-align:right;"> 40.676 </td>
   <td style="text-align:left;"> smaller </td>
   <td style="text-align:right;"> 6.363 </td>
   <td style="text-align:right;"> 2 </td>
  </tr>
<tr>
<td style="text-align:right;"> 5.397 </td>
   <td style="text-align:right;"> 24.555 </td>
   <td style="text-align:left;"> larger </td>
   <td style="text-align:right;"> 6.363 </td>
   <td style="text-align:right;"> 2 </td>
  </tr>
<tr>
<td style="text-align:right;"> 8.808 </td>
   <td style="text-align:right;"> 30.112 </td>
   <td style="text-align:left;"> smaller </td>
   <td style="text-align:right;"> 1.687 </td>
   <td style="text-align:right;"> 3 </td>
  </tr>
<tr>
<td style="text-align:right;"> 14.214 </td>
   <td style="text-align:right;"> 46.330 </td>
   <td style="text-align:left;"> larger </td>
   <td style="text-align:right;"> 1.687 </td>
   <td style="text-align:right;"> 3 </td>
  </tr>
</tbody>
</table>
</div>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># calculate R^2 for each spread dataset</span></span>
<span><span class="va">data_samples</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/split.html">split</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">spread</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">map_dbl</span><span class="op">(</span>\<span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, data <span class="op">=</span> <span class="va">df</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">r.squared</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> larger smaller 
  0.843   0.348 </code></pre>
</div>
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># create plot of both sets of points and regression line</span></span>
<span><span class="co"># -&gt; add reference line for Y-bar for each dataset (to show how SSTO is calculated)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>,</span>
<span>           y <span class="op">=</span> <span class="va">y</span>,</span>
<span>           color <span class="op">=</span> <span class="va">spread</span><span class="op">)</span>,</span>
<span>       data <span class="op">=</span> <span class="va">data_samples</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>              formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span>,</span>
<span>              se <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>              fullrange <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_hline</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>yintercept <span class="op">=</span> <span class="va">y_bar</span>,</span>
<span>                 color <span class="op">=</span> <span class="va">spread</span><span class="op">)</span>,</span>
<span>             data <span class="op">=</span> <span class="fu">summarize</span><span class="op">(</span><span class="va">data_samples</span>, y_bar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, .by <span class="op">=</span> <span class="va">spread</span><span class="op">)</span>,</span>
<span>             linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="notes-inference_files/figure-html/unnamed-chunk-34-1.png" class="img-fluid figure-img" data-fig-pos="hold" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section id="coefficient-of-correlation" class="level3" data-number="2.9.2"><h3 data-number="2.9.2" class="anchored" data-anchor-id="coefficient-of-correlation">
<span class="header-section-number">2.9.2</span> Coefficient of correlation</h3>
<ul>
<li>A measure of linear association between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> when both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are <em>random</em> is the coefficient of correlation. This is the signed square root of <span class="math inline">\(R^2\)</span>:</li>
</ul>
<p><span class="math display">\[
r = \pm \sqrt{R^2}
\]</span></p>
<ul>
<li><p>A plus or minus sign is attached to this measure according to whether the slope of the fitted regression line is positive or negative. Thus, <span class="math inline">\(-1 \le r \le 1\)</span>.</p></li>
<li><p>ONLY in SLR can the coefficient of determination <span class="math inline">\(R^2\)</span> be computed as the square of the correlation coefficient <span class="math inline">\(r^2\)</span>.</p></li>
</ul>
<div class="cell">
<div class="sourceCode" id="cb133"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># continuing previous example</span></span>
<span></span>
<span><span class="co"># calculate correlation</span></span>
<span><span class="va">r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compare to squared-correlation to R^2</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">$</span><span class="va">r.squared</span>, <span class="va">r</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$comparison
[1] TRUE

$`summary(mod)$r.squared`
[1] 0.3969019

$`r^2`
[1] 0.3969019</code></pre>
</div>
</div>
<ul>
<li>Note → Regression models do not contain a parameter to be estimated by <span class="math inline">\(R^2\)</span> or <span class="math inline">\(r\)</span>. These are simply <em>descriptive measures</em> of the <em>degree of linear association</em> between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> in the sample observations that <em>may, or may not, be useful</em> in any instance.</li>
</ul>
<!-- come back and add math 321 stuff about correlation? like the formula?? --></section></section><section id="considerations-in-applying-regression-analysis" class="level2" data-number="2.10"><h2 data-number="2.10" class="anchored" data-anchor-id="considerations-in-applying-regression-analysis">
<span class="header-section-number">2.10</span> Considerations in applying regression analysis</h2>
<p>Reminders when implementing regression models</p>
<ol type="1">
<li><p>Frequently, regression analysis is used to make inferences for the future (e.g.&nbsp;a school board wants to predict future enrollments by using a regression model containing several demographic variables as predictor variables). In these situations, the validity of the regression application depends on whether basic conditions in the future will be similar to those at the time the regression analysis is based on.</p></li>
<li><p>In predicting new observations on <span class="math inline">\(Y\)</span>, the predictor variable <span class="math inline">\(X\)</span> itself often has to be predicted. Therefore, predictions are dependent upon the correctness of the population projection (i.e.&nbsp;they are conditional predictions).</p></li>
<li><p>Be careful of extrapolation. We cannot be sure that the regression function that fits the past data is appropriate over a wider range of the predictor variable.</p></li>
<li><p>A statistical test that concludes <span class="math inline">\(\beta_1 \ne 0\)</span> does not establish a cause-and-effect relation between the predictor and response variables. With nonexperimental data, both the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables may be simultaneously influenced by other variables not in the regression model. On the other hand, the existence of a regression relation in controlled experiments is often good evidence of a cause-and-effect relation.</p></li>
<li><p>We frequently wish to estimate several mean responses or predict several new observations for different levels of the predictor variable; this causes some special problems to arise. The confidence coefficients for the limits for estimating a mean response and for the prediction limits for a new observation only for a <em>single level</em> of <span class="math inline">\(X\)</span> for a given sample.</p></li>
<li><p>When observations on the predictor variable <span class="math inline">\(X\)</span> are subject to measurement errors, the resulting parameter estimates are generally no longer unbiased.</p></li>
</ol>
<!-- skipping 2.1 normal correlation models, definitely want to come back to this -->

<!-- -->

</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./notes-slr.html" class="pagination-link  aria-label=" linear="" regression="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./part2-mlr.html" class="pagination-link" aria-label="Multiple linear regression">
        <span class="nav-page-text">Multiple linear regression</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb135" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Inference {#sec-inference}</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-prereqs</span></span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a><span class="co"># knitr options</span></span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-14"><a href="#cb135-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-15"><a href="#cb135-15" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define LaTeX macros (/shortcuts) --&gt;</span></span>
<span id="cb135-16"><a href="#cb135-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-17"><a href="#cb135-17" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define vector (without parentheses, so when writing out in like a definition) of the form X_1, ..., X_n, where X and n are variable. </span><span class="al">NOTE</span><span class="co">: to call use $\vecn{X}{n}$ --&gt;</span></span>
<span id="cb135-18"><a href="#cb135-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-19"><a href="#cb135-19" aria-hidden="true" tabindex="-1"></a>\newcommand{\vecn}<span class="co">[</span><span class="ot">2</span><span class="co">]</span>{#1_1, \ldots, #1_{#2}}</span>
<span id="cb135-20"><a href="#cb135-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-21"><a href="#cb135-21" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for ~ 'Named dist ' in normal font with space before parameters would go --&gt;</span></span>
<span id="cb135-22"><a href="#cb135-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-23"><a href="#cb135-23" aria-hidden="true" tabindex="-1"></a>\newcommand{\follow}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\sim \text{#1}\,}</span>
<span id="cb135-24"><a href="#cb135-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-25"><a href="#cb135-25" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % (followsp is short for 'follow special') shortcut that can be used for iid or ind ~ 'Named dist ' in normal font with space before parameters would go --&gt;</span></span>
<span id="cb135-26"><a href="#cb135-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-27"><a href="#cb135-27" aria-hidden="true" tabindex="-1"></a>\newcommand{\followsp}<span class="co">[</span><span class="ot">2</span><span class="co">]</span>{\overset{#1}\sim \text{#2}\,}</span>
<span id="cb135-28"><a href="#cb135-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-29"><a href="#cb135-29" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % define independence symbol (it basically makes two orthogonal symbols very close to each other. The number of \! controls the space between each of the orthogonal symbols) --&gt;</span></span>
<span id="cb135-30"><a href="#cb135-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-31"><a href="#cb135-31" aria-hidden="true" tabindex="-1"></a>\newcommand{\ind}{\perp <span class="sc">\!\!\!</span> \perp}</span>
<span id="cb135-32"><a href="#cb135-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-33"><a href="#cb135-33" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for Cov(X,Y) with formatting for Cov --&gt;</span></span>
<span id="cb135-34"><a href="#cb135-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-35"><a href="#cb135-35" aria-hidden="true" tabindex="-1"></a>\newcommand{\cov}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\mathrm{Cov}(#1)}</span>
<span id="cb135-36"><a href="#cb135-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-37"><a href="#cb135-37" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for Corr(X,Y) with formatting for Corr --&gt;</span></span>
<span id="cb135-38"><a href="#cb135-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-39"><a href="#cb135-39" aria-hidden="true" tabindex="-1"></a>\newcommand{\corr}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\mathrm{Corr}(#1)}</span>
<span id="cb135-40"><a href="#cb135-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-41"><a href="#cb135-41" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- % shortcut for non-italic e in math mode --&gt;</span></span>
<span id="cb135-42"><a href="#cb135-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-43"><a href="#cb135-43" aria-hidden="true" tabindex="-1"></a>\newcommand{\e}{\mathrm{e}}</span>
<span id="cb135-44"><a href="#cb135-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-45"><a href="#cb135-45" aria-hidden="true" tabindex="-1"></a>For the rest of this section, assume the normal error regression model is applicable:</span>
<span id="cb135-46"><a href="#cb135-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-47"><a href="#cb135-47" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-48"><a href="#cb135-48" aria-hidden="true" tabindex="-1"></a>Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \hspace{20pt} \text{where} \hspace{10pt} \epsilon_i \overset{iid}\sim \text{N}\,(0,\sigma^2)</span>
<span id="cb135-49"><a href="#cb135-49" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-50"><a href="#cb135-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-51"><a href="#cb135-51" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inferences concerning $\beta_1$</span></span>
<span id="cb135-52"><a href="#cb135-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-53"><a href="#cb135-53" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-54"><a href="#cb135-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-55"><a href="#cb135-55" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Test on slope $\beta_1$ and the implications</span>
<span id="cb135-56"><a href="#cb135-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-57"><a href="#cb135-57" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We often want to make inferences about $\beta_1$. A common test on $\beta_1$ has the form below.</span>
<span id="cb135-58"><a href="#cb135-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-59"><a href="#cb135-59" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If $\beta_1 = 0$ $\Longrightarrow$ Regression line in horizontal, which means there is no linear association between $Y$ and $X$, and even more no relation of any type because all probability distributions of $Y$ are identical at all levels of $X$: normal with $E(Y) = \beta_0 + (0) X = \beta_0$ and variance $\sigma^2$.</span>
<span id="cb135-60"><a href="#cb135-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-61"><a href="#cb135-61" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-62"><a href="#cb135-62" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-63"><a href="#cb135-63" aria-hidden="true" tabindex="-1"></a>  H_0 &amp;: \beta_1 = 0 <span class="sc">\\</span></span>
<span id="cb135-64"><a href="#cb135-64" aria-hidden="true" tabindex="-1"></a>  H_A &amp;: \beta_1 \ne 0</span>
<span id="cb135-65"><a href="#cb135-65" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-66"><a href="#cb135-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-67"><a href="#cb135-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-68"><a href="#cb135-68" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/zero-slope.png)</span>{width="50%"}</span>
<span id="cb135-69"><a href="#cb135-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-70"><a href="#cb135-70" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sampling distribution of $\hat{\beta}_1$</span></span>
<span id="cb135-71"><a href="#cb135-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-72"><a href="#cb135-72" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-73"><a href="#cb135-73" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb135-74"><a href="#cb135-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-75"><a href="#cb135-75" aria-hidden="true" tabindex="-1"></a>Sampling distribution of $\hat{\beta}_1$</span>
<span id="cb135-76"><a href="#cb135-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-77"><a href="#cb135-77" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Refers to distribution of $\hat{\beta}_1$ from repeated sampling when the levels of the predictor variable $X$ are held constant from sample to sample.</span>
<span id="cb135-78"><a href="#cb135-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-79"><a href="#cb135-79" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Recall $\displaystyle \hat{\beta}_1 = \frac{\sum(X_i - \bar{X})(Y_i - \bar{Y})}{\sum(X_i - \bar{X})^2}$; this is the point estimator.</span>
<span id="cb135-80"><a href="#cb135-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-81"><a href="#cb135-81" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Distribution of $\hat{\beta}_1$ is Normal with mean and variance:</span>
<span id="cb135-82"><a href="#cb135-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-83"><a href="#cb135-83" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-84"><a href="#cb135-84" aria-hidden="true" tabindex="-1"></a> \begin{align*}</span>
<span id="cb135-85"><a href="#cb135-85" aria-hidden="true" tabindex="-1"></a>   E(\hat{\beta}_1) &amp;= \beta_1 <span class="sc">\\</span></span>
<span id="cb135-86"><a href="#cb135-86" aria-hidden="true" tabindex="-1"></a>  V (\hat{\beta}_1) &amp;= \frac{\sigma^2}{\sum(X_i - \bar{X})^2}</span>
<span id="cb135-87"><a href="#cb135-87" aria-hidden="true" tabindex="-1"></a> \end{align*}</span>
<span id="cb135-88"><a href="#cb135-88" aria-hidden="true" tabindex="-1"></a> $$</span>
<span id="cb135-89"><a href="#cb135-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-90"><a href="#cb135-90" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Then we can estimate the variance by replacing the parameter $\sigma^2$ with $MSE$, the unbiased estimator of $\sigma^2$. This gives us $S^2_{\hat{\beta}_1}$, which is an unbiased estimator for the variance of the sampling distribution of $\hat{\beta}_1$. And we can take the positive square root to give us $S_{\hat{\beta}_1}$, which is the point estimator of $\sigma_{\hat{\beta}_1}$.</span>
<span id="cb135-91"><a href="#cb135-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-92"><a href="#cb135-92" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-93"><a href="#cb135-93" aria-hidden="true" tabindex="-1"></a>  S^2_{\hat{\beta}_1} = \frac{MSE}{\sum(X_i - \bar{X})^2} = \frac{MSE}{S_{XX}} \hspace{20pt} \longrightarrow \hspace{20pt} s_{\hat{\beta}_1} = \sqrt{\frac{MSE}{S_{XX}}} = \frac{S}{\sqrt{S_{XX}}}</span>
<span id="cb135-94"><a href="#cb135-94" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb135-95"><a href="#cb135-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-96"><a href="#cb135-96" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Thus, $S^2_{\hat{\beta}_1}$ is an unbiased estimator for the variance of the sampling distribution of $\hat{\beta}_1$ and</span>
<span id="cb135-97"><a href="#cb135-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-98"><a href="#cb135-98" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>This is also called the **standard error** (another way to think about it is the standard deviation of the sampling distribution) → $S_{\hat{\beta}_1} = SE(\hat{\beta}_1)$</span>
<span id="cb135-99"><a href="#cb135-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-100"><a href="#cb135-100" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb135-101"><a href="#cb135-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-102"><a href="#cb135-102" aria-hidden="true" tabindex="-1"></a>Main result for normal, mean and variance</span>
<span id="cb135-103"><a href="#cb135-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-104"><a href="#cb135-104" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\hat{\beta}_1$ can be written as a linear combination of the observations $Y_i$:</span>
<span id="cb135-105"><a href="#cb135-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-106"><a href="#cb135-106" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-107"><a href="#cb135-107" aria-hidden="true" tabindex="-1"></a>\hat{\beta_1}=\sum k_i Y_i, \hspace{20pt} \text{where} \hspace{10pt} k_i = \frac{X_i - \bar{X}}{\sum(X_i - \bar{X})^2}</span>
<span id="cb135-108"><a href="#cb135-108" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-109"><a href="#cb135-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-110"><a href="#cb135-110" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\sum \text{Normal} \sim \text{Normal}\,$, so we know $\hat{\beta}_1$ must be Normal. Then properties of the coefficients $k_i$ can be used to show the mean and variance.</span>
<span id="cb135-111"><a href="#cb135-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-112"><a href="#cb135-112" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note that $k_i$'s are fixed quantities because they are a function of only $X_i$'s (which are fixed quantities). Therefore, $\hat{\beta}_1$ is a linear combination of $Y_i$, where the coefficients are solely a function of the fixed $X_i$ (this is why $\hat{\beta}_1$ is a *linear estimator*).</span>
<span id="cb135-113"><a href="#cb135-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-114"><a href="#cb135-114" aria-hidden="true" tabindex="-1"></a>Properties of coefficients $k_i$:</span>
<span id="cb135-115"><a href="#cb135-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-116"><a href="#cb135-116" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/ki-properties.png)</span>{width="20%"}</span>
<span id="cb135-117"><a href="#cb135-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-118"><a href="#cb135-118" aria-hidden="true" tabindex="-1"></a>Proof of linear combination:</span>
<span id="cb135-119"><a href="#cb135-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-120"><a href="#cb135-120" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/proof-linear-combination.png)</span>{width="50%"}</span>
<span id="cb135-121"><a href="#cb135-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-122"><a href="#cb135-122" aria-hidden="true" tabindex="-1"></a>Proofs of properties of $k_i$:</span>
<span id="cb135-123"><a href="#cb135-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-124"><a href="#cb135-124" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/proof-ki-properties.png)</span>{width="50%"}</span>
<span id="cb135-125"><a href="#cb135-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-126"><a href="#cb135-126" aria-hidden="true" tabindex="-1"></a>Proof of mean:</span>
<span id="cb135-127"><a href="#cb135-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-128"><a href="#cb135-128" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/proof-mean.png)</span>{width="50%"}</span>
<span id="cb135-129"><a href="#cb135-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-130"><a href="#cb135-130" aria-hidden="true" tabindex="-1"></a>Proof of variance:</span>
<span id="cb135-131"><a href="#cb135-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-132"><a href="#cb135-132" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/proof-variance.png)</span>{width="50%"}</span>
<span id="cb135-133"><a href="#cb135-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-134"><a href="#cb135-134" aria-hidden="true" tabindex="-1"></a>Can also prove that $\hat{\beta}_1$ has minimum variance among all unbiased linear estimators.</span>
<span id="cb135-135"><a href="#cb135-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-136"><a href="#cb135-136" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- page 43 of textbook, not hard to follow --&gt;</span></span>
<span id="cb135-137"><a href="#cb135-137" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-138"><a href="#cb135-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-139"><a href="#cb135-139" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sampling distribution of $(\hat{\beta}_1 - \beta_1) / S_{\hat{\beta}_1}$</span></span>
<span id="cb135-140"><a href="#cb135-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-141"><a href="#cb135-141" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-142"><a href="#cb135-142" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb135-143"><a href="#cb135-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-144"><a href="#cb135-144" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-145"><a href="#cb135-145" aria-hidden="true" tabindex="-1"></a>\frac{\hat{\beta}_1 - \beta_1}{S_{\hat{\beta}_1}} = \frac{\hat{\beta}_1 - \beta_1}{\sqrt{MSE / S_{XX}}} \sim \text{t}\,_{n - 2}</span>
<span id="cb135-146"><a href="#cb135-146" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-147"><a href="#cb135-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-148"><a href="#cb135-148" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb135-149"><a href="#cb135-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-150"><a href="#cb135-150" aria-hidden="true" tabindex="-1"></a>Deriving the distribution of the standardized slope → $\displaystyle \frac{\hat{\beta}_1 - E(\hat{\beta}_1)}{SE(\hat{\beta}_1)}$</span>
<span id="cb135-151"><a href="#cb135-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-152"><a href="#cb135-152" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Technically when standardizing with an estimated standard deviation it is referred to as *studentized* statistic.</span>
<span id="cb135-153"><a href="#cb135-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-154"><a href="#cb135-154" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/placeholder.png)</span>{width="50%"}</span>
<span id="cb135-155"><a href="#cb135-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-156"><a href="#cb135-156" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Can show the coefficients ki for model with intercept as well (written out in regression notes, probably not necessary); and my proofs have a bit more steps for extra clarity --&gt;</span></span>
<span id="cb135-157"><a href="#cb135-157" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-158"><a href="#cb135-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-159"><a href="#cb135-159" aria-hidden="true" tabindex="-1"></a><span class="fu">### Confidence interval for $\beta_1$</span></span>
<span id="cb135-160"><a href="#cb135-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-161"><a href="#cb135-161" aria-hidden="true" tabindex="-1"></a>Forming interval</span>
<span id="cb135-162"><a href="#cb135-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-163"><a href="#cb135-163" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-164"><a href="#cb135-164" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-165"><a href="#cb135-165" aria-hidden="true" tabindex="-1"></a>  &amp; P(-t_{\alpha/2, n-2} \le \frac{\hat{\beta}_1 - \beta_1}{S_{\hat{\beta}_1}} \le t_{\alpha/2, n-2}) = 1 - \alpha <span class="sc">\\</span></span>
<span id="cb135-166"><a href="#cb135-166" aria-hidden="true" tabindex="-1"></a>  &amp; \Longleftrightarrow \hspace{20pt} P(\hat{\beta}_1 - t_{\alpha/2, n-2} \cdot S_{\hat{\beta}_1} \le \frac{ - \beta_1}{S_{\hat{\beta}_1}} \le \hat{\beta}_1 + t_{\alpha/2, n-2} \cdot S_{\hat{\beta}_1}) = 1 - \alpha <span class="sc">\\</span></span>
<span id="cb135-167"><a href="#cb135-167" aria-hidden="true" tabindex="-1"></a>  &amp; \Longleftrightarrow \hspace{20pt}  100(1 - \alpha)\% \text{ CI } = \hat{\beta}_1 \pm t_{\alpha/2, n-2} \cdot S_{\hat{\beta}_1} \hspace{10pt} = \hspace{10pt} \hat{\beta}_1 \pm t_{\alpha/2, n-2} \cdot \sqrt{MSE / S_{XX}}</span>
<span id="cb135-168"><a href="#cb135-168" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-169"><a href="#cb135-169" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-170"><a href="#cb135-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-171"><a href="#cb135-171" aria-hidden="true" tabindex="-1"></a>Interpretation</span>
<span id="cb135-172"><a href="#cb135-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-173"><a href="#cb135-173" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>With <span class="sc">\&lt;</span> $100(1 - \alpha)$ <span class="sc">\&gt;</span>% confidence, we estimate that the average <span class="sc">\&lt;</span> $Y$ context <span class="sc">\&gt;</span> increases by between <span class="sc">\&lt;</span> lower bound <span class="sc">\&gt;</span> and <span class="sc">\&lt;</span> upper bound <span class="sc">\&gt;</span> for each additional unit increase in <span class="sc">\&lt;</span> $X$ context <span class="sc">\&gt;</span>.</span>
<span id="cb135-174"><a href="#cb135-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-175"><a href="#cb135-175" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Remember the scope of the regression model is restricted to some range of values of the predictor variable → May not be reasonable to use these slope estimates outside this range as the regression relation may not be linear then.</span>
<span id="cb135-176"><a href="#cb135-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-177"><a href="#cb135-177" aria-hidden="true" tabindex="-1"></a>Demo:</span>
<span id="cb135-178"><a href="#cb135-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-179"><a href="#cb135-179" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-180"><a href="#cb135-180" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-181"><a href="#cb135-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-184"><a href="#cb135-184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-185"><a href="#cb135-185" aria-hidden="true" tabindex="-1"></a><span class="co">#| class.source = "fold-hide"</span></span>
<span id="cb135-186"><a href="#cb135-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-187"><a href="#cb135-187" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate sample dataset for normal error regression model</span></span>
<span id="cb135-188"><a href="#cb135-188" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; E ~ Normal(0, sigma^2)</span></span>
<span id="cb135-189"><a href="#cb135-189" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y = B0 + B1*X + E</span></span>
<span id="cb135-190"><a href="#cb135-190" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y | X ~ Normal(B0 + B1*X, sigma^2)</span></span>
<span id="cb135-191"><a href="#cb135-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-192"><a href="#cb135-192" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items</span></span>
<span id="cb135-193"><a href="#cb135-193" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span id="cb135-194"><a href="#cb135-194" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb135-195"><a href="#cb135-195" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb135-196"><a href="#cb135-196" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb135-197"><a href="#cb135-197" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb135-198"><a href="#cb135-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-199"><a href="#cb135-199" aria-hidden="true" tabindex="-1"></a><span class="co"># generate X values</span></span>
<span id="cb135-200"><a href="#cb135-200" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">10</span>)</span>
<span id="cb135-201"><a href="#cb135-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-202"><a href="#cb135-202" aria-hidden="true" tabindex="-1"></a><span class="co"># generate error terms</span></span>
<span id="cb135-203"><a href="#cb135-203" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">sqrt</span>(sigma2))</span>
<span id="cb135-204"><a href="#cb135-204" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb135-205"><a href="#cb135-205" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate observations Y | X ~ Normal(B0 + B1*X, sigma^2)</span></span>
<span id="cb135-206"><a href="#cb135-206" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x <span class="sc">+</span> epsilon</span>
<span id="cb135-207"><a href="#cb135-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-208"><a href="#cb135-208" aria-hidden="true" tabindex="-1"></a><span class="co"># plot sample data with regression line</span></span>
<span id="cb135-209"><a href="#cb135-209" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb135-210"><a href="#cb135-210" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(<span class="at">formula =</span> y <span class="sc">~</span> x ), <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb135-211"><a href="#cb135-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-212"><a href="#cb135-212" aria-hidden="true" tabindex="-1"></a><span class="co"># display error terms</span></span>
<span id="cb135-213"><a href="#cb135-213" aria-hidden="true" tabindex="-1"></a>x_plot <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">3</span> <span class="sc">*</span> <span class="fu">sqrt</span>(sigma2), <span class="at">to =</span> <span class="dv">3</span> <span class="sc">*</span> <span class="fu">sqrt</span>(sigma2), <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb135-214"><a href="#cb135-214" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(epsilon, <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="at">xlab =</span> <span class="fu">bquote</span>(epsilon <span class="sc">*</span> <span class="st">"~ Normal ("</span> <span class="sc">*</span> mu <span class="sc">*</span> <span class="st">","</span> <span class="sc">*</span> sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="st">")"</span>), <span class="at">main =</span> <span class="st">""</span>)</span>
<span id="cb135-215"><a href="#cb135-215" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> x_plot,</span>
<span id="cb135-216"><a href="#cb135-216" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> <span class="fu">dnorm</span>(<span class="at">x =</span> x_plot, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">sqrt</span>(sigma2)))</span>
<span id="cb135-217"><a href="#cb135-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-218"><a href="#cb135-218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-219"><a href="#cb135-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-222"><a href="#cb135-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-223"><a href="#cb135-223" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb135-224"><a href="#cb135-224" aria-hidden="true" tabindex="-1"></a>mod_normal <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb135-225"><a href="#cb135-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-226"><a href="#cb135-226" aria-hidden="true" tabindex="-1"></a><span class="co"># display only coefficient summaries of slope</span></span>
<span id="cb135-227"><a href="#cb135-227" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_normal)<span class="sc">$</span>coefficients[<span class="dv">2</span>,] <span class="co"># Estimate is the middle of the interval</span></span>
<span id="cb135-228"><a href="#cb135-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-229"><a href="#cb135-229" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate confidence interval for slope</span></span>
<span id="cb135-230"><a href="#cb135-230" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb135-231"><a href="#cb135-231" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod_normal, <span class="at">parm =</span> <span class="st">"x"</span>, <span class="at">level =</span> <span class="dv">1</span> <span class="sc">-</span> alpha)</span>
<span id="cb135-232"><a href="#cb135-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-233"><a href="#cb135-233" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-234"><a href="#cb135-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-235"><a href="#cb135-235" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-236"><a href="#cb135-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-239"><a href="#cb135-239" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-240"><a href="#cb135-240" aria-hidden="true" tabindex="-1"></a><span class="co"># using R functions to get the needed values (can reference how to calculate these manually above)</span></span>
<span id="cb135-241"><a href="#cb135-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-242"><a href="#cb135-242" aria-hidden="true" tabindex="-1"></a><span class="co"># extract / calculate needed items</span></span>
<span id="cb135-243"><a href="#cb135-243" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; point estimate = beta1-hat</span></span>
<span id="cb135-244"><a href="#cb135-244" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; critical value = t_alpha/2, n-2</span></span>
<span id="cb135-245"><a href="#cb135-245" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; SE(beta1-hat) = MSE / S_XX = S / sqrt(S_XX)</span></span>
<span id="cb135-246"><a href="#cb135-246" aria-hidden="true" tabindex="-1"></a>pe <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_normal)[<span class="st">"x"</span>]) <span class="co"># SIDENOTE -&gt; as.numeric() just to remove the named number data type</span></span>
<span id="cb135-247"><a href="#cb135-247" aria-hidden="true" tabindex="-1"></a>t_crit <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">qt</span>(<span class="at">p =</span> alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> mod_normal<span class="sc">$</span>df.residual))</span>
<span id="cb135-248"><a href="#cb135-248" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">summary</span>(mod_normal)<span class="sc">$</span>sigma</span>
<span id="cb135-249"><a href="#cb135-249" aria-hidden="true" tabindex="-1"></a>s_xx <span class="ot">&lt;-</span> <span class="fu">sum</span>((x <span class="sc">-</span> <span class="fu">mean</span>(x))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-250"><a href="#cb135-250" aria-hidden="true" tabindex="-1"></a>se_beta1_hat <span class="ot">&lt;-</span> s <span class="sc">/</span> <span class="fu">sqrt</span>(s_xx)</span>
<span id="cb135-251"><a href="#cb135-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-252"><a href="#cb135-252" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to Std. Error from summary of model coefficients</span></span>
<span id="cb135-253"><a href="#cb135-253" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">summary</span>(mod_normal)<span class="sc">$</span>coefficients[<span class="st">"x"</span>,<span class="st">"Std. Error"</span>], se_beta1_hat)</span>
<span id="cb135-254"><a href="#cb135-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-255"><a href="#cb135-255" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate confidence interval for beta1</span></span>
<span id="cb135-256"><a href="#cb135-256" aria-hidden="true" tabindex="-1"></a>ci_limits <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">lower =</span> pe <span class="sc">-</span> t_crit <span class="sc">*</span> se_beta1_hat, <span class="at">upper =</span> pe <span class="sc">+</span> t_crit <span class="sc">*</span> se_beta1_hat)</span>
<span id="cb135-257"><a href="#cb135-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-258"><a href="#cb135-258" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to results from confint(lm())</span></span>
<span id="cb135-259"><a href="#cb135-259" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">confint</span>(mod_normal, <span class="at">parm =</span> <span class="st">"x"</span>, <span class="at">level =</span> <span class="dv">1</span> <span class="sc">-</span> alpha), ci_limits)</span>
<span id="cb135-260"><a href="#cb135-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-261"><a href="#cb135-261" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-262"><a href="#cb135-262" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-263"><a href="#cb135-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-264"><a href="#cb135-264" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tests concerning $\beta_1$</span></span>
<span id="cb135-265"><a href="#cb135-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-266"><a href="#cb135-266" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-267"><a href="#cb135-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-268"><a href="#cb135-268" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The test shown below is called a test of utility of the model.</span>
<span id="cb135-269"><a href="#cb135-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-270"><a href="#cb135-270" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If reject → We conclude that $X$ does contribute information for the prediction of $Y$ when using the straight-line model.</span>
<span id="cb135-271"><a href="#cb135-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-272"><a href="#cb135-272" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If fail to reject → Then we conclude there is no linear relationship between $Y$ and $X$ (horizontal model). But keep in mind:</span>
<span id="cb135-273"><a href="#cb135-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-274"><a href="#cb135-274" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Additional data might indicate that $\beta_1$ differs from zero.</span>
<span id="cb135-275"><a href="#cb135-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-276"><a href="#cb135-276" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>A more complex relationship between $Y$ and $X$ may exist, which would require fitting a model other than the straight-line model.</span>
<span id="cb135-277"><a href="#cb135-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-278"><a href="#cb135-278" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>All assumptions about the error terms ($\epsilon_i \overset{iid}\sim \text{Normal}\,(0,\sigma^2)$) should be satisfied.</span>
<span id="cb135-279"><a href="#cb135-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-280"><a href="#cb135-280" aria-hidden="true" tabindex="-1"></a>Two-tailed test (most common)</span>
<span id="cb135-281"><a href="#cb135-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-282"><a href="#cb135-282" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Hypotheses</span>
<span id="cb135-283"><a href="#cb135-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-284"><a href="#cb135-284" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-285"><a href="#cb135-285" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-286"><a href="#cb135-286" aria-hidden="true" tabindex="-1"></a>  H_0 &amp;: \beta_1 = 0 <span class="sc">\\</span></span>
<span id="cb135-287"><a href="#cb135-287" aria-hidden="true" tabindex="-1"></a>  H_A &amp;: \beta_1 \ne 0</span>
<span id="cb135-288"><a href="#cb135-288" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-289"><a href="#cb135-289" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-290"><a href="#cb135-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-291"><a href="#cb135-291" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Test statistic</span>
<span id="cb135-292"><a href="#cb135-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-293"><a href="#cb135-293" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-294"><a href="#cb135-294" aria-hidden="true" tabindex="-1"></a>TS = t^* = \frac{\hat{\beta}_1 - 0}{S_{\hat{\beta}_1}} = \frac{\hat{\beta}_1}{\sqrt{MSE / S_{XX}}}</span>
<span id="cb135-295"><a href="#cb135-295" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-296"><a href="#cb135-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-297"><a href="#cb135-297" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Rejection region and p-value</span>
<span id="cb135-298"><a href="#cb135-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-299"><a href="#cb135-299" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-300"><a href="#cb135-300" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-301"><a href="#cb135-301" aria-hidden="true" tabindex="-1"></a>  RR &amp;= <span class="sc">\{</span>\lvert t^* \rvert &gt; t_{\alpha/2, n - 2}<span class="sc">\}</span> <span class="sc">\\</span></span>
<span id="cb135-302"><a href="#cb135-302" aria-hidden="true" tabindex="-1"></a>  p\text{-value} &amp;= 2 \cdot P(t_{n-2} \ge \lvert t^* \rvert)</span>
<span id="cb135-303"><a href="#cb135-303" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-304"><a href="#cb135-304" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-305"><a href="#cb135-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-306"><a href="#cb135-306" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Decision</span>
<span id="cb135-307"><a href="#cb135-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-308"><a href="#cb135-308" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Reject $H_0$ and conclude $H_A$ if $\hspace{10pt}$ $TS \in RR \hspace{10pt} \Longleftrightarrow \hspace{10pt} p\text{-value} \le \alpha$</span>
<span id="cb135-309"><a href="#cb135-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-310"><a href="#cb135-310" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Fail to reject $H_0$ if $\hspace{10pt}$ $TS \notin RR \hspace{10pt} \Longleftrightarrow \hspace{10pt} p\text{-value} &gt; \alpha$</span>
<span id="cb135-311"><a href="#cb135-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-312"><a href="#cb135-312" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Can also look at the $100(1 - \alpha)\%$ CI for $\beta_1$ to see if contains 0.</span>
<span id="cb135-313"><a href="#cb135-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-314"><a href="#cb135-314" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Conclusion / Interpretation</span>
<span id="cb135-315"><a href="#cb135-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-316"><a href="#cb135-316" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>At the $\alpha$ significance level, we <span class="sc">\&lt;</span> have / do not have <span class="sc">\&gt;</span> sufficient evidence of a significant linear relationship between <span class="sc">\&lt;</span> $Y$ context <span class="sc">\&gt;</span> and <span class="sc">\&lt;</span> $X$ context <span class="sc">\&gt;</span>. <span class="sc">\&lt;</span> if yes... <span class="sc">\&gt;</span> This is a <span class="sc">\&lt;</span> positive / negative <span class="sc">\&gt;</span> linear relationship, indicating that as <span class="sc">\&lt;</span> $X$ context <span class="sc">\&gt;</span> increases, <span class="sc">\&lt;</span> $Y$ context <span class="sc">\&gt;</span> <span class="sc">\&lt;</span> increases / decreases <span class="sc">\&gt;</span>, on average.</span>
<span id="cb135-317"><a href="#cb135-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-318"><a href="#cb135-318" aria-hidden="true" tabindex="-1"></a>Other tests</span>
<span id="cb135-319"><a href="#cb135-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-320"><a href="#cb135-320" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>One-tailed tests</span>
<span id="cb135-321"><a href="#cb135-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-322"><a href="#cb135-322" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$H_A: \beta_1 &lt; 0 \hspace{10pt} \Longrightarrow \hspace{10pt} RR = \{t^*&lt; t_{\alpha, n - 2}\} \hspace{10pt} \text{and} \hspace{10pt} p\text{-value} = P(t_{n-2} \le t^*)$</span>
<span id="cb135-323"><a href="#cb135-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-324"><a href="#cb135-324" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$H_A: \beta_1 &gt; 0 \hspace{10pt} \Longrightarrow \hspace{10pt} RR = \{t^* &gt; t_{\alpha, n - 2}\} \hspace{10pt} \text{and} \hspace{10pt} p\text{-value} = P(t_{n-2} \ge t^*)$</span>
<span id="cb135-325"><a href="#cb135-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-326"><a href="#cb135-326" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Tests against specified nonzero value of $\beta_{1,0}$</span>
<span id="cb135-327"><a href="#cb135-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-328"><a href="#cb135-328" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$TS = t^* = \frac{\hat{\beta}_1 - \beta_{1,0}}{S_{\hat{\beta}_1}}$</span>
<span id="cb135-329"><a href="#cb135-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-330"><a href="#cb135-330" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>RR, $p$-value and decisions are the same, just based on new $t^*$.</span>
<span id="cb135-331"><a href="#cb135-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-332"><a href="#cb135-332" aria-hidden="true" tabindex="-1"></a>Demo:</span>
<span id="cb135-333"><a href="#cb135-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-334"><a href="#cb135-334" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-335"><a href="#cb135-335" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-336"><a href="#cb135-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-339"><a href="#cb135-339" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-340"><a href="#cb135-340" aria-hidden="true" tabindex="-1"></a><span class="co"># using same model from the confidence interval for beta1 demo</span></span>
<span id="cb135-341"><a href="#cb135-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-342"><a href="#cb135-342" aria-hidden="true" tabindex="-1"></a><span class="co"># display model summary, focusing on coefficient summaries for slope</span></span>
<span id="cb135-343"><a href="#cb135-343" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; looking for t value (if doing traditional method test with RR) and Pr(&gt;|t|) = p-value</span></span>
<span id="cb135-344"><a href="#cb135-344" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_normal) <span class="co"># compare p-value to alpha</span></span>
<span id="cb135-345"><a href="#cb135-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-346"><a href="#cb135-346" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-347"><a href="#cb135-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-348"><a href="#cb135-348" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-349"><a href="#cb135-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-352"><a href="#cb135-352" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-353"><a href="#cb135-353" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate test statistic t* = beta1-hat / SE(beta1-hat)</span></span>
<span id="cb135-354"><a href="#cb135-354" aria-hidden="true" tabindex="-1"></a>beta1_hat <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_normal)[<span class="dv">2</span>])</span>
<span id="cb135-355"><a href="#cb135-355" aria-hidden="true" tabindex="-1"></a>se_beta1_hat <span class="ot">&lt;-</span> <span class="fu">summary</span>(mod_normal)<span class="sc">$</span>coefficients[<span class="st">"x"</span>,<span class="st">"Std. Error"</span>]</span>
<span id="cb135-356"><a href="#cb135-356" aria-hidden="true" tabindex="-1"></a>t_star <span class="ot">&lt;-</span> beta1_hat <span class="sc">/</span> se_beta1_hat</span>
<span id="cb135-357"><a href="#cb135-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-358"><a href="#cb135-358" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to result from summary(lm())</span></span>
<span id="cb135-359"><a href="#cb135-359" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">summary</span>(mod_normal)<span class="sc">$</span>coefficients[<span class="st">"x"</span>,<span class="st">"t value"</span>], t_star)</span>
<span id="cb135-360"><a href="#cb135-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-361"><a href="#cb135-361" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate p-value = 2 * P(t_(n-2) &gt;= |t*|)</span></span>
<span id="cb135-362"><a href="#cb135-362" aria-hidden="true" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">pt</span>(<span class="at">q =</span> t_star, <span class="at">df =</span> <span class="fu">df.residual</span>(mod_normal), <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb135-363"><a href="#cb135-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-364"><a href="#cb135-364" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to results from summary(lm())</span></span>
<span id="cb135-365"><a href="#cb135-365" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">summary</span>(mod_normal)<span class="sc">$</span>coefficients[<span class="st">"x"</span>,<span class="st">"Pr(&gt;|t|)"</span>], p_value)</span>
<span id="cb135-366"><a href="#cb135-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-367"><a href="#cb135-367" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-368"><a href="#cb135-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-369"><a href="#cb135-369" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Simulation</span></span>
<span id="cb135-370"><a href="#cb135-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-371"><a href="#cb135-371" aria-hidden="true" tabindex="-1"></a>Simulation to determine how the magnitude of $\beta_1$ and $\sigma$ affect the resulting significance of the $X$ variable in SLR when simulating data. For example, suppose $\beta_1 = 1a$ and $\sigma = 3a$, where $a = 1, 2, 3$. Is there the same resulting significance for all values of $a$?  </span>
<span id="cb135-372"><a href="#cb135-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-375"><a href="#cb135-375" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-376"><a href="#cb135-376" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize simulation settings</span></span>
<span id="cb135-377"><a href="#cb135-377" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; first the parameters of interest (that are variable)</span></span>
<span id="cb135-378"><a href="#cb135-378" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; create all combos</span></span>
<span id="cb135-379"><a href="#cb135-379" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; add in the constant settings</span></span>
<span id="cb135-380"><a href="#cb135-380" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; arrange in a good order</span></span>
<span id="cb135-381"><a href="#cb135-381" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; add simulation id column</span></span>
<span id="cb135-382"><a href="#cb135-382" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; set row names equal to id (helps keep track of results later)</span></span>
<span id="cb135-383"><a href="#cb135-383" aria-hidden="true" tabindex="-1"></a>params <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">beta_1 =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">10</span>),</span>
<span id="cb135-384"><a href="#cb135-384" aria-hidden="true" tabindex="-1"></a>                      <span class="at">ratio =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,<span class="dv">5</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-385"><a href="#cb135-385" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sigma =</span> beta_1 <span class="sc">*</span> ratio) <span class="sc">%&gt;%</span> </span>
<span id="cb135-386"><a href="#cb135-386" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n =</span> <span class="dv">30</span>,</span>
<span id="cb135-387"><a href="#cb135-387" aria-hidden="true" tabindex="-1"></a>         <span class="at">beta_0 =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb135-388"><a href="#cb135-388" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(beta_1, ratio) <span class="sc">%&gt;%</span> </span>
<span id="cb135-389"><a href="#cb135-389" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">data.frame</span>(<span class="at">sim_id =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(.)))</span>
<span id="cb135-390"><a href="#cb135-390" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(params) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"sim"</span>, params<span class="sc">$</span>sim_id)</span>
<span id="cb135-391"><a href="#cb135-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-392"><a href="#cb135-392" aria-hidden="true" tabindex="-1"></a><span class="co"># define function to run on each unique simulation setting</span></span>
<span id="cb135-393"><a href="#cb135-393" aria-hidden="true" tabindex="-1"></a>simulation <span class="ot">&lt;-</span> <span class="cf">function</span>(vec, vec_names, <span class="at">m =</span> <span class="dv">1000</span>) {</span>
<span id="cb135-394"><a href="#cb135-394" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb135-395"><a href="#cb135-395" aria-hidden="true" tabindex="-1"></a>  <span class="co"># set names of parameter vector for clearer reference</span></span>
<span id="cb135-396"><a href="#cb135-396" aria-hidden="true" tabindex="-1"></a>  <span class="fu">names</span>(vec) <span class="ot">=</span> vec_names</span>
<span id="cb135-397"><a href="#cb135-397" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb135-398"><a href="#cb135-398" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initialize results vector</span></span>
<span id="cb135-399"><a href="#cb135-399" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">=</span> <span class="fu">rep</span>(<span class="cn">NA</span>, m)</span>
<span id="cb135-400"><a href="#cb135-400" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb135-401"><a href="#cb135-401" aria-hidden="true" tabindex="-1"></a>  <span class="co"># loop to simulate m models and extract summaries</span></span>
<span id="cb135-402"><a href="#cb135-402" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>m) {</span>
<span id="cb135-403"><a href="#cb135-403" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-404"><a href="#cb135-404" aria-hidden="true" tabindex="-1"></a>    <span class="co"># generate data</span></span>
<span id="cb135-405"><a href="#cb135-405" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">=</span> <span class="fu">runif</span>(<span class="at">n =</span> vec[<span class="st">"n"</span>], <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">10</span>)</span>
<span id="cb135-406"><a href="#cb135-406" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="at">n =</span> vec[<span class="st">"n"</span>], <span class="at">mean =</span> vec[<span class="st">"beta_0"</span>] <span class="sc">+</span> vec[<span class="st">"beta_1"</span>] <span class="sc">*</span> x, <span class="at">sd =</span> vec[<span class="st">"sigma"</span>])</span>
<span id="cb135-407"><a href="#cb135-407" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-408"><a href="#cb135-408" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fit model</span></span>
<span id="cb135-409"><a href="#cb135-409" aria-hidden="true" tabindex="-1"></a>    mod <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb135-410"><a href="#cb135-410" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-411"><a href="#cb135-411" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get summaries</span></span>
<span id="cb135-412"><a href="#cb135-412" aria-hidden="true" tabindex="-1"></a>    <span class="co"># -&gt; just want t-stat</span></span>
<span id="cb135-413"><a href="#cb135-413" aria-hidden="true" tabindex="-1"></a>    results[i] <span class="ot">=</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>coefficients[<span class="st">"x"</span>, <span class="st">"t value"</span>]</span>
<span id="cb135-414"><a href="#cb135-414" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-415"><a href="#cb135-415" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb135-416"><a href="#cb135-416" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb135-417"><a href="#cb135-417" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(results)</span>
<span id="cb135-418"><a href="#cb135-418" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb135-419"><a href="#cb135-419" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb135-420"><a href="#cb135-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-421"><a href="#cb135-421" aria-hidden="true" tabindex="-1"></a><span class="co"># run simulation for each parameter settings</span></span>
<span id="cb135-422"><a href="#cb135-422" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; have to transpose so that now each column is a parameter settings and convert to dataframe so can pass to map(), which needs a list</span></span>
<span id="cb135-423"><a href="#cb135-423" aria-hidden="true" tabindex="-1"></a>results_raw <span class="ot">&lt;-</span> params <span class="sc">%&gt;%</span> </span>
<span id="cb135-424"><a href="#cb135-424" aria-hidden="true" tabindex="-1"></a>  t <span class="sc">%&gt;%</span> </span>
<span id="cb135-425"><a href="#cb135-425" aria-hidden="true" tabindex="-1"></a>  data.frame <span class="sc">%&gt;%</span> </span>
<span id="cb135-426"><a href="#cb135-426" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(\(vec) <span class="fu">simulation</span>(vec, <span class="at">vec_names =</span> <span class="fu">names</span>(params), <span class="at">m =</span> <span class="dv">1000</span>), <span class="at">.progress =</span> T)</span>
<span id="cb135-427"><a href="#cb135-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-428"><a href="#cb135-428" aria-hidden="true" tabindex="-1"></a><span class="co"># reformat results</span></span>
<span id="cb135-429"><a href="#cb135-429" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; combine results into a dataframe</span></span>
<span id="cb135-430"><a href="#cb135-430" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; convert to long so have one column for which simulation settings and one for the results</span></span>
<span id="cb135-431"><a href="#cb135-431" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; attach the simulation settings to the results</span></span>
<span id="cb135-432"><a href="#cb135-432" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; for the plot, want all parameters as factors -&gt; so before joining convert all</span></span>
<span id="cb135-433"><a href="#cb135-433" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> results_raw <span class="sc">%&gt;%</span> </span>
<span id="cb135-434"><a href="#cb135-434" aria-hidden="true" tabindex="-1"></a>  bind_rows <span class="sc">%&gt;%</span> </span>
<span id="cb135-435"><a href="#cb135-435" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(params),</span>
<span id="cb135-436"><a href="#cb135-436" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"sim_id"</span>,</span>
<span id="cb135-437"><a href="#cb135-437" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"t"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb135-438"><a href="#cb135-438" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sim_id =</span> <span class="fu">as.factor</span>(<span class="fu">str_sub</span>(sim_id, <span class="at">start =</span> <span class="dv">4</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb135-439"><a href="#cb135-439" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(<span class="fu">mutate</span>(params, <span class="fu">across</span>(<span class="fu">everything</span>(), as_factor)), <span class="at">by =</span> <span class="st">"sim_id"</span>) <span class="co"># levels are slightly out of order....</span></span>
<span id="cb135-440"><a href="#cb135-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-441"><a href="#cb135-441" aria-hidden="true" tabindex="-1"></a><span class="co"># create a plot facetted by beta value, with density curves for the sampling distributions of the t-stats for each value of the sigma / beta1 ratio</span></span>
<span id="cb135-442"><a href="#cb135-442" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; add reference line for significance cutoff</span></span>
<span id="cb135-443"><a href="#cb135-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-444"><a href="#cb135-444" aria-hidden="true" tabindex="-1"></a><span class="co"># set more informative labels for the facets</span></span>
<span id="cb135-445"><a href="#cb135-445" aria-hidden="true" tabindex="-1"></a>labels_beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"1"</span> <span class="ot">=</span> <span class="st">"beta1 = 1"</span>,</span>
<span id="cb135-446"><a href="#cb135-446" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"5"</span> <span class="ot">=</span> <span class="st">"beta1 = 5"</span>,</span>
<span id="cb135-447"><a href="#cb135-447" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"10"</span> <span class="ot">=</span> <span class="st">"beta1 = 10"</span>)</span>
<span id="cb135-448"><a href="#cb135-448" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb135-449"><a href="#cb135-449" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> t,</span>
<span id="cb135-450"><a href="#cb135-450" aria-hidden="true" tabindex="-1"></a>                   <span class="at">group =</span> ratio,</span>
<span id="cb135-451"><a href="#cb135-451" aria-hidden="true" tabindex="-1"></a>                   <span class="at">color =</span> ratio,</span>
<span id="cb135-452"><a href="#cb135-452" aria-hidden="true" tabindex="-1"></a>                   <span class="at">fill =</span> ratio),</span>
<span id="cb135-453"><a href="#cb135-453" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> results,</span>
<span id="cb135-454"><a href="#cb135-454" aria-hidden="true" tabindex="-1"></a>               <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span> </span>
<span id="cb135-455"><a href="#cb135-455" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> t),</span>
<span id="cb135-456"><a href="#cb135-456" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">t =</span> <span class="fu">abs</span>(<span class="fu">qt</span>(<span class="fl">0.025</span>, <span class="at">df =</span> params[<span class="dv">1</span>,<span class="st">"n"</span>]<span class="sc">-</span><span class="dv">1</span>))),</span>
<span id="cb135-457"><a href="#cb135-457" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"darkgrey"</span>) <span class="sc">+</span> </span>
<span id="cb135-458"><a href="#cb135-458" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(beta_1 <span class="sc">~</span> .,</span>
<span id="cb135-459"><a href="#cb135-459" aria-hidden="true" tabindex="-1"></a>             <span class="at">labeller =</span> <span class="fu">as_labeller</span>(labels_beta)) <span class="sc">+</span> </span>
<span id="cb135-460"><a href="#cb135-460" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(</span>
<span id="cb135-461"><a href="#cb135-461" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="fu">guide_legend</span>(<span class="fu">bquote</span>(sigma <span class="sc">*</span>  <span class="st">"/"</span> <span class="sc">*</span> beta[<span class="dv">1</span>] <span class="sc">*</span> <span class="st">" ratio"</span>)),</span>
<span id="cb135-462"><a href="#cb135-462" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"none"</span>)</span>
<span id="cb135-463"><a href="#cb135-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-464"><a href="#cb135-464" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-465"><a href="#cb135-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-466"><a href="#cb135-466" aria-hidden="true" tabindex="-1"></a>Based on the sampling distributions, it appears that the relative magnitude is what is important. And if it is the same even for different values, then will get similar results.</span>
<span id="cb135-467"><a href="#cb135-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-468"><a href="#cb135-468" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-469"><a href="#cb135-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-470"><a href="#cb135-470" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> Inferences concerning $\beta_0$ --- infrequent that this is ever done, so skipping --&gt;</span></span>
<span id="cb135-471"><a href="#cb135-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-472"><a href="#cb135-472" aria-hidden="true" tabindex="-1"></a><span class="fu">## Some considerations when making inferences</span></span>
<span id="cb135-473"><a href="#cb135-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-474"><a href="#cb135-474" aria-hidden="true" tabindex="-1"></a>Effects of departures from normality:</span>
<span id="cb135-475"><a href="#cb135-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-476"><a href="#cb135-476" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If the probability distributions of $Y$ are not exactly normal but do not depart seriously $\Longrightarrow$ Sampling distribution of $\hat{\beta_1}$ $\approx$ normal $\Longrightarrow$ Using the $t$ distribution will provide $\approx$ $(100 - \alpha)\%$ CIs and $\alpha$-level tests.</span>
<span id="cb135-477"><a href="#cb135-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-478"><a href="#cb135-478" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The estimator $\hat{\beta_1}$ generally has the property of **asymptotic normality** (i.e. it's distribution approaches normality under very general conditions as the sample size increases). So with a sufficiently large sample size, inference procedures are still valid even if distributions of $Y$ have large departures from normality. Can switch from $t$-based procedures to $Z$-based with large $n$.</span>
<span id="cb135-479"><a href="#cb135-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-482"><a href="#cb135-482" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-483"><a href="#cb135-483" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval = FALSE,</span></span>
<span id="cb135-484"><a href="#cb135-484" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo = FALSE</span></span>
<span id="cb135-485"><a href="#cb135-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-486"><a href="#cb135-486" aria-hidden="true" tabindex="-1"></a><span class="co"># create plot of t vs z critical values</span></span>
<span id="cb135-487"><a href="#cb135-487" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="dv">5</span><span class="sc">:</span><span class="dv">500</span></span>
<span id="cb135-488"><a href="#cb135-488" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.025</span></span>
<span id="cb135-489"><a href="#cb135-489" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> df, <span class="fu">qt</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, <span class="at">df =</span> df), <span class="at">type  =</span><span class="st">"l"</span>, <span class="at">xlab =</span> <span class="st">"df"</span>, <span class="at">ylab =</span> <span class="st">"Critical values"</span>)</span>
<span id="cb135-490"><a href="#cb135-490" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> df, <span class="at">y =</span> <span class="fu">rep</span>(<span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha), <span class="fu">length</span>(df)), <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb135-491"><a href="#cb135-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-492"><a href="#cb135-492" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-493"><a href="#cb135-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-494"><a href="#cb135-494" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- does R do this implicitly?? ; doubt it, but difference in marginal--&gt;</span></span>
<span id="cb135-495"><a href="#cb135-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-496"><a href="#cb135-496" aria-hidden="true" tabindex="-1"></a>Interpretation of confidence coefficient and risks of errors</span>
<span id="cb135-497"><a href="#cb135-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-498"><a href="#cb135-498" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Our regression model assumes that the $X_i$ are known constants. So the confidence coefficient and risks of errors are interpreted with respect to taking repeated samples where the $X$ observations are kept at the same levels as in the observed sample.</span>
<span id="cb135-499"><a href="#cb135-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-500"><a href="#cb135-500" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For example, confidence interval for $\beta_1$ with confidence coefficient 95% → If many independent samples are taken *where the levels of* $X$ are the same as in the dataset, approximately 95% of the constructed confidence intervals would capture the true value of $\beta_1$.</span>
<span id="cb135-501"><a href="#cb135-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-502"><a href="#cb135-502" aria-hidden="true" tabindex="-1"></a>Spacing of the $X$ levels</span>
<span id="cb135-503"><a href="#cb135-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-504"><a href="#cb135-504" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For a given $n$ and $\sigma^2$, the variance of $\hat{\beta_1}$ is affected by the spacing of the $X$ levels in the observed data. As the spread in the $X$ levels increases, $S_{xx}$ increases and therefore $V(\hat{\beta_1})$ decreases.</span>
<span id="cb135-505"><a href="#cb135-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-506"><a href="#cb135-506" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Power of tests; skipping--&gt;</span></span>
<span id="cb135-507"><a href="#cb135-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-508"><a href="#cb135-508" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interval estimation of $E(Y_h)$</span></span>
<span id="cb135-509"><a href="#cb135-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-510"><a href="#cb135-510" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-511"><a href="#cb135-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-512"><a href="#cb135-512" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A common objective is to estimate the mean of one or more probability distributions of $Y$.</span>
<span id="cb135-513"><a href="#cb135-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-514"><a href="#cb135-514" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Setup</span>
<span id="cb135-515"><a href="#cb135-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-516"><a href="#cb135-516" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Let $X_h$ = level of $X$ that we wish to estimate the mean response for (may be a value which occurred in the sample, or some other value within the scope of the model).</span>
<span id="cb135-517"><a href="#cb135-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-518"><a href="#cb135-518" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Mean response when $X = X_h$ is $E(Y_h)$; this is what we are estimating.</span>
<span id="cb135-519"><a href="#cb135-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-520"><a href="#cb135-520" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sampling distribution of $\hat{Y_h}$</span></span>
<span id="cb135-521"><a href="#cb135-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-522"><a href="#cb135-522" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-523"><a href="#cb135-523" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb135-524"><a href="#cb135-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-525"><a href="#cb135-525" aria-hidden="true" tabindex="-1"></a>Sampling distribution of $\hat{Y_h}$</span>
<span id="cb135-526"><a href="#cb135-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-527"><a href="#cb135-527" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Again, this refers to the different of $\hat{Y_h}$ from repeated sampling when the levels of the predictor variable $X$ are held constant from sample to sample.</span>
<span id="cb135-528"><a href="#cb135-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-529"><a href="#cb135-529" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Point estimator for $E(Y_h)$ → $\hat{Y_h} = \hat{\beta}_0 + \hat{\beta}_1 X_h$</span>
<span id="cb135-530"><a href="#cb135-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-531"><a href="#cb135-531" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Distribution of $\hat{Y_h}$ is Normal with mean and variance:</span>
<span id="cb135-532"><a href="#cb135-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-533"><a href="#cb135-533" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-534"><a href="#cb135-534" aria-hidden="true" tabindex="-1"></a>  \begin{align*}</span>
<span id="cb135-535"><a href="#cb135-535" aria-hidden="true" tabindex="-1"></a>    E(\hat{Y_h}) &amp;= E(Y_h) <span class="sc">\\</span></span>
<span id="cb135-536"><a href="#cb135-536" aria-hidden="true" tabindex="-1"></a>    V(\hat{Y_h}) &amp;= \sigma^2 \bigg<span class="co">[</span><span class="ot">\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg</span><span class="co">]</span></span>
<span id="cb135-537"><a href="#cb135-537" aria-hidden="true" tabindex="-1"></a>  \end{align*}</span>
<span id="cb135-538"><a href="#cb135-538" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb135-539"><a href="#cb135-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-540"><a href="#cb135-540" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Estimate variance (and standard deviation) by substituting $MSE$. This gives us:</span>
<span id="cb135-541"><a href="#cb135-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-542"><a href="#cb135-542" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-543"><a href="#cb135-543" aria-hidden="true" tabindex="-1"></a>  S^2_{\hat{Y_h}} = MSE \bigg<span class="co">[</span><span class="ot">\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg</span><span class="co">]</span> \hspace{20pt} \longrightarrow \hspace{20pt} S_{\hat{Y_h}} = \sqrt{S^2_{\hat{Y_h}}} = S \sqrt{\frac{1}{n} + \frac{(X_h - \bar{X})^2}{S_{XX}}}</span>
<span id="cb135-544"><a href="#cb135-544" aria-hidden="true" tabindex="-1"></a>  $$ Notes</span>
<span id="cb135-545"><a href="#cb135-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-546"><a href="#cb135-546" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The variability of the sampling distribution of $Y_h$ is affected by how far $X_h$ is from $\bar{X}$ (from the numerator of second term in $V(\hat{Y_h})$) $\Longrightarrow$ $V(\hat{Y_h})$ increases the further $X_h$ is from $\bar{X}$.</span>
<span id="cb135-547"><a href="#cb135-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-548"><a href="#cb135-548" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Intuitive / visual explanation of this affect</span>
<span id="cb135-549"><a href="#cb135-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-550"><a href="#cb135-550" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In the picture below, two regression lines are assumed to go through the same $(\bar{X}, \bar{Y})$ point to isolate the effect of variation in the estimated slope $\hat{\beta}_1$ from sample to sample.</span>
<span id="cb135-551"><a href="#cb135-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-552"><a href="#cb135-552" aria-hidden="true" tabindex="-1"></a>    <span class="al">![](files/images/variance-y-hat.png)</span>{width="40%"}</span>
<span id="cb135-553"><a href="#cb135-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-554"><a href="#cb135-554" aria-hidden="true" tabindex="-1"></a><span class="in">    -   We see the difference between estimated responses is much smaller when $X$ is near the mean $\bar{X}$. So the variation in slope from sample to sample has a much more pronounced effect for $X$ levels far from the mean.</span></span>
<span id="cb135-555"><a href="#cb135-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-556"><a href="#cb135-556" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>When $X_h = 0$ $\Longrightarrow$ $V(\hat{Y_h})$ reduces to $V(\hat{\beta}_0)$ (likewise for the estimated variances). This is because when $X_h = 0$, $\hat{Y_h} = \hat{\beta}_0 + \hat{\beta}_1 (0) = \hat{\beta}_0$.</span>
<span id="cb135-557"><a href="#cb135-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-558"><a href="#cb135-558" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb135-559"><a href="#cb135-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-560"><a href="#cb135-560" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/placeholder.png)</span>{width="50%"}</span>
<span id="cb135-561"><a href="#cb135-561" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-562"><a href="#cb135-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-563"><a href="#cb135-563" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sampling distribution of $(\hat{Y_h} - E(Y_h)) / S_{\hat{Y_h}}$</span></span>
<span id="cb135-564"><a href="#cb135-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-565"><a href="#cb135-565" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-566"><a href="#cb135-566" aria-hidden="true" tabindex="-1"></a>\frac{\hat{Y_h} - E(Y_h)}{S_{\hat{Y_h}}} = \frac{\hat{Y_h} - E(Y_h)}{\sqrt{MSE \bigg<span class="co">[</span><span class="ot">\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg</span><span class="co">]</span>}} \sim \text{t}\,_{n - 2}</span>
<span id="cb135-567"><a href="#cb135-567" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-568"><a href="#cb135-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-569"><a href="#cb135-569" aria-hidden="true" tabindex="-1"></a><span class="fu">### Confidence interval for $E(Y_h)$</span></span>
<span id="cb135-570"><a href="#cb135-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-571"><a href="#cb135-571" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Goal → Estimate the mean value of $Y$ for a given value of $X$.</span>
<span id="cb135-572"><a href="#cb135-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-573"><a href="#cb135-573" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Results → Using the same general format / derivation of a $t$ interval, we have</span>
<span id="cb135-574"><a href="#cb135-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-575"><a href="#cb135-575" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-576"><a href="#cb135-576" aria-hidden="true" tabindex="-1"></a>100(1 - \alpha)\% \text{ CI } = \hat{Y_h} \pm t_{\alpha/2, n-2} \cdot S_{\hat{Y_h}} \hspace{10pt} = \hspace{10pt} \hat{Y_h} \pm t_{\alpha/2, n-2} \cdot \sqrt{MSE \bigg<span class="co">[</span><span class="ot">\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg</span><span class="co">]</span>}</span>
<span id="cb135-577"><a href="#cb135-577" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-578"><a href="#cb135-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-579"><a href="#cb135-579" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretation → With <span class="sc">\&lt;</span> $1 - \alpha$ <span class="sc">\&gt;</span>% confidence, we estimate that the true mean value of <span class="sc">\&lt;</span> $Y$ context <span class="sc">\&gt;</span> for all individuals with an <span class="sc">\&lt;</span> $X$ context <span class="sc">\&gt;</span> of <span class="sc">\&lt;</span> $X_h$ <span class="sc">\&gt;</span> to be between <span class="sc">\&lt;</span> lower bound <span class="sc">\&gt;</span> and <span class="sc">\&lt;</span> upper bound <span class="sc">\&gt;</span>.</span>
<span id="cb135-580"><a href="#cb135-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-581"><a href="#cb135-581" aria-hidden="true" tabindex="-1"></a>Notes</span>
<span id="cb135-582"><a href="#cb135-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-583"><a href="#cb135-583" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretations → Same interpretation rules about repeated sampling for constant $X$ levels (because $X_i$ are known constants in the regression model).</span>
<span id="cb135-584"><a href="#cb135-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-585"><a href="#cb135-585" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Confidence interval width is the smallest when $X_h = \bar{X}$ (assuming everything else remains equal).</span>
<span id="cb135-586"><a href="#cb135-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-587"><a href="#cb135-587" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Design of experiments → Thus in an experiment to estimate the mean response at a particular level $X_h$, the precision of the estimate will be best if (everything else remaining equal) the observations on $X$ are spaced so that $\bar{X} = X_h$.</span>
<span id="cb135-588"><a href="#cb135-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-589"><a href="#cb135-589" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Tests → Can use the CI to perform a two-sided test as well.</span>
<span id="cb135-590"><a href="#cb135-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-591"><a href="#cb135-591" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Robust → Confidence limits shown here for $\hat{Y_h}$ are not sensitive to moderate departures from the assumption that the error terms are normally distributed. If there is substantial departures from normality, still not sensitive if large $n$; this robustness comes from robustness of CIs for $\beta_0$ and $\beta_1$.</span>
<span id="cb135-592"><a href="#cb135-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-593"><a href="#cb135-593" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Can also think of these CIs as robust because they are only concerned with the center (location) of the distribution of $Y_h$.</span>
<span id="cb135-594"><a href="#cb135-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-595"><a href="#cb135-595" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Multiple intervals → <span class="sc">\*\*</span> CIs apply when a estimating *a single mean response* from the study. Will show later how to adjust when estimating several mean responses. <span class="sc">\*\*</span></span>
<span id="cb135-596"><a href="#cb135-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-597"><a href="#cb135-597" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb135-598"><a href="#cb135-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-599"><a href="#cb135-599" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-600"><a href="#cb135-600" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-601"><a href="#cb135-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-604"><a href="#cb135-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-605"><a href="#cb135-605" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb135-606"><a href="#cb135-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-607"><a href="#cb135-607" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate sample dataset for normal error regression model</span></span>
<span id="cb135-608"><a href="#cb135-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-609"><a href="#cb135-609" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items</span></span>
<span id="cb135-610"><a href="#cb135-610" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span id="cb135-611"><a href="#cb135-611" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb135-612"><a href="#cb135-612" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb135-613"><a href="#cb135-613" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb135-614"><a href="#cb135-614" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">10</span> </span>
<span id="cb135-615"><a href="#cb135-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-616"><a href="#cb135-616" aria-hidden="true" tabindex="-1"></a><span class="co"># generate X values</span></span>
<span id="cb135-617"><a href="#cb135-617" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">15</span>)</span>
<span id="cb135-618"><a href="#cb135-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-619"><a href="#cb135-619" aria-hidden="true" tabindex="-1"></a><span class="co"># generate response Y | X ~ Normal(B0 + B1*X, sigma^2)</span></span>
<span id="cb135-620"><a href="#cb135-620" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; specify the conditional means and then incorporate the random error</span></span>
<span id="cb135-621"><a href="#cb135-621" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; rnorm() can take a vector of means and iterates through them</span></span>
<span id="cb135-622"><a href="#cb135-622" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; if there n &gt; length(means), then the means get recycled from the start</span></span>
<span id="cb135-623"><a href="#cb135-623" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x, <span class="at">sd =</span> sigma)</span>
<span id="cb135-624"><a href="#cb135-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-625"><a href="#cb135-625" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-626"><a href="#cb135-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-629"><a href="#cb135-629" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-630"><a href="#cb135-630" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb135-631"><a href="#cb135-631" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb135-632"><a href="#cb135-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-633"><a href="#cb135-633" aria-hidden="true" tabindex="-1"></a><span class="co"># specify new X level (X range is 5 - 15)</span></span>
<span id="cb135-634"><a href="#cb135-634" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; newdata frame should have columns with same name as data for the model</span></span>
<span id="cb135-635"><a href="#cb135-635" aria-hidden="true" tabindex="-1"></a>x_h <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">12</span>)</span>
<span id="cb135-636"><a href="#cb135-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-637"><a href="#cb135-637" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate just the point estimate of estimated E(Y_h)</span></span>
<span id="cb135-638"><a href="#cb135-638" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; technically using the predict() function for class lm(), so just calling predict() is masking predict.lm() --&gt; other classes like predict.glm() have slightly different argument options</span></span>
<span id="cb135-639"><a href="#cb135-639" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; by default predict() returns the fits (regression line) for all of the obs (X values) used in the model fit, can specify new data points with newdata = &lt; data_frame &gt;</span></span>
<span id="cb135-640"><a href="#cb135-640" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h)</span>
<span id="cb135-641"><a href="#cb135-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-642"><a href="#cb135-642" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate lower and upper bounds of interval estimate for E(Y_h)</span></span>
<span id="cb135-643"><a href="#cb135-643" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; by default does 95% CI and returns the point estimate (fit) as well</span></span>
<span id="cb135-644"><a href="#cb135-644" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"confidence"</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb135-645"><a href="#cb135-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-646"><a href="#cb135-646" aria-hidden="true" tabindex="-1"></a><span class="co"># show items related to standard error of estimation se(Y_h-hat)</span></span>
<span id="cb135-647"><a href="#cb135-647" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; residual.scale = S = sqrt(MSE)</span></span>
<span id="cb135-648"><a href="#cb135-648" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb135-649"><a href="#cb135-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-650"><a href="#cb135-650" aria-hidden="true" tabindex="-1"></a><span class="co"># alternate way from ALSM package</span></span>
<span id="cb135-651"><a href="#cb135-651" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; this is the package that goes with the textbook; provides some functions that are nowhere else, and some alternatives to common functions</span></span>
<span id="cb135-652"><a href="#cb135-652" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; the implementation of this function is essentially what is done in the "manual" section</span></span>
<span id="cb135-653"><a href="#cb135-653" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; type = "m" gives CI for mean observation; by default does CL of 95%, but specifies alpha</span></span>
<span id="cb135-654"><a href="#cb135-654" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; SIDENOTE -&gt; formatting: original result is a dataframe which displays poorly, so convert to matrix</span></span>
<span id="cb135-655"><a href="#cb135-655" aria-hidden="true" tabindex="-1"></a>ALSM<span class="sc">::</span><span class="fu">ci.reg</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">type =</span> <span class="st">"m"</span>, <span class="at">alpha =</span> <span class="fl">0.05</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb135-656"><a href="#cb135-656" aria-hidden="true" tabindex="-1"></a>  as.matrix</span>
<span id="cb135-657"><a href="#cb135-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-658"><a href="#cb135-658" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-659"><a href="#cb135-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-660"><a href="#cb135-660" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-661"><a href="#cb135-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-664"><a href="#cb135-664" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-665"><a href="#cb135-665" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate point estimate using estimated coefficients</span></span>
<span id="cb135-666"><a href="#cb135-666" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; hat(Y_h) = hat(beta_0) + hat(beta_1) X_h</span></span>
<span id="cb135-667"><a href="#cb135-667" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod))</span>
<span id="cb135-668"><a href="#cb135-668" aria-hidden="true" tabindex="-1"></a>pe <span class="ot">&lt;-</span> b[<span class="dv">1</span>] <span class="sc">+</span> b[<span class="dv">2</span>] <span class="sc">*</span> <span class="fu">as.numeric</span>(x_h)</span>
<span id="cb135-669"><a href="#cb135-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-670"><a href="#cb135-670" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate critical value</span></span>
<span id="cb135-671"><a href="#cb135-671" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; use lower.tail = FALSE to get the positive version of t_alpha/2</span></span>
<span id="cb135-672"><a href="#cb135-672" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb135-673"><a href="#cb135-673" aria-hidden="true" tabindex="-1"></a>t_crit <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> <span class="fu">df.residual</span>(mod), <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb135-674"><a href="#cb135-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-675"><a href="#cb135-675" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate se(Y_h-hat) = MSE (1/n (X_h - X-bar)^2 / S_XX) %&gt;% sqrt OR S * sqrt(1/n + S_XX)</span></span>
<span id="cb135-676"><a href="#cb135-676" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb135-677"><a href="#cb135-677" aria-hidden="true" tabindex="-1"></a>x_bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(x)</span>
<span id="cb135-678"><a href="#cb135-678" aria-hidden="true" tabindex="-1"></a>s_xx <span class="ot">&lt;-</span> <span class="fu">sum</span>((x <span class="sc">-</span> x_bar)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-679"><a href="#cb135-679" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> (<span class="fu">summary</span>(mod)<span class="sc">$</span>sigma)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb135-680"><a href="#cb135-680" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>residual.scale</span>
<span id="cb135-681"><a href="#cb135-681" aria-hidden="true" tabindex="-1"></a>se_yh_hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(mse <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">/</span> n <span class="sc">+</span> (<span class="fu">as.numeric</span>(x_h) <span class="sc">-</span> x_bar)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> s_xx))</span>
<span id="cb135-682"><a href="#cb135-682" aria-hidden="true" tabindex="-1"></a>se_yh_hat <span class="ot">&lt;-</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>sigma <span class="sc">*</span> <span class="fu">sqrt</span>((<span class="dv">1</span> <span class="sc">/</span> n <span class="sc">+</span> (<span class="fu">as.numeric</span>(x_h) <span class="sc">-</span> x_bar)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> s_xx))</span>
<span id="cb135-683"><a href="#cb135-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-684"><a href="#cb135-684" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate CI for E(Y_h)</span></span>
<span id="cb135-685"><a href="#cb135-685" aria-hidden="true" tabindex="-1"></a>ci_limits <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">lower =</span> pe <span class="sc">-</span> t_crit <span class="sc">*</span> se_yh_hat, <span class="at">upper =</span> pe <span class="sc">+</span> t_crit <span class="sc">*</span> se_yh_hat)</span>
<span id="cb135-686"><a href="#cb135-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-687"><a href="#cb135-687" aria-hidden="true" tabindex="-1"></a><span class="co"># compare results to predict(lm(), type = "confidence")</span></span>
<span id="cb135-688"><a href="#cb135-688" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y_h-hat and interval bounds</span></span>
<span id="cb135-689"><a href="#cb135-689" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"confidence"</span>), <span class="fu">c</span>(<span class="st">"point estimate"</span> <span class="ot">=</span> pe, ci_limits))</span>
<span id="cb135-690"><a href="#cb135-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-691"><a href="#cb135-691" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; se of estimation</span></span>
<span id="cb135-692"><a href="#cb135-692" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; by default predict uses s = sqrt(mse) = residual standard error to get the se.fit (and the df as well = df.residual(mod)) ---&gt; assumes future obs have same error variance as originals used for fitting</span></span>
<span id="cb135-693"><a href="#cb135-693" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; can specify a different variance to use for future obs with pred.var if desired</span></span>
<span id="cb135-694"><a href="#cb135-694" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>se.fit, se_yh_hat)</span>
<span id="cb135-695"><a href="#cb135-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-696"><a href="#cb135-696" aria-hidden="true" tabindex="-1"></a><span class="co"># can return fit, bounds, and standard error info from predict using type = "terms"</span></span>
<span id="cb135-697"><a href="#cb135-697" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">type =</span> <span class="st">"terms"</span>, <span class="at">interval =</span> <span class="st">"conf"</span>)</span>
<span id="cb135-698"><a href="#cb135-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-699"><a href="#cb135-699" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; for the fit and bounds, for some reason this actually uses the alternate regression model -&gt; Y_h-hat = bar(y) + beta_1-hat (X_h - bar(x))</span></span>
<span id="cb135-700"><a href="#cb135-700" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; results: constant = beta_1-hat (X_h - X-bar) and attr = Y-bar</span></span>
<span id="cb135-701"><a href="#cb135-701" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; same process to get upper and lower too, add to Y-bar</span></span>
<span id="cb135-702"><a href="#cb135-702" aria-hidden="true" tabindex="-1"></a>(x_star <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">type =</span> <span class="st">"terms"</span>))</span>
<span id="cb135-703"><a href="#cb135-703" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(pe, <span class="fu">mean</span>(y) <span class="sc">+</span> b[<span class="dv">2</span>] <span class="sc">*</span> (<span class="fu">as.numeric</span>(x_h) <span class="sc">-</span> <span class="fu">mean</span>(x)))</span>
<span id="cb135-704"><a href="#cb135-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-705"><a href="#cb135-705" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-706"><a href="#cb135-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-707"><a href="#cb135-707" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Properties</span></span>
<span id="cb135-708"><a href="#cb135-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-711"><a href="#cb135-711" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-712"><a href="#cb135-712" aria-hidden="true" tabindex="-1"></a><span class="co"># compare width of confidence intervals at two X levels</span></span>
<span id="cb135-713"><a href="#cb135-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-714"><a href="#cb135-714" aria-hidden="true" tabindex="-1"></a><span class="co"># specify new X levels (X range is 5 - 15)</span></span>
<span id="cb135-715"><a href="#cb135-715" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; optimal width will be at X = X-bar</span></span>
<span id="cb135-716"><a href="#cb135-716" aria-hidden="true" tabindex="-1"></a>x_h_mean <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">mean</span>(x))</span>
<span id="cb135-717"><a href="#cb135-717" aria-hidden="true" tabindex="-1"></a>x_h2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">8</span>)</span>
<span id="cb135-718"><a href="#cb135-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-719"><a href="#cb135-719" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate width of intervals</span></span>
<span id="cb135-720"><a href="#cb135-720" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h_mean, <span class="at">interval =</span> <span class="st">"confidence"</span>)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>] <span class="sc">%&gt;%</span> diff</span>
<span id="cb135-721"><a href="#cb135-721" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h2, <span class="at">interval =</span> <span class="st">"confidence"</span>)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>] <span class="sc">%&gt;%</span> diff</span>
<span id="cb135-722"><a href="#cb135-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-723"><a href="#cb135-723" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-724"><a href="#cb135-724" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-725"><a href="#cb135-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-726"><a href="#cb135-726" aria-hidden="true" tabindex="-1"></a><span class="fu">## Prediction of new observation</span></span>
<span id="cb135-727"><a href="#cb135-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-728"><a href="#cb135-728" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-729"><a href="#cb135-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-730"><a href="#cb135-730" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Goal → Predict a new observation $Y$ for a given $X$ value. This new observation is viewed as the result of a new trial, independent of the trials the model is based on.</span>
<span id="cb135-731"><a href="#cb135-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-732"><a href="#cb135-732" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Setup</span>
<span id="cb135-733"><a href="#cb135-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-734"><a href="#cb135-734" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Again, $X_h$ is the $X$ level for the new trial. Still assuming the underlying regression model is appropriate for the new observation.</span>
<span id="cb135-735"><a href="#cb135-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-736"><a href="#cb135-736" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The new observation on $Y$ is $Y_{h(new)}$; this is what we are estimating.</span>
<span id="cb135-737"><a href="#cb135-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-738"><a href="#cb135-738" aria-hidden="true" tabindex="-1"></a>Distinction between (1) estimation of the mean response $E(Y_h)$ and (2) prediction of a new response $Y_{h(new)}$</span>
<span id="cb135-739"><a href="#cb135-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-740"><a href="#cb135-740" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>We estimate the *mean* of the distribution of $Y$.</span>
<span id="cb135-741"><a href="#cb135-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-742"><a href="#cb135-742" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>We predict an *individual outcome* drawn from the distribution of $Y$. Obviously, most outcomes deviate from the mean response; so this must be taken into account when predicting $Y_{h(new)}$.</span>
<span id="cb135-743"><a href="#cb135-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-744"><a href="#cb135-744" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Prediction has extra variability $\Longrightarrow$ Less precision.</span>
<span id="cb135-745"><a href="#cb135-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-746"><a href="#cb135-746" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prediction interval for $Y_{h(new)}$ when parameters are known</span></span>
<span id="cb135-747"><a href="#cb135-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-748"><a href="#cb135-748" aria-hidden="true" tabindex="-1"></a>Demonstration of prediction intervals</span>
<span id="cb135-749"><a href="#cb135-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-750"><a href="#cb135-750" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For a simple example, assume the relevant parameters of the regression model are known:</span>
<span id="cb135-751"><a href="#cb135-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-752"><a href="#cb135-752" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-753"><a href="#cb135-753" aria-hidden="true" tabindex="-1"></a>\beta_0 = 0.10, \, \beta_1 = 0.95, \, \sigma = 0.12 \hspace{10pt} \longrightarrow \hspace{10pt} E(Y) = 0.10 + 0.95 X</span>
<span id="cb135-754"><a href="#cb135-754" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-755"><a href="#cb135-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-756"><a href="#cb135-756" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If we have a new observation with $X_h = 3.425$ → $E(Y_h) = 0.10 + 0.95 (3.5) = 3.425$ (so we know the center of the normal distribution of $Y_h$). Thus, using the empirical rule we have the following prediction interval:</span>
<span id="cb135-757"><a href="#cb135-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-758"><a href="#cb135-758" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-759"><a href="#cb135-759" aria-hidden="true" tabindex="-1"></a>99.7\% \text{ CI } = E(Y_h) \pm 3 \sigma \hspace{10pt} = \hspace{10pt} 3.425 \pm 3 (0.12) \hspace{10pt} \Longrightarrow \hspace{10pt} 3.065 \le Y_{h(new)} \le 3.785</span>
<span id="cb135-760"><a href="#cb135-760" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-761"><a href="#cb135-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-762"><a href="#cb135-762" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/simple-prediction-interval.png)</span>{width="30%"}</span>
<span id="cb135-763"><a href="#cb135-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-764"><a href="#cb135-764" aria-hidden="true" tabindex="-1"></a>Basic idea of prediction used here</span>
<span id="cb135-765"><a href="#cb135-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-766"><a href="#cb135-766" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Choose a range in the distribution of $Y$ where most of the observations will fall and then declare that the next observation will fall in this range.</span>
<span id="cb135-767"><a href="#cb135-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-768"><a href="#cb135-768" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The usefulness of the prediction interval depends on the width of the interval and the needs for precision by the user.</span>
<span id="cb135-769"><a href="#cb135-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-770"><a href="#cb135-770" aria-hidden="true" tabindex="-1"></a>Generalizing for this simple scenario</span>
<span id="cb135-771"><a href="#cb135-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-772"><a href="#cb135-772" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>When the regression parameters of normal error regression model are known:</span>
<span id="cb135-773"><a href="#cb135-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-774"><a href="#cb135-774" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-775"><a href="#cb135-775" aria-hidden="true" tabindex="-1"></a>100(1 - \alpha)\% \text{ PI for } Y_{h(new)} = E(Y_h) \pm z_{\alpha / 2} \cdot \sigma</span>
<span id="cb135-776"><a href="#cb135-776" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-777"><a href="#cb135-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-778"><a href="#cb135-778" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Centering the limits around $E(Y_h)$ results in the narrowest interval consistent with the specified probability of a correct prediction.</span>
<span id="cb135-779"><a href="#cb135-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-780"><a href="#cb135-780" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prediction interval for $Y_{h(new)}$ when parameters are unknown</span></span>
<span id="cb135-781"><a href="#cb135-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-782"><a href="#cb135-782" aria-hidden="true" tabindex="-1"></a>Overview and demo</span>
<span id="cb135-783"><a href="#cb135-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-784"><a href="#cb135-784" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>When the regression parameters are unknown, they must be estimated.</span>
<span id="cb135-785"><a href="#cb135-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-786"><a href="#cb135-786" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The mean of the distribution of $Y$ is estimated by $\hat{Y_h}$ as usual, and the variance of the distribution of $Y$ is estimated with $MSE$.</span>
<span id="cb135-787"><a href="#cb135-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-788"><a href="#cb135-788" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>However, we cannot simply use the previous PI with the parameters replaced by the corresponding point estimators. Here's a demo of why:</span>
<span id="cb135-789"><a href="#cb135-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-790"><a href="#cb135-790" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The picture below shows two possible probability distributions of $Y$, corresponding to the lower and upper limits of a CI for $E(Y_h)$. In other words, the distribution of $Y$ could be located as far left as the one shown, as far right as the other one shown, or anywhere in between.</span>
<span id="cb135-791"><a href="#cb135-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-792"><a href="#cb135-792" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/possible-prediction-intervals.png)</span>{width="40%"}</span>
<span id="cb135-793"><a href="#cb135-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-794"><a href="#cb135-794" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Results</span>
<span id="cb135-795"><a href="#cb135-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-796"><a href="#cb135-796" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Since we do not know the mean $E(Y_h)$ and only estimate it by a confidence interval, we cannot be certain of the location of the distribution of $Y$.</span>
<span id="cb135-797"><a href="#cb135-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-798"><a href="#cb135-798" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Because of this uncertainty, PIs for $Y_{h(new)}$ clearly must take into account two elements:</span>
<span id="cb135-799"><a href="#cb135-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-800"><a href="#cb135-800" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>Variation in possible location of the distribution of $Y$.</span>
<span id="cb135-801"><a href="#cb135-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-802"><a href="#cb135-802" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>Variation within the probability distribution of $Y$.</span>
<span id="cb135-803"><a href="#cb135-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-804"><a href="#cb135-804" aria-hidden="true" tabindex="-1"></a>Prediction interval for $Y_{h(new)}$</span>
<span id="cb135-805"><a href="#cb135-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-806"><a href="#cb135-806" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Sampling distribution</span>
<span id="cb135-807"><a href="#cb135-807" aria-hidden="true" tabindex="-1"></a>         </span>
<span id="cb135-808"><a href="#cb135-808" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Note that this studentized statistic uses the point estimator $\hat{Y_h}$ in the numerator rather than the true mean $E(Y_h)$ because the true mean is unknown and cannot be used in making a prediction.</span>
<span id="cb135-809"><a href="#cb135-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-810"><a href="#cb135-810" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>For $E(Y_h)$ CIs shown earlier, we used $[\hat{Y_h} - E(Y_h)] / S_{\hat{Y_h}}$, which was okay because the only unknown was $E(Y_h)$ and it is what we are estimating. But now there are two layers of uncertainty (variability). So the reference value in the numerator is also an estimate, not the true value.</span>
<span id="cb135-811"><a href="#cb135-811" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-812"><a href="#cb135-812" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-813"><a href="#cb135-813" aria-hidden="true" tabindex="-1"></a>\frac{Y_{h(new)} - \hat{Y_h}}{S_{pred}} \sim \text{t}\,_{n-2}</span>
<span id="cb135-814"><a href="#cb135-814" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-815"><a href="#cb135-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-816"><a href="#cb135-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-817"><a href="#cb135-817" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Prediction interval</span>
<span id="cb135-818"><a href="#cb135-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-819"><a href="#cb135-819" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Interpretation → With <span class="sc">\&lt;</span> $1-\alpha$ <span class="sc">\&gt;</span>% confidence, we predict that the true value of <span class="sc">\&lt;</span> $Y$ context <span class="sc">\&gt;</span> for a single (or the next) <span class="sc">\&lt;</span> $X$ context <span class="sc">\&gt;</span> of <span class="sc">\&lt;</span> $X_h$ <span class="sc">\&gt;</span> to be between <span class="sc">\&lt;</span> lower bound <span class="sc">\&gt;</span> and <span class="sc">\&lt;</span> upper bound <span class="sc">\&gt;</span>.</span>
<span id="cb135-820"><a href="#cb135-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-821"><a href="#cb135-821" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-822"><a href="#cb135-822" aria-hidden="true" tabindex="-1"></a>100(1 - \alpha)\% \text{ PI for } Y_{h(new)} = \hat{Y_h} \pm t_{\alpha/2, n-2} \cdot S_{pred}</span>
<span id="cb135-823"><a href="#cb135-823" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-824"><a href="#cb135-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-825"><a href="#cb135-825" aria-hidden="true" tabindex="-1"></a>Standard deviation of prediction $\sigma^2_{pred}$</span>
<span id="cb135-826"><a href="#cb135-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-827"><a href="#cb135-827" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The numerator of the studentized statistic represents how far the new observation will deviate from the estimated mean (based on the original $n$ cases in the study). This difference can be viewed as the prediction error, with $\hat{Y_h}$ serving as the best point estimate of the value of the new observation $Y_{h(new)}$.</span>
<span id="cb135-828"><a href="#cb135-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-829"><a href="#cb135-829" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We can easily find the variance of this difference (because of independence of the new $Y_{h(new)}$ and original $n$ cases on which $\hat{Y_h}$ is based).</span>
<span id="cb135-830"><a href="#cb135-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-831"><a href="#cb135-831" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-832"><a href="#cb135-832" aria-hidden="true" tabindex="-1"></a>\sigma^2_{pred} = V(Y_{h(new)} - \hat{Y_h}) = V(Y_{h(new)}) + V(\hat{Y_h}) = \sigma^2 + \sigma^2_{\hat{Y_h}}.</span>
<span id="cb135-833"><a href="#cb135-833" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-834"><a href="#cb135-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-835"><a href="#cb135-835" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This has two components:</span>
<span id="cb135-836"><a href="#cb135-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-837"><a href="#cb135-837" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>Variance of the distribution of $Y$ at $X = X_h$ → $\sigma^2$</span>
<span id="cb135-838"><a href="#cb135-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-839"><a href="#cb135-839" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>Variance of the sampling distribution of $\hat{Y_h}$ → $\sigma^2_{\hat{Y_h}}$</span>
<span id="cb135-840"><a href="#cb135-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-841"><a href="#cb135-841" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The unbiased estimator of $\sigma^2_{pred}$ is</span>
<span id="cb135-842"><a href="#cb135-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-843"><a href="#cb135-843" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-844"><a href="#cb135-844" aria-hidden="true" tabindex="-1"></a>S^2_{pred} = MSE + S^2_{\hat{Y_h}} = MSE + MSE \bigg<span class="co">[</span><span class="ot">\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg</span><span class="co">]</span> = MSE \bigg<span class="co">[</span><span class="ot">1 + \frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum (X_i - \bar{X})^2}\bigg</span><span class="co">]</span> \hspace{20pt} \longrightarrow \hspace{20pt} S_{pred} = \sqrt{S^2_{pred}}</span>
<span id="cb135-845"><a href="#cb135-845" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-846"><a href="#cb135-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-847"><a href="#cb135-847" aria-hidden="true" tabindex="-1"></a>Notes about prediction intervals</span>
<span id="cb135-848"><a href="#cb135-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-849"><a href="#cb135-849" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Analogous results / interpretations to estimation</span>
<span id="cb135-850"><a href="#cb135-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-851"><a href="#cb135-851" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Interpretation → Again, the confidence coefficient refers to taking repeated samples based on the same set of $X$ values, and calculating prediction limits for $Y_{h(new)}$ for each sample.</span>
<span id="cb135-852"><a href="#cb135-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-853"><a href="#cb135-853" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Precision → PI width is the smallest when $X_h = \bar{X}$ (assuming everything else remains equal).</span>
<span id="cb135-854"><a href="#cb135-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-855"><a href="#cb135-855" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>One interval → PIs apply for a single prediction based on the sample data.</span>
<span id="cb135-856"><a href="#cb135-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-857"><a href="#cb135-857" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Not robust → PIs (unlike CIs for the mean response) are sensitive to departures from normality of the error terms distribution. Can think of this non-robustness a result of having to take into account the center of the distribution of $Y_h$ (just like with CIs) AND also the tails (spread) of the distribution.</span>
<span id="cb135-858"><a href="#cb135-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-859"><a href="#cb135-859" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Precision → Even if PIs are too wide for useful predictions, they can still be informative for control / modelling purposes, specifically the estimated variance of prediction.</span>
<span id="cb135-860"><a href="#cb135-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-861"><a href="#cb135-861" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$S^2_{pred} = MSE + S^2_{\hat{Y_h}} \hspace{10pt}$ has two pieces: (1) $MSE$ measures $X$-to-$X$ variation within the probability distribution for $Y$ (different response values for observations with same $X$ level) and (2) $S^2_{\hat{Y_h}}$ measures sample-to-sample variation (mean response of samples with overall same $X$ levels).</span>
<span id="cb135-862"><a href="#cb135-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-863"><a href="#cb135-863" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>So if $MSE$ is very large compared to $S^2_{\hat{Y_h}}$, e.g. $\frac{MSE}{S^2_{pred}} \ge 0.8 \text{ or } 0.9$, then the majority of the variation is from sample-to-sample. This could reflect other factors that aren't being taken into account by the model. So perhaps a multiple linear regression model should be used, which could result in more useful predictions.&lt;mark&gt; NOT SURE HOW THIS WORKS&lt;/mark&gt;</span>
<span id="cb135-864"><a href="#cb135-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-865"><a href="#cb135-865" aria-hidden="true" tabindex="-1"></a>Estimation vs Prediction</span>
<span id="cb135-866"><a href="#cb135-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-867"><a href="#cb135-867" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Location → For a particular $X_h$, CIs and PIs have the same point estimate $\hat{Y_h}$, which is the estimate of the mean $E(Y_h)$.</span>
<span id="cb135-868"><a href="#cb135-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-869"><a href="#cb135-869" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Precision</span>
<span id="cb135-870"><a href="#cb135-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-871"><a href="#cb135-871" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The difference between CIs and PIs then lies in the relative accuracy of the interval.</span>
<span id="cb135-872"><a href="#cb135-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-873"><a href="#cb135-873" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>CIs are narrower than PIs at the same $X_h$.</span>
<span id="cb135-874"><a href="#cb135-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-875"><a href="#cb135-875" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The only way to obtain more accurate prediction for a new value of $Y$ is to reduce the standard deviation of the regression model. This can be accomplished by using a curvilinear model, adding new independent variables, etc. or by collecting more data (width of both intervals decrease when the sample size increases).</span>
<span id="cb135-876"><a href="#cb135-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-877"><a href="#cb135-877" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Conceptual difference → CIs resemble PIs, except: A CI represents an inference on a parameter and is an interval that is intended to cover the value of the parameter; and a PI is a statement about the value to be taken by a random variable, the new observation $Y_{h(new)}$.</span>
<span id="cb135-878"><a href="#cb135-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-879"><a href="#cb135-879" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb135-880"><a href="#cb135-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-881"><a href="#cb135-881" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-882"><a href="#cb135-882" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-883"><a href="#cb135-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-886"><a href="#cb135-886" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-887"><a href="#cb135-887" aria-hidden="true" tabindex="-1"></a><span class="co"># using the same model as the confidence interval for E(Y_h) demo</span></span>
<span id="cb135-888"><a href="#cb135-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-889"><a href="#cb135-889" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate just the point estimate of predicted Y_h(new)</span></span>
<span id="cb135-890"><a href="#cb135-890" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; this is the same as the PE for a CI of E(Y_h) </span></span>
<span id="cb135-891"><a href="#cb135-891" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h)</span>
<span id="cb135-892"><a href="#cb135-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-893"><a href="#cb135-893" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate lower and upper bounds of prediction interval Y_h(new)</span></span>
<span id="cb135-894"><a href="#cb135-894" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; by default does 95% CI and returns the point estimate (fit) as well</span></span>
<span id="cb135-895"><a href="#cb135-895" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"prediction"</span>)</span>
<span id="cb135-896"><a href="#cb135-896" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"co"</span>)</span>
<span id="cb135-897"><a href="#cb135-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-898"><a href="#cb135-898" aria-hidden="true" tabindex="-1"></a><span class="co"># show items related to standard error of ESTIMATION se(Y_h-hat)</span></span>
<span id="cb135-899"><a href="#cb135-899" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; ALWAYS returns this, even if specify interval = "pred"...</span></span>
<span id="cb135-900"><a href="#cb135-900" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; suppose it implicitly adds the extra MSE term (from residual.scale) to get the prediction lwr and upr</span></span>
<span id="cb135-901"><a href="#cb135-901" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb135-902"><a href="#cb135-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-903"><a href="#cb135-903" aria-hidden="true" tabindex="-1"></a><span class="co"># alternative way using ALSM</span></span>
<span id="cb135-904"><a href="#cb135-904" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; type = "n" gives PI for single new observation</span></span>
<span id="cb135-905"><a href="#cb135-905" aria-hidden="true" tabindex="-1"></a>ALSM<span class="sc">::</span><span class="fu">ci.reg</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">type =</span> <span class="st">"n"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb135-906"><a href="#cb135-906" aria-hidden="true" tabindex="-1"></a>  as.matrix</span>
<span id="cb135-907"><a href="#cb135-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-908"><a href="#cb135-908" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-909"><a href="#cb135-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-910"><a href="#cb135-910" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-911"><a href="#cb135-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-914"><a href="#cb135-914" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-915"><a href="#cb135-915" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate point estimate and critical value</span></span>
<span id="cb135-916"><a href="#cb135-916" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; same as for confidence interval</span></span>
<span id="cb135-917"><a href="#cb135-917" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod))</span>
<span id="cb135-918"><a href="#cb135-918" aria-hidden="true" tabindex="-1"></a>pe <span class="ot">&lt;-</span> b[<span class="dv">1</span>] <span class="sc">+</span> b[<span class="dv">2</span>] <span class="sc">*</span> <span class="fu">as.numeric</span>(x_h)</span>
<span id="cb135-919"><a href="#cb135-919" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb135-920"><a href="#cb135-920" aria-hidden="true" tabindex="-1"></a>t_crit <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> <span class="fu">df.residual</span>(mod), <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb135-921"><a href="#cb135-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-922"><a href="#cb135-922" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate standard error in prediction se(pred) = sqrt(MSE + var(Y-h-hat))</span></span>
<span id="cb135-923"><a href="#cb135-923" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; save se(estimation = fit), shown earlier, then have to add in the extra MSE term</span></span>
<span id="cb135-924"><a href="#cb135-924" aria-hidden="true" tabindex="-1"></a>se_fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>se.fit</span>
<span id="cb135-925"><a href="#cb135-925" aria-hidden="true" tabindex="-1"></a>se_pred <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">summary</span>(mod)<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> se_fit<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-926"><a href="#cb135-926" aria-hidden="true" tabindex="-1"></a>se_pred <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">summary</span>(mod)<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> se_fit<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-927"><a href="#cb135-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-928"><a href="#cb135-928" aria-hidden="true" tabindex="-1"></a><span class="co"># OR calculate se(pred) using expanded formula se(pred) = MSE * (1 + 1/n (X_h - X-bar)^2 / S_XX) %&gt;% sqrt OR s * sqrt(...)</span></span>
<span id="cb135-929"><a href="#cb135-929" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb135-930"><a href="#cb135-930" aria-hidden="true" tabindex="-1"></a>x_bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(x)</span>
<span id="cb135-931"><a href="#cb135-931" aria-hidden="true" tabindex="-1"></a>s_xx <span class="ot">&lt;-</span> <span class="fu">sum</span>((x <span class="sc">-</span> x_bar)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-932"><a href="#cb135-932" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> (<span class="fu">summary</span>(mod)<span class="sc">$</span>sigma)</span>
<span id="cb135-933"><a href="#cb135-933" aria-hidden="true" tabindex="-1"></a>se_pred <span class="ot">&lt;-</span> s <span class="sc">*</span> <span class="fu">sqrt</span>((<span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span> <span class="sc">/</span> n <span class="sc">+</span> (<span class="fu">as.numeric</span>(x_h) <span class="sc">-</span> x_bar)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> s_xx))</span>
<span id="cb135-934"><a href="#cb135-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-935"><a href="#cb135-935" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate PI for Y_h(new)</span></span>
<span id="cb135-936"><a href="#cb135-936" aria-hidden="true" tabindex="-1"></a>pi_limits <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">lower =</span> pe <span class="sc">-</span> t_crit <span class="sc">*</span> se_pred, <span class="at">upper =</span> pe <span class="sc">+</span> t_crit <span class="sc">*</span> se_pred)</span>
<span id="cb135-937"><a href="#cb135-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-938"><a href="#cb135-938" aria-hidden="true" tabindex="-1"></a><span class="co"># compare results to predict(lm(), type = "prediction)</span></span>
<span id="cb135-939"><a href="#cb135-939" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; Y_h-hat and interval bounds</span></span>
<span id="cb135-940"><a href="#cb135-940" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"prediction"</span>), <span class="fu">c</span>(<span class="st">"point estimate"</span> <span class="ot">=</span> pe, pi_limits))</span>
<span id="cb135-941"><a href="#cb135-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-942"><a href="#cb135-942" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-943"><a href="#cb135-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-944"><a href="#cb135-944" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Properties</span></span>
<span id="cb135-945"><a href="#cb135-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-948"><a href="#cb135-948" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-949"><a href="#cb135-949" aria-hidden="true" tabindex="-1"></a><span class="co"># compare width of prediction intervals at two X levels</span></span>
<span id="cb135-950"><a href="#cb135-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-951"><a href="#cb135-951" aria-hidden="true" tabindex="-1"></a><span class="co"># specify new X levels (X range is 5 - 15)</span></span>
<span id="cb135-952"><a href="#cb135-952" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; optimal width will again be at X = X-bar</span></span>
<span id="cb135-953"><a href="#cb135-953" aria-hidden="true" tabindex="-1"></a>x_h_mean <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">mean</span>(x))</span>
<span id="cb135-954"><a href="#cb135-954" aria-hidden="true" tabindex="-1"></a>x_h2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">8</span>)</span>
<span id="cb135-955"><a href="#cb135-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-956"><a href="#cb135-956" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate width of intervals</span></span>
<span id="cb135-957"><a href="#cb135-957" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h_mean, <span class="at">interval =</span> <span class="st">"prediction"</span>)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>] <span class="sc">%&gt;%</span> diff</span>
<span id="cb135-958"><a href="#cb135-958" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h2, <span class="at">interval =</span> <span class="st">"prediction"</span>)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>] <span class="sc">%&gt;%</span> diff</span>
<span id="cb135-959"><a href="#cb135-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-960"><a href="#cb135-960" aria-hidden="true" tabindex="-1"></a><span class="co"># compare widths of CI vs PI at the same X level</span></span>
<span id="cb135-961"><a href="#cb135-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-962"><a href="#cb135-962" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate width of intervals</span></span>
<span id="cb135-963"><a href="#cb135-963" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"conf"</span>)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>] <span class="sc">%&gt;%</span> diff</span>
<span id="cb135-964"><a href="#cb135-964" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"pred"</span>)[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>] <span class="sc">%&gt;%</span> diff</span>
<span id="cb135-965"><a href="#cb135-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-966"><a href="#cb135-966" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-967"><a href="#cb135-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-968"><a href="#cb135-968" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- question --&gt;</span></span>
<span id="cb135-969"><a href="#cb135-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-970"><a href="#cb135-970" aria-hidden="true" tabindex="-1"></a><span class="in">```{r question2}</span></span>
<span id="cb135-971"><a href="#cb135-971" aria-hidden="true" tabindex="-1"></a><span class="in">#| eval = FALSE,</span></span>
<span id="cb135-972"><a href="#cb135-972" aria-hidden="true" tabindex="-1"></a><span class="in">#| echo = FALSE</span></span>
<span id="cb135-973"><a href="#cb135-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-974"><a href="#cb135-974" aria-hidden="true" tabindex="-1"></a><span class="in"># function to calculate mse, var(estimation) and var(prediction) for a given model and X level</span></span>
<span id="cb135-975"><a href="#cb135-975" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; inputs: lm() object and df of x values</span></span>
<span id="cb135-976"><a href="#cb135-976" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; returns vector of length 3</span></span>
<span id="cb135-977"><a href="#cb135-977" aria-hidden="true" tabindex="-1"></a><span class="in">get_pred_var &lt;- function(mod, x_h) {</span></span>
<span id="cb135-978"><a href="#cb135-978" aria-hidden="true" tabindex="-1"></a><span class="in">  </span></span>
<span id="cb135-979"><a href="#cb135-979" aria-hidden="true" tabindex="-1"></a><span class="in">    mse = summary(mod)$sigma^2</span></span>
<span id="cb135-980"><a href="#cb135-980" aria-hidden="true" tabindex="-1"></a><span class="in">    var_yh_hat = predict(mod, newdata = x_h, se.fit = TRUE)$se.fit^2</span></span>
<span id="cb135-981"><a href="#cb135-981" aria-hidden="true" tabindex="-1"></a><span class="in">    var_pred = mse + var_yh_hat</span></span>
<span id="cb135-982"><a href="#cb135-982" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb135-983"><a href="#cb135-983" aria-hidden="true" tabindex="-1"></a><span class="in">    return(c(mse = mse, "var(estimation)" = var_yh_hat, "var(pred)" = var_pred))</span></span>
<span id="cb135-984"><a href="#cb135-984" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb135-985"><a href="#cb135-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-986"><a href="#cb135-986" aria-hidden="true" tabindex="-1"></a><span class="in"># simulation to determine how much leaving out a predictor impacts the ratio of MSE to V(pred)</span></span>
<span id="cb135-987"><a href="#cb135-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-988"><a href="#cb135-988" aria-hidden="true" tabindex="-1"></a><span class="in"># setup two population models / datasets</span></span>
<span id="cb135-989"><a href="#cb135-989" aria-hidden="true" tabindex="-1"></a><span class="in"># 1: Y1 = B0 + B1X1 -&gt; responses just based on one predictor</span></span>
<span id="cb135-990"><a href="#cb135-990" aria-hidden="true" tabindex="-1"></a><span class="in"># 2: Y2 = B0 + B1X1 + B2 X2 =&gt; responses now based on two predictors</span></span>
<span id="cb135-991"><a href="#cb135-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-992"><a href="#cb135-992" aria-hidden="true" tabindex="-1"></a><span class="in"># initialize items</span></span>
<span id="cb135-993"><a href="#cb135-993" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; sample size, population parameters and error variance</span></span>
<span id="cb135-994"><a href="#cb135-994" aria-hidden="true" tabindex="-1"></a><span class="in">n &lt;- 30; beta_0 &lt;- 2; beta_1 &lt;- 5; beta_2 &lt;- -5; beta_3 &lt;- 2; sigma &lt;- 10</span></span>
<span id="cb135-995"><a href="#cb135-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-996"><a href="#cb135-996" aria-hidden="true" tabindex="-1"></a><span class="in"># generate X values, same scope for each</span></span>
<span id="cb135-997"><a href="#cb135-997" aria-hidden="true" tabindex="-1"></a><span class="in">x_1 &lt;- runif(n = n, min = 5, max = 15)</span></span>
<span id="cb135-998"><a href="#cb135-998" aria-hidden="true" tabindex="-1"></a><span class="in">x_2 &lt;- runif(n = n, min = 5, max = 15)</span></span>
<span id="cb135-999"><a href="#cb135-999" aria-hidden="true" tabindex="-1"></a><span class="in">x_3 &lt;- runif(n = n, min = 0, max = 100)</span></span>
<span id="cb135-1000"><a href="#cb135-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1001"><a href="#cb135-1001" aria-hidden="true" tabindex="-1"></a><span class="in"># generate one set of error terms</span></span>
<span id="cb135-1002"><a href="#cb135-1002" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; this way the ONLY difference between the two datasets is the different conditional means because of the extra predictor</span></span>
<span id="cb135-1003"><a href="#cb135-1003" aria-hidden="true" tabindex="-1"></a><span class="in">epsilon &lt;- rnorm(n = n, mean = 0, sd = sigma)</span></span>
<span id="cb135-1004"><a href="#cb135-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1005"><a href="#cb135-1005" aria-hidden="true" tabindex="-1"></a><span class="in"># generate responses</span></span>
<span id="cb135-1006"><a href="#cb135-1006" aria-hidden="true" tabindex="-1"></a><span class="in"># model 1: Y1 | X1 ~ Normal(B0 + B1*X1, sigma^2)</span></span>
<span id="cb135-1007"><a href="#cb135-1007" aria-hidden="true" tabindex="-1"></a><span class="in"># model 2: Y2 | X1, X2 ~ Normal(B0 + B1*X1 + B2*X2, sigma^2)</span></span>
<span id="cb135-1008"><a href="#cb135-1008" aria-hidden="true" tabindex="-1"></a><span class="in">y_1 &lt;- beta_0 + beta_1 * x_1 + epsilon</span></span>
<span id="cb135-1009"><a href="#cb135-1009" aria-hidden="true" tabindex="-1"></a><span class="in">y_2 &lt;- beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + epsilon</span></span>
<span id="cb135-1010"><a href="#cb135-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1011"><a href="#cb135-1011" aria-hidden="true" tabindex="-1"></a><span class="in"># fit models</span></span>
<span id="cb135-1012"><a href="#cb135-1012" aria-hidden="true" tabindex="-1"></a><span class="in"># model 1: correctly fit on just X1</span></span>
<span id="cb135-1013"><a href="#cb135-1013" aria-hidden="true" tabindex="-1"></a><span class="in"># model 2: incorrectly fit on just X1</span></span>
<span id="cb135-1014"><a href="#cb135-1014" aria-hidden="true" tabindex="-1"></a><span class="in">mod_1 &lt;- lm(y_1 ~ x_1)</span></span>
<span id="cb135-1015"><a href="#cb135-1015" aria-hidden="true" tabindex="-1"></a><span class="in">mod_2 &lt;- lm(y_2 ~ x_1)</span></span>
<span id="cb135-1016"><a href="#cb135-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1017"><a href="#cb135-1017" aria-hidden="true" tabindex="-1"></a><span class="in"># calculate mse, se(Y_h-hat) and se(pred) for both models</span></span>
<span id="cb135-1018"><a href="#cb135-1018" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; iterate over list of both models; set names so output list elements are labelled</span></span>
<span id="cb135-1019"><a href="#cb135-1019" aria-hidden="true" tabindex="-1"></a><span class="in">(var_info &lt;- list(mod_1, mod_2) %&gt;% </span></span>
<span id="cb135-1020"><a href="#cb135-1020" aria-hidden="true" tabindex="-1"></a><span class="in">  set_names(nm = c("mod_1", "mod_2")) %&gt;% </span></span>
<span id="cb135-1021"><a href="#cb135-1021" aria-hidden="true" tabindex="-1"></a><span class="in">  map(\(mod) get_pred_var(mod, x_h = data.frame(x_1 = 12))))</span></span>
<span id="cb135-1022"><a href="#cb135-1022" aria-hidden="true" tabindex="-1"></a><span class="in">  </span></span>
<span id="cb135-1023"><a href="#cb135-1023" aria-hidden="true" tabindex="-1"></a><span class="in"># display / compare ratio of MSE to V(pred)</span></span>
<span id="cb135-1024"><a href="#cb135-1024" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; RESULTS: results are obviously a function of the original sigma^2 AND the effect (slope) of the extra predictor, but ratio for mis-specified model does seem to be much larger even with small sigma^2 and beta1</span></span>
<span id="cb135-1025"><a href="#cb135-1025" aria-hidden="true" tabindex="-1"></a><span class="in">var_info %&gt;% </span></span>
<span id="cb135-1026"><a href="#cb135-1026" aria-hidden="true" tabindex="-1"></a><span class="in">  map(\(x) as.numeric(x["mse"] / x["var(pred)"]))</span></span>
<span id="cb135-1027"><a href="#cb135-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1028"><a href="#cb135-1028" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1029"><a href="#cb135-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1032"><a href="#cb135-1032" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1033"><a href="#cb135-1033" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval = FALSE,</span></span>
<span id="cb135-1034"><a href="#cb135-1034" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo = FALSE</span></span>
<span id="cb135-1035"><a href="#cb135-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1036"><a href="#cb135-1036" aria-hidden="true" tabindex="-1"></a><span class="co"># fit models</span></span>
<span id="cb135-1037"><a href="#cb135-1037" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; can fit models for multiple independent responses with same call, just specify a matrix of responses</span></span>
<span id="cb135-1038"><a href="#cb135-1038" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; then a linear model is fitted separately by LSE to each column (using the same predictors, RHS)</span></span>
<span id="cb135-1039"><a href="#cb135-1039" aria-hidden="true" tabindex="-1"></a><span class="co"># format of results</span></span>
<span id="cb135-1040"><a href="#cb135-1040" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; now have mlm object (multivariate linear model)</span></span>
<span id="cb135-1041"><a href="#cb135-1041" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; print just one set for model</span></span>
<span id="cb135-1042"><a href="#cb135-1042" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; items of mods object (coefficients, residuals, fitted.values) are now matrices with columns for each model</span></span>
<span id="cb135-1043"><a href="#cb135-1043" aria-hidden="true" tabindex="-1"></a>mods <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">cbind</span>(y_1, y_2) <span class="sc">~</span> x_1)</span>
<span id="cb135-1044"><a href="#cb135-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1045"><a href="#cb135-1045" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the mse, var(estimation) and var(prediction) for a given model and X level</span></span>
<span id="cb135-1046"><a href="#cb135-1046" aria-hidden="true" tabindex="-1"></a>x_h <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x_1 =</span> <span class="dv">12</span>)</span>
<span id="cb135-1047"><a href="#cb135-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1048"><a href="#cb135-1048" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; model summary then is a list with an element for each model</span></span>
<span id="cb135-1049"><a href="#cb135-1049" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> <span class="fu">summary</span>(mods) <span class="sc">%&gt;%</span> <span class="fu">map_dbl</span>(\(summ) summ<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-1050"><a href="#cb135-1050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1051"><a href="#cb135-1051" aria-hidden="true" tabindex="-1"></a><span class="co"># using predict()</span></span>
<span id="cb135-1052"><a href="#cb135-1052" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mods, <span class="at">newdata =</span> x_h)</span>
<span id="cb135-1053"><a href="#cb135-1053" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mods, <span class="at">newdata =</span> x_h, <span class="at">se.fit =</span> <span class="cn">TRUE</span>) <span class="co"># doesn't work</span></span>
<span id="cb135-1054"><a href="#cb135-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1055"><a href="#cb135-1055" aria-hidden="true" tabindex="-1"></a><span class="co"># ??? is it really fitting two completely separate (independent) models, or does the multivariate aspect mean there is some relation?</span></span>
<span id="cb135-1056"><a href="#cb135-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1057"><a href="#cb135-1057" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1058"><a href="#cb135-1058" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-1059"><a href="#cb135-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1060"><a href="#cb135-1060" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prediction of mean of $m$ observations for given $X_h$</span></span>
<span id="cb135-1061"><a href="#cb135-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1062"><a href="#cb135-1062" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-1063"><a href="#cb135-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1064"><a href="#cb135-1064" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Goal → Predict the mean of $m$ new observations on $Y$ for a given level of the predictor variable.</span>
<span id="cb135-1065"><a href="#cb135-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1066"><a href="#cb135-1066" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Setup → $\bar{Y}_{h(new)}$ represents the mean of the new $Y$ observations to be predicted.</span>
<span id="cb135-1067"><a href="#cb135-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1068"><a href="#cb135-1068" aria-hidden="true" tabindex="-1"></a>Results</span>
<span id="cb135-1069"><a href="#cb135-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1070"><a href="#cb135-1070" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$100(1 - \alpha)\%$ Prediction interval for $\bar{Y}_{h(new)}$ (assuming the new observations are independent):</span>
<span id="cb135-1071"><a href="#cb135-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1072"><a href="#cb135-1072" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1073"><a href="#cb135-1073" aria-hidden="true" tabindex="-1"></a>\hat{Y_h} \pm t_{(1 - alpha /2, n - 2)} \cdot S_{predmean}</span>
<span id="cb135-1074"><a href="#cb135-1074" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1075"><a href="#cb135-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1076"><a href="#cb135-1076" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Standard deviation in prediction of a mean $S_{predmean}$</span>
<span id="cb135-1077"><a href="#cb135-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1078"><a href="#cb135-1078" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1079"><a href="#cb135-1079" aria-hidden="true" tabindex="-1"></a>S^2_{predmean} = \frac{MSE}{m} + S^2_{\hat{Y_h}}  = MSE \bigg<span class="co">[</span><span class="ot">\frac{1}{m} + \frac{1}{n} + \frac{(X_h - \bar{X})^2}{S_{XX}}\bigg</span><span class="co">]</span>  \hspace{20pt} \longrightarrow \hspace{20pt} S_{predmean} = \sqrt{S^2_{predmean}}</span>
<span id="cb135-1080"><a href="#cb135-1080" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1081"><a href="#cb135-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1082"><a href="#cb135-1082" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This has two components:</span>
<span id="cb135-1083"><a href="#cb135-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1084"><a href="#cb135-1084" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>Variance of the distribution mean of $m$ observations from the probability distrubtion of $Y$ at $X = X_h$ → $\sigma^2 / m$</span>
<span id="cb135-1085"><a href="#cb135-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1086"><a href="#cb135-1086" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>Variance of the sampling distribution of $\hat{Y_h}$ → $\sigma^2_{\hat{Y_h}}$</span>
<span id="cb135-1087"><a href="#cb135-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1088"><a href="#cb135-1088" aria-hidden="true" tabindex="-1"></a>Notes</span>
<span id="cb135-1089"><a href="#cb135-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1090"><a href="#cb135-1090" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretation → With <span class="sc">\&lt;</span> $1 - \alpha$ <span class="sc">\&gt;</span>% confidence, we predict that the true value of <span class="sc">\&lt;</span> $Y$ context <span class="sc">\&gt;</span> for <span class="sc">\&lt;</span> $m$ <span class="sc">\&gt;</span> <span class="sc">\&lt;</span> $X$ context <span class="sc">\&gt;</span> of <span class="sc">\&lt;</span> $X_h$ <span class="sc">\&gt;</span> to be between <span class="sc">\&lt;</span> lower bound <span class="sc">\&gt;</span> and <span class="sc">\&lt;</span> upper bound <span class="sc">\&gt;</span>.</span>
<span id="cb135-1091"><a href="#cb135-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1092"><a href="#cb135-1092" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interval still has the same center as when estimating $E(Y_h)$ and predicting a single $Y_{h(new)}$.</span>
<span id="cb135-1093"><a href="#cb135-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1094"><a href="#cb135-1094" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This prediction interval is narrower than when predicting for a single observation (because it involves the prediction of the mean for a group), but still wider than the confidence interval.</span>
<span id="cb135-1095"><a href="#cb135-1095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1096"><a href="#cb135-1096" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We can then obtain the prediction interval for the total of the $m$ observations by multiplying each limit by $m$.</span>
<span id="cb135-1097"><a href="#cb135-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1098"><a href="#cb135-1098" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>e.g) For $m = 4$, if $5 \le \bar{Y}_{h(new)} \le 15 \hspace{10pt} \Longrightarrow \hspace{10pt} 5(4) = 20 \le \sum Y_{h(new)} \le 15(4)= 60$</span>
<span id="cb135-1099"><a href="#cb135-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1100"><a href="#cb135-1100" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb135-1101"><a href="#cb135-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1102"><a href="#cb135-1102" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-1103"><a href="#cb135-1103" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-1104"><a href="#cb135-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1107"><a href="#cb135-1107" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1108"><a href="#cb135-1108" aria-hidden="true" tabindex="-1"></a><span class="co"># using the same model as the confidence interval for E(Y_h) demo</span></span>
<span id="cb135-1109"><a href="#cb135-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1110"><a href="#cb135-1110" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the predicted mean for m observations of Y_h(new)</span></span>
<span id="cb135-1111"><a href="#cb135-1111" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; type = "nm" is gives PR for mean of m new observations at X_h</span></span>
<span id="cb135-1112"><a href="#cb135-1112" aria-hidden="true" tabindex="-1"></a>ALSM<span class="sc">::</span><span class="fu">ci.reg</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">type =</span> <span class="st">"nm"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb135-1113"><a href="#cb135-1113" aria-hidden="true" tabindex="-1"></a>  as.matrix</span>
<span id="cb135-1114"><a href="#cb135-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1115"><a href="#cb135-1115" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1116"><a href="#cb135-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1117"><a href="#cb135-1117" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-1118"><a href="#cb135-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1121"><a href="#cb135-1121" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1122"><a href="#cb135-1122" aria-hidden="true" tabindex="-1"></a><span class="co"># set number of observations to predict at X_h</span></span>
<span id="cb135-1123"><a href="#cb135-1123" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb135-1124"><a href="#cb135-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1125"><a href="#cb135-1125" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate just the point estimate of predicted Y-bar_h(new) and critical value</span></span>
<span id="cb135-1126"><a href="#cb135-1126" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; PE is the same as previous CI and PI</span></span>
<span id="cb135-1127"><a href="#cb135-1127" aria-hidden="true" tabindex="-1"></a>pe <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h))</span>
<span id="cb135-1128"><a href="#cb135-1128" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb135-1129"><a href="#cb135-1129" aria-hidden="true" tabindex="-1"></a>t_crit <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> <span class="fu">df.residual</span>(mod), <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb135-1130"><a href="#cb135-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1131"><a href="#cb135-1131" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate standard error in prediction se(pred) = sqrt(MSE / m + var(Y-h-hat))</span></span>
<span id="cb135-1132"><a href="#cb135-1132" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; save se(fit), shown earlier, then have to add in the extra MSE / m term</span></span>
<span id="cb135-1133"><a href="#cb135-1133" aria-hidden="true" tabindex="-1"></a>se_fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>se.fit</span>
<span id="cb135-1134"><a href="#cb135-1134" aria-hidden="true" tabindex="-1"></a>se_pred <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">summary</span>(mod)<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> m <span class="sc">+</span> se_fit<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-1135"><a href="#cb135-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1136"><a href="#cb135-1136" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate PI for Y-bar_h(new)</span></span>
<span id="cb135-1137"><a href="#cb135-1137" aria-hidden="true" tabindex="-1"></a>(pi_limits <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">lower =</span> pe <span class="sc">-</span> t_crit <span class="sc">*</span> se_pred, <span class="at">upper =</span> pe <span class="sc">+</span> t_crit <span class="sc">*</span> se_pred))</span>
<span id="cb135-1138"><a href="#cb135-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1139"><a href="#cb135-1139" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to (widths) of previous types of intervals</span></span>
<span id="cb135-1140"><a href="#cb135-1140" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; order from most to least precise: CI for E(Y_h), PI for Y-bar_h(new), PI for single Y_h-hat</span></span>
<span id="cb135-1141"><a href="#cb135-1141" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"conf"</span>)</span>
<span id="cb135-1142"><a href="#cb135-1142" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">interval =</span> <span class="st">"pred"</span>)</span>
<span id="cb135-1143"><a href="#cb135-1143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1144"><a href="#cb135-1144" aria-hidden="true" tabindex="-1"></a><span class="co"># interval for sum (total) of m predictions at X_h</span></span>
<span id="cb135-1145"><a href="#cb135-1145" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; depends on context if this is meaningful</span></span>
<span id="cb135-1146"><a href="#cb135-1146" aria-hidden="true" tabindex="-1"></a>pi_limits <span class="sc">*</span> m</span>
<span id="cb135-1147"><a href="#cb135-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1148"><a href="#cb135-1148" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1149"><a href="#cb135-1149" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-1150"><a href="#cb135-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1151"><a href="#cb135-1151" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confidence band for regression line</span></span>
<span id="cb135-1152"><a href="#cb135-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1153"><a href="#cb135-1153" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-1154"><a href="#cb135-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1155"><a href="#cb135-1155" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The goal is to obtain a confidence band for the entire regression line $E(Y) = \beta_0 + \beta_1 X$.</span>
<span id="cb135-1156"><a href="#cb135-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1157"><a href="#cb135-1157" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This band enables us to see the region in which the entire regression line lies and is particularly useful for determining the appropriateness of a fitted regression function.</span>
<span id="cb135-1158"><a href="#cb135-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1159"><a href="#cb135-1159" aria-hidden="true" tabindex="-1"></a>Results</span>
<span id="cb135-1160"><a href="#cb135-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1161"><a href="#cb135-1161" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This confidence band formula below the same form as the CI formula for $E(Y_h)$, the mean response at $X_h$ ($\hat{Y_h} \pm t_{\alpha/2, n-2} \cdot S_{\hat{Y_h}}$), except it uses a different multiplier to adjust for multiple comparisons $\Longrightarrow$ Same point estimate and standard error.</span>
<span id="cb135-1162"><a href="#cb135-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1163"><a href="#cb135-1163" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Some alternative procedures for developing confidence bands have been developed.</span>
<span id="cb135-1164"><a href="#cb135-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1165"><a href="#cb135-1165" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The one shown below is the *Working-Hotelling confidence band* (more will be said about this method later).</span>
<span id="cb135-1166"><a href="#cb135-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1167"><a href="#cb135-1167" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The simplicity of this method is that it is a direct extension of the confidence limits for a single mean response $E(Y_h)$ shown earlier.</span>
<span id="cb135-1168"><a href="#cb135-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1169"><a href="#cb135-1169" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The $100(1 - \alpha)\%$ confidence band for the regression line has boundaries at any level $X_h$:</span>
<span id="cb135-1170"><a href="#cb135-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1171"><a href="#cb135-1171" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1172"><a href="#cb135-1172" aria-hidden="true" tabindex="-1"></a>\hat{Y_h} \pm W \cdot S_{\hat{Y_h}} = \hat{Y_h} \pm W \cdot \sqrt{MSE \bigg<span class="co">[</span><span class="ot">\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum(X_i - \bar{X})^2}\bigg</span><span class="co">]</span>}</span>
<span id="cb135-1173"><a href="#cb135-1173" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1174"><a href="#cb135-1174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1175"><a href="#cb135-1175" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>(Initial steps of deriving CI) → We are finding the two values such that $P(\text{lower} \le \beta_0 + \beta_1 X_h \le \text{upper}) = 1- \alpha$; And $\hat{Y_h}$ is the point estimator for $E(Y_h) = \beta_0 + \beta_1 X_h$.</span>
<span id="cb135-1176"><a href="#cb135-1176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1177"><a href="#cb135-1177" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$W$ multiplier</span>
<span id="cb135-1178"><a href="#cb135-1178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1179"><a href="#cb135-1179" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1180"><a href="#cb135-1180" aria-hidden="true" tabindex="-1"></a>W^2 = 2 \cdot F_{(1-\alpha; \, 2, n-2)}</span>
<span id="cb135-1181"><a href="#cb135-1181" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1182"><a href="#cb135-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1183"><a href="#cb135-1183" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We multiply by two for SLR becuase there are two estimated coefficients.</span>
<span id="cb135-1184"><a href="#cb135-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1185"><a href="#cb135-1185" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The $W$-multiplier is larger than the $t$ multiplier because the confidence band must encompass the entire regression line, whereas the confidence limits for $E(Y_h)$ at $X_h$ apply only at the single level $X_h$.</span>
<span id="cb135-1186"><a href="#cb135-1186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1187"><a href="#cb135-1187" aria-hidden="true" tabindex="-1"></a>Notes</span>
<span id="cb135-1188"><a href="#cb135-1188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1189"><a href="#cb135-1189" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Confidence band confidence level</span>
<span id="cb135-1190"><a href="#cb135-1190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1191"><a href="#cb135-1191" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Interpretation → Indicates the proportion of time that the estimating procedure will yield a band that covers the entire line, in a long series of samples in which the $X$ observations are kept at the same level as in the actual study.</span>
<span id="cb135-1192"><a href="#cb135-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1193"><a href="#cb135-1193" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Technical application → The confidence band applies to the entire regression line over all real-numbered values of $X$ from $-\infty$ to $\infty$.</span>
<span id="cb135-1194"><a href="#cb135-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1195"><a href="#cb135-1195" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Practical application → In practice, the confidence band is ignored for that part of the regression line which is not of interest, so the confidence coefficient for this limited segment is somewhat higher than $1-\alpha$. Thus, $1-\alpha$ serves as a lower bound to the confidence coefficient.</span>
<span id="cb135-1196"><a href="#cb135-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1197"><a href="#cb135-1197" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Things to look for → Can see if the slope is clearly positive or negative, can look at the levels of the regression line at different levels of $X$ to gauge relative precision, etc.</span>
<span id="cb135-1198"><a href="#cb135-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1199"><a href="#cb135-1199" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Precision</span>
<span id="cb135-1200"><a href="#cb135-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1201"><a href="#cb135-1201" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>With the somewhat wider limits for the entire regression line, we are able to draw conclusions about any and all mean responses for the entire regression line and not just about the mean response at a given $X$ level.</span>
<span id="cb135-1202"><a href="#cb135-1202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1203"><a href="#cb135-1203" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Although, generally confidence band lines at any value $X_h$ often are not substantially wider than the confidence limits for the mean response at that single $X_h$ level.</span>
<span id="cb135-1204"><a href="#cb135-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1205"><a href="#cb135-1205" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Just like with the CI for $E(Y_h)$, the boundary points of the confidence band for the regression line are wider apart the further $X_h$ is from the mean $\bar{X}$ of the $X$ observations.</span>
<span id="cb135-1206"><a href="#cb135-1206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1207"><a href="#cb135-1207" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Formula → The lower and upper bounds together actually define a hyperbola.</span>
<span id="cb135-1208"><a href="#cb135-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1209"><a href="#cb135-1209" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb135-1210"><a href="#cb135-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1211"><a href="#cb135-1211" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-1212"><a href="#cb135-1212" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-1213"><a href="#cb135-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1216"><a href="#cb135-1216" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1217"><a href="#cb135-1217" aria-hidden="true" tabindex="-1"></a><span class="co"># using the same model as the confidence interval for E(Y_h) demo</span></span>
<span id="cb135-1218"><a href="#cb135-1218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1219"><a href="#cb135-1219" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate confidence band limits across scope of model</span></span>
<span id="cb135-1220"><a href="#cb135-1220" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; initialize many x_h values covering min to max of original sample</span></span>
<span id="cb135-1221"><a href="#cb135-1221" aria-hidden="true" tabindex="-1"></a>x_h <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fu">min</span>(x), <span class="at">to =</span> <span class="fu">max</span>(x), <span class="at">length =</span> <span class="dv">20</span>))</span>
<span id="cb135-1222"><a href="#cb135-1222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1223"><a href="#cb135-1223" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate confidence bands</span></span>
<span id="cb135-1224"><a href="#cb135-1224" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; type = "w" uses the Working-Hotelling method with the W multiplier</span></span>
<span id="cb135-1225"><a href="#cb135-1225" aria-hidden="true" tabindex="-1"></a>conf_band <span class="ot">&lt;-</span> ALSM<span class="sc">::</span><span class="fu">ci.reg</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">type =</span> <span class="st">"w"</span>, <span class="at">alpha =</span> <span class="fl">0.05</span>)</span>
<span id="cb135-1226"><a href="#cb135-1226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1227"><a href="#cb135-1227" aria-hidden="true" tabindex="-1"></a><span class="co"># display results</span></span>
<span id="cb135-1228"><a href="#cb135-1228" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(conf_band[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,], <span class="at">format =</span> <span class="st">"html"</span>, <span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb135-1229"><a href="#cb135-1229" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>,</span>
<span id="cb135-1230"><a href="#cb135-1230" aria-hidden="true" tabindex="-1"></a>                <span class="at">position =</span> <span class="st">"left"</span>)</span>
<span id="cb135-1231"><a href="#cb135-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1232"><a href="#cb135-1232" aria-hidden="true" tabindex="-1"></a><span class="co"># compare width when estimating a single E(X_h) to the confidence bands</span></span>
<span id="cb135-1233"><a href="#cb135-1233" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(x_h[<span class="dv">1</span>,], <span class="fu">predict</span>(mod, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x_h[<span class="dv">1</span>,]), <span class="at">interval =</span> <span class="st">"conf"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-1234"><a href="#cb135-1234" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_names</span>(<span class="fu">c</span>(<span class="st">"x"</span>, <span class="st">"fit"</span>, <span class="st">"lwr"</span>, <span class="st">"upr"</span>))</span>
<span id="cb135-1235"><a href="#cb135-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1236"><a href="#cb135-1236" aria-hidden="true" tabindex="-1"></a><span class="co"># plot fitted line and confidence bands on scatterplot</span></span>
<span id="cb135-1237"><a href="#cb135-1237" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; also add reference line for X-bar showing where the most precision is</span></span>
<span id="cb135-1238"><a href="#cb135-1238" aria-hidden="true" tabindex="-1"></a>conf_band <span class="sc">%$%</span> </span>
<span id="cb135-1239"><a href="#cb135-1239" aria-hidden="true" tabindex="-1"></a>  <span class="fu">matplot</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">cbind</span>(Fit, Lower.Band, Upper.Band), <span class="at">type =</span>  <span class="st">"l"</span>, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"blue"</span>, <span class="st">"blue"</span>), <span class="at">xlab =</span> <span class="fu">expression</span>(X[h]), <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(Y)[h]), <span class="at">main =</span> <span class="fu">bquote</span>(.(<span class="dv">100</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> alpha)) <span class="sc">*</span> <span class="st">"% Confidence band"</span>))</span>
<span id="cb135-1240"><a href="#cb135-1240" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, y)</span>
<span id="cb135-1241"><a href="#cb135-1241" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">mean</span>(x), <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"lightgrey"</span>)</span>
<span id="cb135-1242"><a href="#cb135-1242" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="fu">mean</span>(x) <span class="sc">+</span> <span class="fl">0.5</span>, <span class="at">y =</span> <span class="fu">min</span>(y) <span class="sc">+</span> <span class="dv">1</span>, <span class="at">labels =</span> <span class="fu">expression</span>(<span class="fu">bar</span>(X)) , <span class="at">col =</span> <span class="st">"darkgrey"</span>)</span>
<span id="cb135-1243"><a href="#cb135-1243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1244"><a href="#cb135-1244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1245"><a href="#cb135-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1246"><a href="#cb135-1246" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-1247"><a href="#cb135-1247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1250"><a href="#cb135-1250" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1251"><a href="#cb135-1251" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate W multiplier = 2 F_crit(regression = of coefficients, residual)</span></span>
<span id="cb135-1252"><a href="#cb135-1252" aria-hidden="true" tabindex="-1"></a><span class="co"># degrees of freedom</span></span>
<span id="cb135-1253"><a href="#cb135-1253" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; numerator -&gt; = df regression (# of coefficients) = 2 for SLR</span></span>
<span id="cb135-1254"><a href="#cb135-1254" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; denominator -&gt; df residual (n - # of coefficients) = n - 2 for SLR</span></span>
<span id="cb135-1255"><a href="#cb135-1255" aria-hidden="true" tabindex="-1"></a><span class="co"># probability -&gt; F is right-tailed, so need to use 1 - alpha now</span></span>
<span id="cb135-1256"><a href="#cb135-1256" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; no dividing by two or taking absolute value</span></span>
<span id="cb135-1257"><a href="#cb135-1257" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb135-1258"><a href="#cb135-1258" aria-hidden="true" tabindex="-1"></a>(W <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">2</span> <span class="sc">*</span> <span class="fu">qf</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, <span class="at">df1 =</span> <span class="fu">length</span>(<span class="fu">coef</span>(mod)), <span class="at">df2 =</span> <span class="fu">df.residual</span>(mod))))</span>
<span id="cb135-1259"><a href="#cb135-1259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1260"><a href="#cb135-1260" aria-hidden="true" tabindex="-1"></a><span class="co"># compare W to t at a specific X_h</span></span>
<span id="cb135-1261"><a href="#cb135-1261" aria-hidden="true" tabindex="-1"></a><span class="fu">abs</span>(<span class="fu">qt</span>(alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> <span class="fu">df.residual</span>(mod)))</span>
<span id="cb135-1262"><a href="#cb135-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1263"><a href="#cb135-1263" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate confidence bands</span></span>
<span id="cb135-1264"><a href="#cb135-1264" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; use seq of x values from before</span></span>
<span id="cb135-1265"><a href="#cb135-1265" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; get the fits and se(estimation) for each new x</span></span>
<span id="cb135-1266"><a href="#cb135-1266" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; calculate lower and upper confidence band limits = Y_h-hat +- W * se(estimation)</span></span>
<span id="cb135-1267"><a href="#cb135-1267" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h))</span>
<span id="cb135-1268"><a href="#cb135-1268" aria-hidden="true" tabindex="-1"></a>se_fit <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>se.fit</span>
<span id="cb135-1269"><a href="#cb135-1269" aria-hidden="true" tabindex="-1"></a>lower <span class="ot">&lt;-</span> fit <span class="sc">-</span> W <span class="sc">*</span> se_fit</span>
<span id="cb135-1270"><a href="#cb135-1270" aria-hidden="true" tabindex="-1"></a>upper <span class="ot">&lt;-</span> fit <span class="sc">+</span> W <span class="sc">*</span> se_fit</span>
<span id="cb135-1271"><a href="#cb135-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1272"><a href="#cb135-1272" aria-hidden="true" tabindex="-1"></a><span class="co"># combine above info</span></span>
<span id="cb135-1273"><a href="#cb135-1273" aria-hidden="true" tabindex="-1"></a>data_conf_band <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x_h =</span> x_h<span class="sc">$</span>x, fit, se_fit, lower, upper, <span class="at">width =</span> upper <span class="sc">-</span> lower) </span>
<span id="cb135-1274"><a href="#cb135-1274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1275"><a href="#cb135-1275" aria-hidden="true" tabindex="-1"></a><span class="co"># illustrate process of confidence bands over X range</span></span>
<span id="cb135-1276"><a href="#cb135-1276" aria-hidden="true" tabindex="-1"></a>data_conf_band <span class="sc">%&gt;%</span> </span>
<span id="cb135-1277"><a href="#cb135-1277" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"X_h"</span>, <span class="st">"fit = Y_h-hat"</span>, <span class="st">"SE(fit) = S_{Y_h-hat}"</span>, <span class="st">"LB = Y_h-hat - W x S_{Y_h-hat}"</span>, <span class="st">"UB = $Y_h-hat + W x S_{Y_h-hat}$"</span>, <span class="st">"Width"</span>),</span>
<span id="cb135-1278"><a href="#cb135-1278" aria-hidden="true" tabindex="-1"></a>        <span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb135-1279"><a href="#cb135-1279" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>,</span>
<span id="cb135-1280"><a href="#cb135-1280" aria-hidden="true" tabindex="-1"></a>                <span class="at">position =</span> <span class="st">"left"</span>)</span>
<span id="cb135-1281"><a href="#cb135-1281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1282"><a href="#cb135-1282" aria-hidden="true" tabindex="-1"></a><span class="co"># compare results to ci.reg(type = "w)</span></span>
<span id="cb135-1283"><a href="#cb135-1283" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">head</span>(ALSM<span class="sc">::</span><span class="fu">ci.reg</span>(mod, <span class="at">newdata =</span> x_h, <span class="at">type =</span> <span class="st">"w"</span>, <span class="at">alpha =</span> <span class="fl">0.05</span>)), <span class="fu">head</span>(data_conf_band[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">5</span>)]))</span>
<span id="cb135-1284"><a href="#cb135-1284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1285"><a href="#cb135-1285" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data_conf_band)</span>
<span id="cb135-1286"><a href="#cb135-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1287"><a href="#cb135-1287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1288"><a href="#cb135-1288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1289"><a href="#cb135-1289" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Other functions</span></span>
<span id="cb135-1290"><a href="#cb135-1290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1293"><a href="#cb135-1293" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1294"><a href="#cb135-1294" aria-hidden="true" tabindex="-1"></a><span class="co"># demo to verify what geom_smooth() gives</span></span>
<span id="cb135-1295"><a href="#cb135-1295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1296"><a href="#cb135-1296" aria-hidden="true" tabindex="-1"></a><span class="co"># results</span></span>
<span id="cb135-1297"><a href="#cb135-1297" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; lm regression lines line up as expected, BUT...</span></span>
<span id="cb135-1298"><a href="#cb135-1298" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; the confidence bands using se = TRUE are actually the lower and upper **pointwise** confidence interval around the mean</span></span>
<span id="cb135-1299"><a href="#cb135-1299" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; ** this means it is plotting ALL of the INDIVIDUAL CIs for E(Y_h), whereas Working-Hotelling confidence bands represent a confidence "interval" for the ENTIRE regression line</span></span>
<span id="cb135-1300"><a href="#cb135-1300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1301"><a href="#cb135-1301" aria-hidden="true" tabindex="-1"></a><span class="co"># create dataframe of original observations the model was built on</span></span>
<span id="cb135-1302"><a href="#cb135-1302" aria-hidden="true" tabindex="-1"></a>data_original <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x, y)</span>
<span id="cb135-1303"><a href="#cb135-1303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1304"><a href="#cb135-1304" aria-hidden="true" tabindex="-1"></a><span class="co"># set t multiplier for making single interval estimates of E(Y_h)</span></span>
<span id="cb135-1305"><a href="#cb135-1305" aria-hidden="true" tabindex="-1"></a>t_crit <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">qt</span>(alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> <span class="fu">df.residual</span>(mod)))</span>
<span id="cb135-1306"><a href="#cb135-1306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1307"><a href="#cb135-1307" aria-hidden="true" tabindex="-1"></a><span class="co"># create confidence band demo plotting dataset</span></span>
<span id="cb135-1308"><a href="#cb135-1308" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; rename current lower and upper to have an indication of W multiplier</span></span>
<span id="cb135-1309"><a href="#cb135-1309" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; calculate new lower and upper bounds based on t multiplier</span></span>
<span id="cb135-1310"><a href="#cb135-1310" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; remove unneeded columns for plot</span></span>
<span id="cb135-1311"><a href="#cb135-1311" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; reshaoe to long with to long with and columns for type of bound and value</span></span>
<span id="cb135-1312"><a href="#cb135-1312" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; create indicator variable for type of multiplier used in calculating the lower and upper bounds (check what suffix is of bound) and then remove multiplier indication from bound column (just take off suffix)</span></span>
<span id="cb135-1313"><a href="#cb135-1313" aria-hidden="true" tabindex="-1"></a>data_conf_band_plot <span class="ot">&lt;-</span> data_conf_band <span class="sc">%&gt;%</span> </span>
<span id="cb135-1314"><a href="#cb135-1314" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">lower_w =</span> lower,</span>
<span id="cb135-1315"><a href="#cb135-1315" aria-hidden="true" tabindex="-1"></a>         <span class="at">upper_w =</span> upper) <span class="sc">%&gt;%</span> </span>
<span id="cb135-1316"><a href="#cb135-1316" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">lower_t =</span> fit <span class="sc">-</span> t_crit <span class="sc">*</span> se_fit,</span>
<span id="cb135-1317"><a href="#cb135-1317" aria-hidden="true" tabindex="-1"></a>         <span class="at">upper_t =</span> fit <span class="sc">+</span> t_crit <span class="sc">*</span> se_fit) <span class="sc">%&gt;%</span> </span>
<span id="cb135-1318"><a href="#cb135-1318" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(width, se_fit)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-1319"><a href="#cb135-1319" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">starts_with</span>(<span class="fu">c</span>(<span class="st">"lower"</span>, <span class="st">"upper"</span>)),</span>
<span id="cb135-1320"><a href="#cb135-1320" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"bound"</span>,</span>
<span id="cb135-1321"><a href="#cb135-1321" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"value"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb135-1322"><a href="#cb135-1322" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">multiplier =</span> </span>
<span id="cb135-1323"><a href="#cb135-1323" aria-hidden="true" tabindex="-1"></a>           <span class="fu">case_when</span>(</span>
<span id="cb135-1324"><a href="#cb135-1324" aria-hidden="true" tabindex="-1"></a>             <span class="fu">str_sub</span>(bound, <span class="at">start =</span> <span class="sc">-</span><span class="dv">1</span>) <span class="sc">==</span> <span class="st">"t"</span> <span class="sc">~</span> <span class="st">"t"</span>,</span>
<span id="cb135-1325"><a href="#cb135-1325" aria-hidden="true" tabindex="-1"></a>             <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">"W"</span>),</span>
<span id="cb135-1326"><a href="#cb135-1326" aria-hidden="true" tabindex="-1"></a>         <span class="at">bound =</span> <span class="fu">str_sub</span>(bound, <span class="at">end =</span> <span class="sc">-</span><span class="dv">3</span>))</span>
<span id="cb135-1327"><a href="#cb135-1327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1328"><a href="#cb135-1328" aria-hidden="true" tabindex="-1"></a><span class="co"># create demo plot</span></span>
<span id="cb135-1329"><a href="#cb135-1329" aria-hidden="true" tabindex="-1"></a><span class="co"># layer:  geom_smooth()</span></span>
<span id="cb135-1330"><a href="#cb135-1330" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; this adds regression line</span></span>
<span id="cb135-1331"><a href="#cb135-1331" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; se + TRUE adds the shaded ribbon representing "confidence bands"</span></span>
<span id="cb135-1332"><a href="#cb135-1332" aria-hidden="true" tabindex="-1"></a><span class="co"># layer: geom_line() first one</span></span>
<span id="cb135-1333"><a href="#cb135-1333" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; add manually calculated regression line, should line up exactly with above</span></span>
<span id="cb135-1334"><a href="#cb135-1334" aria-hidden="true" tabindex="-1"></a><span class="co"># layer: geom_line() second and third ones</span></span>
<span id="cb135-1335"><a href="#cb135-1335" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; confidence bands for both multipliers</span></span>
<span id="cb135-1336"><a href="#cb135-1336" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb135-1337"><a href="#cb135-1337" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">x =</span> x,</span>
<span id="cb135-1338"><a href="#cb135-1338" aria-hidden="true" tabindex="-1"></a>                  <span class="at">y =</span> y),</span>
<span id="cb135-1339"><a href="#cb135-1339" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> data_original,</span>
<span id="cb135-1340"><a href="#cb135-1340" aria-hidden="true" tabindex="-1"></a>              <span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb135-1341"><a href="#cb135-1341" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> x,</span>
<span id="cb135-1342"><a href="#cb135-1342" aria-hidden="true" tabindex="-1"></a>              <span class="at">level =</span> <span class="dv">1</span> <span class="sc">-</span> alpha,</span>
<span id="cb135-1343"><a href="#cb135-1343" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">TRUE</span>,</span>
<span id="cb135-1344"><a href="#cb135-1344" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">"yellow"</span>,</span>
<span id="cb135-1345"><a href="#cb135-1345" aria-hidden="true" tabindex="-1"></a>              <span class="at">linewidth =</span> <span class="dv">1</span>,</span>
<span id="cb135-1346"><a href="#cb135-1346" aria-hidden="true" tabindex="-1"></a>              <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> </span>
<span id="cb135-1347"><a href="#cb135-1347" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x_h,</span>
<span id="cb135-1348"><a href="#cb135-1348" aria-hidden="true" tabindex="-1"></a>                <span class="at">y =</span> fit),</span>
<span id="cb135-1349"><a href="#cb135-1349" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> data_conf_band_plot,</span>
<span id="cb135-1350"><a href="#cb135-1350" aria-hidden="true" tabindex="-1"></a>            <span class="at">color =</span> <span class="st">"red"</span>,</span>
<span id="cb135-1351"><a href="#cb135-1351" aria-hidden="true" tabindex="-1"></a>            <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span> </span>
<span id="cb135-1352"><a href="#cb135-1352" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x_h,</span>
<span id="cb135-1353"><a href="#cb135-1353" aria-hidden="true" tabindex="-1"></a>                <span class="at">y =</span> value,</span>
<span id="cb135-1354"><a href="#cb135-1354" aria-hidden="true" tabindex="-1"></a>                <span class="at">color =</span> multiplier),</span>
<span id="cb135-1355"><a href="#cb135-1355" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> <span class="fu">filter</span>(data_conf_band_plot, bound <span class="sc">==</span> <span class="st">"lower"</span>),</span>
<span id="cb135-1356"><a href="#cb135-1356" aria-hidden="true" tabindex="-1"></a>            <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb135-1357"><a href="#cb135-1357" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x_h,</span>
<span id="cb135-1358"><a href="#cb135-1358" aria-hidden="true" tabindex="-1"></a>                <span class="at">y =</span> value,</span>
<span id="cb135-1359"><a href="#cb135-1359" aria-hidden="true" tabindex="-1"></a>                <span class="at">color =</span> multiplier),</span>
<span id="cb135-1360"><a href="#cb135-1360" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> <span class="fu">filter</span>(data_conf_band_plot, bound <span class="sc">==</span> <span class="st">"upper"</span>),</span>
<span id="cb135-1361"><a href="#cb135-1361" aria-hidden="true" tabindex="-1"></a>            <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb135-1362"><a href="#cb135-1362" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">"Multiplier"</span>, <span class="at">values =</span> <span class="fu">c</span>(<span class="at">t =</span> <span class="st">"purple"</span>, <span class="at">W =</span> <span class="st">"blue"</span>)) <span class="sc">+</span> </span>
<span id="cb135-1363"><a href="#cb135-1363" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Demo of confidence bands"</span>,</span>
<span id="cb135-1364"><a href="#cb135-1364" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(X[h]),</span>
<span id="cb135-1365"><a href="#cb135-1365" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(Y)[h]))</span>
<span id="cb135-1366"><a href="#cb135-1366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1367"><a href="#cb135-1367" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1368"><a href="#cb135-1368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1369"><a href="#cb135-1369" aria-hidden="true" tabindex="-1"></a>Where the multipliers are $t_{\alpha / 2, n - p}$ and $W = 2 \cdot F_{1 - \alpha; p, n - p}$.</span>
<span id="cb135-1370"><a href="#cb135-1370" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-1371"><a href="#cb135-1371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1372"><a href="#cb135-1372" aria-hidden="true" tabindex="-1"></a><span class="fu">## Analysis of variance approach to regression</span></span>
<span id="cb135-1373"><a href="#cb135-1373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1374"><a href="#cb135-1374" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This approach is very useful for multiple linear regression and other types of linear statistical models.</span>
<span id="cb135-1375"><a href="#cb135-1375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1376"><a href="#cb135-1376" aria-hidden="true" tabindex="-1"></a><span class="fu">### Partitioning of total sum of squares</span></span>
<span id="cb135-1377"><a href="#cb135-1377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1378"><a href="#cb135-1378" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-1379"><a href="#cb135-1379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1380"><a href="#cb135-1380" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In a regression setting, analysis of variance (ANOVA) allows us to capture the different sources of variability in the model.</span>
<span id="cb135-1381"><a href="#cb135-1381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1382"><a href="#cb135-1382" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We do this by partitioning the sums of squares and degrees of freedom associated with the the response variable $Y$.</span>
<span id="cb135-1383"><a href="#cb135-1383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1384"><a href="#cb135-1384" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/ss-breakdown.png)</span>{width="100%"}</span>
<span id="cb135-1385"><a href="#cb135-1385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1386"><a href="#cb135-1386" aria-hidden="true" tabindex="-1"></a>Types of sum of squares</span>
<span id="cb135-1387"><a href="#cb135-1387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1388"><a href="#cb135-1388" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Total sum of squares → Measured in terms of the deviations of the $Y_i$ around their mean $\bar{Y}$.</span>
<span id="cb135-1389"><a href="#cb135-1389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1390"><a href="#cb135-1390" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1391"><a href="#cb135-1391" aria-hidden="true" tabindex="-1"></a>SSTO = \sum (Y_i - \bar{Y})^2 = S_{YY}</span>
<span id="cb135-1392"><a href="#cb135-1392" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1393"><a href="#cb135-1393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1394"><a href="#cb135-1394" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Measures the total variation of $Y$, which tells us the uncertainty related to $Y$ when the predictor variable $X$ is *not* taken into account.</span>
<span id="cb135-1395"><a href="#cb135-1395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1396"><a href="#cb135-1396" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If all observations are the same, then $SSTO = 0$. More variation in $Y_i$, the larger $SSTO$ is.</span>
<span id="cb135-1397"><a href="#cb135-1397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1398"><a href="#cb135-1398" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Sum of squares error → Measured in terms of the deviations of the $Y_i$ around the fitted regression line $\hat{Y_i}$ (i.e. the residuals $e_i$).</span>
<span id="cb135-1399"><a href="#cb135-1399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1400"><a href="#cb135-1400" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1401"><a href="#cb135-1401" aria-hidden="true" tabindex="-1"></a>SSE = \sum (Y_i - \hat{Y_i})^2</span>
<span id="cb135-1402"><a href="#cb135-1402" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1403"><a href="#cb135-1403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1404"><a href="#cb135-1404" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Measures the remaining variation / uncertainty in the $Y_i$'s after we utilize the predictor variable $X$ (i.e. "unexplained" variation).</span>
<span id="cb135-1405"><a href="#cb135-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1406"><a href="#cb135-1406" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If all observations fall on the fitted line, $SSE = 0$. More variation in $Y$ around the fitted line, the larger $SSE$ is.</span>
<span id="cb135-1407"><a href="#cb135-1407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1408"><a href="#cb135-1408" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Sum of squares regression → Measured in terms of the deviations of the fitted $\hat{Y_i}$ around their mean $\bar{Y}$.</span>
<span id="cb135-1409"><a href="#cb135-1409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1410"><a href="#cb135-1410" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1411"><a href="#cb135-1411" aria-hidden="true" tabindex="-1"></a>SSR = \sum (\hat{Y_i} - \bar{Y})^2</span>
<span id="cb135-1412"><a href="#cb135-1412" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1413"><a href="#cb135-1413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1414"><a href="#cb135-1414" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Measures the variation in the $Y_i$'s that is associated with the regression line.</span>
<span id="cb135-1415"><a href="#cb135-1415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1416"><a href="#cb135-1416" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In other words, it measures the variation in the $Y_i$'s that is accounted for by the relationship between $Y$ and $X$ (i.e. "explained" variation). We are essentially upgrading our original prediction for $Y$ from $\bar{Y}$ to now $\hat{Y}$; so this $\approx$ (conceptually) measures how much better the predictions become.</span>
<span id="cb135-1417"><a href="#cb135-1417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1418"><a href="#cb135-1418" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>So, the larger $SSR$ is in relation to $SSTO$, the greater is the effect of the regression relation in accounting for the total variation in the $Y_i$ observations.</span>
<span id="cb135-1419"><a href="#cb135-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1420"><a href="#cb135-1420" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-1421"><a href="#cb135-1421" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb135-1422"><a href="#cb135-1422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1423"><a href="#cb135-1423" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Partitioning individual deviations</span>
<span id="cb135-1424"><a href="#cb135-1424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1425"><a href="#cb135-1425" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/partitioning-deviations.png)</span>{width="30%"}</span>
<span id="cb135-1426"><a href="#cb135-1426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1427"><a href="#cb135-1427" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The two components are:</span>
<span id="cb135-1428"><a href="#cb135-1428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1429"><a href="#cb135-1429" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>The deviation of the fitted value $\hat{Y_i}$ around the mean $\bar{Y}$.</span>
<span id="cb135-1430"><a href="#cb135-1430" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>The deviation of the observation $Y_i$ around the fitted regression line.</span>
<span id="cb135-1431"><a href="#cb135-1431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1432"><a href="#cb135-1432" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This relationship holds for the sum of the squared deviations as well:</span>
<span id="cb135-1433"><a href="#cb135-1433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1434"><a href="#cb135-1434" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1435"><a href="#cb135-1435" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1436"><a href="#cb135-1436" aria-hidden="true" tabindex="-1"></a>  \sum (Y_i - \bar{Y})^2 &amp;= \sum (\hat{Y_i} - \bar{Y})^2 + \sum (Y_i - \hat{Y_i})^2<span class="sc">\\</span></span>
<span id="cb135-1437"><a href="#cb135-1437" aria-hidden="true" tabindex="-1"></a>  SSTO &amp;= SSR + SSE</span>
<span id="cb135-1438"><a href="#cb135-1438" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1439"><a href="#cb135-1439" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1440"><a href="#cb135-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1441"><a href="#cb135-1441" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb135-1442"><a href="#cb135-1442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1443"><a href="#cb135-1443" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Partitioning total sum of squares</span>
<span id="cb135-1444"><a href="#cb135-1444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1445"><a href="#cb135-1445" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/partition-ss-proof.png)</span>{width="50%"}</span>
<span id="cb135-1446"><a href="#cb135-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1447"><a href="#cb135-1447" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The formulas for $SSTO$, $SSE$ and $SSR$ above are best for computations. But an alternate form of $SSR$ is useful for deriving analytical results is shown below:</span>
<span id="cb135-1448"><a href="#cb135-1448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1449"><a href="#cb135-1449" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1450"><a href="#cb135-1450" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1451"><a href="#cb135-1451" aria-hidden="true" tabindex="-1"></a>  SSR &amp;= \sum <span class="co">[</span><span class="ot">\hat{Y_i} - \bar{Y}</span><span class="co">]</span>^2 <span class="sc">\\</span></span>
<span id="cb135-1452"><a href="#cb135-1452" aria-hidden="true" tabindex="-1"></a>      &amp;= \sum <span class="co">[</span><span class="ot">(\hat{\beta}_0 + \hat{\beta}_1 X_i) - \bar{Y}</span><span class="co">]</span>^2 <span class="sc">\\</span></span>
<span id="cb135-1453"><a href="#cb135-1453" aria-hidden="true" tabindex="-1"></a>      &amp;= \sum <span class="co">[</span><span class="ot">(\bar{Y} - \hat{\beta}_1 \bar{X}) + \hat{\beta}_1 X_i - \bar{Y}</span><span class="co">]</span>^2 <span class="sc">\\</span></span>
<span id="cb135-1454"><a href="#cb135-1454" aria-hidden="true" tabindex="-1"></a>      &amp;= \hat{\beta}_1^2 \sum <span class="co">[</span><span class="ot">X_i - \bar{X}</span><span class="co">]</span>^2</span>
<span id="cb135-1455"><a href="#cb135-1455" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1456"><a href="#cb135-1456" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1457"><a href="#cb135-1457" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-1458"><a href="#cb135-1458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1459"><a href="#cb135-1459" aria-hidden="true" tabindex="-1"></a><span class="fu">### Breakdown of degrees of freedom</span></span>
<span id="cb135-1460"><a href="#cb135-1460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1461"><a href="#cb135-1461" aria-hidden="true" tabindex="-1"></a>Degrees of freedom for each sum of square</span>
<span id="cb135-1462"><a href="#cb135-1462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1463"><a href="#cb135-1463" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$SSTO$ → Has $n-1$ degrees of freedom associated with it.</span>
<span id="cb135-1464"><a href="#cb135-1464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1465"><a href="#cb135-1465" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>One degree of freedom is lost because the deviations $Y_i - \bar{Y}$ are subject to one constraint: they must sum to zero ($\sum (Y_i - \bar{Y}) = 0$).</span>
<span id="cb135-1466"><a href="#cb135-1466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1467"><a href="#cb135-1467" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Equivalently, one degree of freedom is lost because the sample mean $\bar{Y}$ is used to estimate the population mean.</span>
<span id="cb135-1468"><a href="#cb135-1468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1469"><a href="#cb135-1469" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$SSE$ → Has $n-2$ degrees of freedom associated with it.</span>
<span id="cb135-1470"><a href="#cb135-1470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1471"><a href="#cb135-1471" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Two degrees of freedom are lost because the two parameters $\beta_0$ and $\beta_1$ are estimated in obtaining the fitted values $\hat{Y_i}$.</span>
<span id="cb135-1472"><a href="#cb135-1472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1473"><a href="#cb135-1473" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$SSR$ → Has 1 degrees of freedom associated with it.</span>
<span id="cb135-1474"><a href="#cb135-1474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1475"><a href="#cb135-1475" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Although there are $n$ deviations $\hat{Y_i} - \bar{Y}$, all fitted values are calculated from the same estimated regression line. So the regression line just has two degrees of freedom (corresponding to the slope and intercept, for SLR $p = 2$)...</span>
<span id="cb135-1476"><a href="#cb135-1476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1477"><a href="#cb135-1477" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>BUT then, one degree of freedom is lost because again we have to estimate the mean in order to calculate $\sum (\hat{Y_i} - \bar{Y})^2$, thus $p - 1$ $\Longleftrightarrow$ the deviations $\hat{Y_i} - \bar{Y}$ are subject to one constraint: they must sum to zero.</span>
<span id="cb135-1478"><a href="#cb135-1478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1479"><a href="#cb135-1479" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>(Note: The constraints on the deviations come from the properties of the fitted LSE line.)</span>
<span id="cb135-1480"><a href="#cb135-1480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1481"><a href="#cb135-1481" aria-hidden="true" tabindex="-1"></a>Property of degrees of freedom</span>
<span id="cb135-1482"><a href="#cb135-1482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1483"><a href="#cb135-1483" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Dfs are additive</span>
<span id="cb135-1484"><a href="#cb135-1484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1485"><a href="#cb135-1485" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1486"><a href="#cb135-1486" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1487"><a href="#cb135-1487" aria-hidden="true" tabindex="-1"></a>  n - 1 &amp;= 1 + (n-2) <span class="sc">\\</span></span>
<span id="cb135-1488"><a href="#cb135-1488" aria-hidden="true" tabindex="-1"></a>  df_{TO} &amp;= df_{R} +df_{E}</span>
<span id="cb135-1489"><a href="#cb135-1489" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1490"><a href="#cb135-1490" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1491"><a href="#cb135-1491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1492"><a href="#cb135-1492" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mean squares</span></span>
<span id="cb135-1493"><a href="#cb135-1493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1494"><a href="#cb135-1494" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>General definition → A sum of squares divided by its associated degrees of freedom is called a mean square ($MS$).</span>
<span id="cb135-1495"><a href="#cb135-1495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1496"><a href="#cb135-1496" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Two mean squares</span>
<span id="cb135-1497"><a href="#cb135-1497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1498"><a href="#cb135-1498" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Mean square regression:</span>
<span id="cb135-1499"><a href="#cb135-1499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1500"><a href="#cb135-1500" aria-hidden="true" tabindex="-1"></a>    $$MSR = \frac{SSR}{df_R} = \frac{SSR}{1}$$</span>
<span id="cb135-1501"><a href="#cb135-1501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1502"><a href="#cb135-1502" aria-hidden="true" tabindex="-1"></a><span class="in">    -   Mean square error:</span></span>
<span id="cb135-1503"><a href="#cb135-1503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1504"><a href="#cb135-1504" aria-hidden="true" tabindex="-1"></a><span class="in">    $$MSE = \frac{SSR}{df_E} = \frac{SSE}{n-2}$$</span></span>
<span id="cb135-1505"><a href="#cb135-1505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1506"><a href="#cb135-1506" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note → Mean squares are not additive $\Longrightarrow$ $MSR + MSE \ne MSTO$</span>
<span id="cb135-1507"><a href="#cb135-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1508"><a href="#cb135-1508" aria-hidden="true" tabindex="-1"></a><span class="fu">### ANOVA table</span></span>
<span id="cb135-1509"><a href="#cb135-1509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1510"><a href="#cb135-1510" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The breakdowns of the total sum of squares and associated degrees of freedom are displayed in the form of an analysis of variance table.</span>
<span id="cb135-1511"><a href="#cb135-1511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1512"><a href="#cb135-1512" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Below shows an extra column for expected mean squares, which will be needed for inference (usual ANOVA tables have everything except this column).</span>
<span id="cb135-1513"><a href="#cb135-1513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1514"><a href="#cb135-1514" aria-hidden="true" tabindex="-1"></a>| Source of Variation | $df$             | $SS$                                   | $MS$                    | $E(MS)$                                     | $F$               | $p$-value                 |</span>
<span id="cb135-1515"><a href="#cb135-1515" aria-hidden="true" tabindex="-1"></a>|:----------|:----------|:----------|:----------|:----------|:----------|-----------|</span>
<span id="cb135-1516"><a href="#cb135-1516" aria-hidden="true" tabindex="-1"></a>| Regression          | $df_R = 1$       | $SSR = \sum (\hat{Y_i} - \bar{Y})^2$ 1 | $MSR = \frac{SSR}{1}$   | $\sigma^2 + \beta_1 \sum (X_i - \bar{X})^2$ | $\frac{MSR}{MSE}$ | $P(F_{(df_R, df_E)} &gt; F)$ |</span>
<span id="cb135-1517"><a href="#cb135-1517" aria-hidden="true" tabindex="-1"></a>| Error               | $df_E = n - 2$   | $SSE = \sum (Y_i - \hat{Y_i})^2$       | $MSE = \frac{SSE}{n-2}$ | $\sigma^2$                                  |                   |                           |</span>
<span id="cb135-1518"><a href="#cb135-1518" aria-hidden="true" tabindex="-1"></a>| Total               | $df_{TO} = n -1$ | $SSTO = \sum (Y_i - \bar{Y})^2$        |                         |                                             |                   |                           |</span>
<span id="cb135-1519"><a href="#cb135-1519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1520"><a href="#cb135-1520" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Could convert $SSTO = S_{YY}$ to a mean square as well by dividing by $df_{TO} = n - 1$ → This gives us $\frac{1}{n - 1}{\sum (Y_i - \bar{Y})^2}$ = Sample variance of $Y_i$ (totally unrelated to the regression line; just the variance of a set of numbers, which is technically a mean square).</span>
<span id="cb135-1521"><a href="#cb135-1521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1522"><a href="#cb135-1522" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This is different than the regression $S^2 = MSE$ which is an estimate of the error variance which is found by taking the deviations relative to the fitted line (not $bar{Y}$).</span>
<span id="cb135-1523"><a href="#cb135-1523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1524"><a href="#cb135-1524" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb135-1525"><a href="#cb135-1525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1526"><a href="#cb135-1526" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-1527"><a href="#cb135-1527" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-1528"><a href="#cb135-1528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1531"><a href="#cb135-1531" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1532"><a href="#cb135-1532" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb135-1533"><a href="#cb135-1533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1534"><a href="#cb135-1534" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items</span></span>
<span id="cb135-1535"><a href="#cb135-1535" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span id="cb135-1536"><a href="#cb135-1536" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>; beta_0 <span class="ot">&lt;-</span> <span class="dv">2</span>; beta_1 <span class="ot">&lt;-</span> <span class="dv">3</span>; sigma <span class="ot">&lt;-</span> <span class="dv">15</span> </span>
<span id="cb135-1537"><a href="#cb135-1537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1538"><a href="#cb135-1538" aria-hidden="true" tabindex="-1"></a><span class="co"># generate data</span></span>
<span id="cb135-1539"><a href="#cb135-1539" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">15</span>)</span>
<span id="cb135-1540"><a href="#cb135-1540" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x, <span class="at">sd =</span> sigma)</span>
<span id="cb135-1541"><a href="#cb135-1541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1542"><a href="#cb135-1542" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1543"><a href="#cb135-1543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1546"><a href="#cb135-1546" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1547"><a href="#cb135-1547" aria-hidden="true" tabindex="-1"></a><span class="co"># now introducing another function to fit models and the different results / outputs from each</span></span>
<span id="cb135-1548"><a href="#cb135-1548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1549"><a href="#cb135-1549" aria-hidden="true" tabindex="-1"></a><span class="co"># fit equivalent models</span></span>
<span id="cb135-1550"><a href="#cb135-1550" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; lm() fits linear models</span></span>
<span id="cb135-1551"><a href="#cb135-1551" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; also one-way anova (ancova) models, but aov() works better with anova analyses</span></span>
<span id="cb135-1552"><a href="#cb135-1552" aria-hidden="true" tabindex="-1"></a>mod_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb135-1553"><a href="#cb135-1553" aria-hidden="true" tabindex="-1"></a>mod_aov <span class="ot">&lt;-</span> <span class="fu">aov</span>(y <span class="sc">~</span> x)</span>
<span id="cb135-1554"><a href="#cb135-1554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1555"><a href="#cb135-1555" aria-hidden="true" tabindex="-1"></a><span class="co"># the main difference between lm() and aov() is mainly in the form of the output</span></span>
<span id="cb135-1556"><a href="#cb135-1556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1557"><a href="#cb135-1557" aria-hidden="true" tabindex="-1"></a><span class="co"># calling (printing) the model object</span></span>
<span id="cb135-1558"><a href="#cb135-1558" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; for lm object gives estimated coefficients</span></span>
<span id="cb135-1559"><a href="#cb135-1559" aria-hidden="true" tabindex="-1"></a>mod_lm</span>
<span id="cb135-1560"><a href="#cb135-1560" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; for aov object it gives breakdown of SS and df for each variable and sigma estimate</span></span>
<span id="cb135-1561"><a href="#cb135-1561" aria-hidden="true" tabindex="-1"></a>mod_aov</span>
<span id="cb135-1562"><a href="#cb135-1562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1563"><a href="#cb135-1563" aria-hidden="true" tabindex="-1"></a><span class="co"># summary() function</span></span>
<span id="cb135-1564"><a href="#cb135-1564" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; for lm it gives regression-style output, i.e. regression coefficients with standard errors and t-tests</span></span>
<span id="cb135-1565"><a href="#cb135-1565" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lm)</span>
<span id="cb135-1566"><a href="#cb135-1566" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; for aov it gives anova table,which is the same information but represented as sums of squares estimates with F ratios</span></span>
<span id="cb135-1567"><a href="#cb135-1567" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_aov)</span>
<span id="cb135-1568"><a href="#cb135-1568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1569"><a href="#cb135-1569" aria-hidden="true" tabindex="-1"></a><span class="co"># can switch between the two summaries by calling a summary method</span></span>
<span id="cb135-1570"><a href="#cb135-1570" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; get anova table from lm object</span></span>
<span id="cb135-1571"><a href="#cb135-1571" aria-hidden="true" tabindex="-1"></a><span class="fu">summary.aov</span>(mod_lm)</span>
<span id="cb135-1572"><a href="#cb135-1572" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; get regression-style output from aov object</span></span>
<span id="cb135-1573"><a href="#cb135-1573" aria-hidden="true" tabindex="-1"></a><span class="fu">summary.lm</span>(mod_aov)</span>
<span id="cb135-1574"><a href="#cb135-1574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1575"><a href="#cb135-1575" aria-hidden="true" tabindex="-1"></a><span class="co"># alternative (more straight-forward) way to get anova table </span></span>
<span id="cb135-1576"><a href="#cb135-1576" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; use anova() on lm object &lt;==&gt; anova.lm() -&gt; this is one of the two main uses of this function</span></span>
<span id="cb135-1577"><a href="#cb135-1577" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; looking for Df, Sum Sq, and Mean Sq</span></span>
<span id="cb135-1578"><a href="#cb135-1578" aria-hidden="true" tabindex="-1"></a><span class="co"># --&gt; gives sequential SS (will look into more later)</span></span>
<span id="cb135-1579"><a href="#cb135-1579" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_lm) <span class="sc">%&gt;%</span> as.matrix <span class="co"># could do anova(mod_aov), but makes for sense just to do summary() if already have aov object</span></span>
<span id="cb135-1580"><a href="#cb135-1580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1581"><a href="#cb135-1581" aria-hidden="true" tabindex="-1"></a><span class="co"># save usual lm model as another object to simplify notation</span></span>
<span id="cb135-1582"><a href="#cb135-1582" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> mod_lm</span>
<span id="cb135-1583"><a href="#cb135-1583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1584"><a href="#cb135-1584" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1585"><a href="#cb135-1585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1586"><a href="#cb135-1586" aria-hidden="true" tabindex="-1"></a><span class="in">```{r question}</span></span>
<span id="cb135-1587"><a href="#cb135-1587" aria-hidden="true" tabindex="-1"></a><span class="in">#| eval = FALSE,</span></span>
<span id="cb135-1588"><a href="#cb135-1588" aria-hidden="true" tabindex="-1"></a><span class="in">#| echo = FALSE</span></span>
<span id="cb135-1589"><a href="#cb135-1589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1590"><a href="#cb135-1590" aria-hidden="true" tabindex="-1"></a><span class="in"># NOT SURE WHAT IS HAPPENING HERE ?????</span></span>
<span id="cb135-1591"><a href="#cb135-1591" aria-hidden="true" tabindex="-1"></a><span class="in"># this by default just shows rows for x variables</span></span>
<span id="cb135-1592"><a href="#cb135-1592" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; for SLR, SSR = SS for x shown here</span></span>
<span id="cb135-1593"><a href="#cb135-1593" aria-hidden="true" tabindex="-1"></a><span class="in">summary.aov(mod_lm)</span></span>
<span id="cb135-1594"><a href="#cb135-1594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1595"><a href="#cb135-1595" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; can also show the intercept row as well, by default just does a row for each X and then residuals (error)</span></span>
<span id="cb135-1596"><a href="#cb135-1596" aria-hidden="true" tabindex="-1"></a><span class="in">summary.aov(mod_lm, intercept = TRUE)</span></span>
<span id="cb135-1597"><a href="#cb135-1597" aria-hidden="true" tabindex="-1"></a><span class="in"># not sure where this SS comes from, because it's wayy more than SSTO</span></span>
<span id="cb135-1598"><a href="#cb135-1598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1599"><a href="#cb135-1599" aria-hidden="true" tabindex="-1"></a><span class="in"># and the intercept SS stays the same if fit model without X</span></span>
<span id="cb135-1600"><a href="#cb135-1600" aria-hidden="true" tabindex="-1"></a><span class="in">summary.aov(lm(y ~ 1), intercept = TRUE)</span></span>
<span id="cb135-1601"><a href="#cb135-1601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1602"><a href="#cb135-1602" aria-hidden="true" tabindex="-1"></a><span class="in"># and not sure why (although I think this may come up later?)</span></span>
<span id="cb135-1603"><a href="#cb135-1603" aria-hidden="true" tabindex="-1"></a><span class="in"># -&gt; SS for x is the same regardless if intercept is in model</span></span>
<span id="cb135-1604"><a href="#cb135-1604" aria-hidden="true" tabindex="-1"></a><span class="in">summary.aov(lm(y ~ x -1))</span></span>
<span id="cb135-1605"><a href="#cb135-1605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1606"><a href="#cb135-1606" aria-hidden="true" tabindex="-1"></a><span class="in"># ALSO, how does an intercept-only model have any DF for MS?? 1 - 1 = 0??</span></span>
<span id="cb135-1607"><a href="#cb135-1607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1608"><a href="#cb135-1608" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1609"><a href="#cb135-1609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1610"><a href="#cb135-1610" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-1611"><a href="#cb135-1611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1614"><a href="#cb135-1614" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1615"><a href="#cb135-1615" aria-hidden="true" tabindex="-1"></a><span class="co"># recreating each value in the anova table output</span></span>
<span id="cb135-1616"><a href="#cb135-1616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1617"><a href="#cb135-1617" aria-hidden="true" tabindex="-1"></a><span class="co"># degrees of freedom </span></span>
<span id="cb135-1618"><a href="#cb135-1618" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; regression: each individual coefficient gets 1 df, then lose 1; so for SLR df = 2 - 1 = 1</span></span>
<span id="cb135-1619"><a href="#cb135-1619" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; error: df = n - # of predictors (p) as usual</span></span>
<span id="cb135-1620"><a href="#cb135-1620" aria-hidden="true" tabindex="-1"></a>df_e <span class="ot">&lt;-</span> mod<span class="sc">$</span>df.residual</span>
<span id="cb135-1621"><a href="#cb135-1621" aria-hidden="true" tabindex="-1"></a>df_r <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">coef</span>(mod)) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb135-1622"><a href="#cb135-1622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1623"><a href="#cb135-1623" aria-hidden="true" tabindex="-1"></a><span class="co"># sums of squares</span></span>
<span id="cb135-1624"><a href="#cb135-1624" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; SSR = explained error (improved prediction) -&gt; Y-hat - Y-bar</span></span>
<span id="cb135-1625"><a href="#cb135-1625" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; SSE = still unexplained error (residuals) -&gt; Y - Y-hat</span></span>
<span id="cb135-1626"><a href="#cb135-1626" aria-hidden="true" tabindex="-1"></a>ssr <span class="ot">&lt;-</span> <span class="fu">sum</span>((<span class="fu">fitted</span>(mod) <span class="sc">-</span> <span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-1627"><a href="#cb135-1627" aria-hidden="true" tabindex="-1"></a>sse <span class="ot">&lt;-</span> <span class="fu">sum</span>((y <span class="sc">-</span> <span class="fu">fitted</span>(mod))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-1628"><a href="#cb135-1628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1629"><a href="#cb135-1629" aria-hidden="true" tabindex="-1"></a><span class="co"># mean squares = respective SS / df</span></span>
<span id="cb135-1630"><a href="#cb135-1630" aria-hidden="true" tabindex="-1"></a>msr <span class="ot">&lt;-</span> ssr <span class="sc">/</span> df_r</span>
<span id="cb135-1631"><a href="#cb135-1631" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> sse <span class="sc">/</span> df_e</span>
<span id="cb135-1632"><a href="#cb135-1632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1633"><a href="#cb135-1633" aria-hidden="true" tabindex="-1"></a><span class="co"># combine (organize) into anova table layout for comparison</span></span>
<span id="cb135-1634"><a href="#cb135-1634" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; fill matrix by column</span></span>
<span id="cb135-1635"><a href="#cb135-1635" aria-hidden="true" tabindex="-1"></a>at <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">data =</span> <span class="fu">c</span>(<span class="fu">c</span>(df_r, df_e), <span class="fu">c</span>(ssr, sse), <span class="fu">c</span>(msr, mse)), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">FALSE</span>)</span>
<span id="cb135-1636"><a href="#cb135-1636" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(at) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"df"</span>, <span class="st">"SS"</span>, <span class="st">"MS"</span>)</span>
<span id="cb135-1637"><a href="#cb135-1637" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(at) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"x"</span>, <span class="st">"error"</span>)</span>
<span id="cb135-1638"><a href="#cb135-1638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1639"><a href="#cb135-1639" aria-hidden="true" tabindex="-1"></a><span class="co"># compare results to relevant pieces of anova(lm())</span></span>
<span id="cb135-1640"><a href="#cb135-1640" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">anova</span>(mod_lm)[,<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>], at)</span>
<span id="cb135-1641"><a href="#cb135-1641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1642"><a href="#cb135-1642" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1643"><a href="#cb135-1643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1644"><a href="#cb135-1644" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Properties</span></span>
<span id="cb135-1645"><a href="#cb135-1645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1648"><a href="#cb135-1648" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1649"><a href="#cb135-1649" aria-hidden="true" tabindex="-1"></a><span class="co"># demonstrate additive df and SS</span></span>
<span id="cb135-1650"><a href="#cb135-1650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1651"><a href="#cb135-1651" aria-hidden="true" tabindex="-1"></a><span class="co"># df total = n - 1 (have to estimate pop mean, so lose 1)</span></span>
<span id="cb135-1652"><a href="#cb135-1652" aria-hidden="true" tabindex="-1"></a>df_to <span class="ot">&lt;-</span> <span class="fu">length</span>(y) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb135-1653"><a href="#cb135-1653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1654"><a href="#cb135-1654" aria-hidden="true" tabindex="-1"></a><span class="co"># SSTO = total deviation (S_YY) -&gt; Y - Y-bar</span></span>
<span id="cb135-1655"><a href="#cb135-1655" aria-hidden="true" tabindex="-1"></a>ssto <span class="ot">&lt;-</span> <span class="fu">sum</span>((y <span class="sc">-</span> <span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-1656"><a href="#cb135-1656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1657"><a href="#cb135-1657" aria-hidden="true" tabindex="-1"></a><span class="co"># compare pieces from anova to calculated totals</span></span>
<span id="cb135-1658"><a href="#cb135-1658" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">c</span>(<span class="fu">sum</span>(<span class="fu">anova</span>(mod)[, <span class="st">"Df"</span>]), <span class="fu">sum</span>(<span class="fu">anova</span>(mod)[, <span class="st">"Sum Sq"</span>])), <span class="fu">c</span>(df_to, ssto))</span>
<span id="cb135-1659"><a href="#cb135-1659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1660"><a href="#cb135-1660" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1661"><a href="#cb135-1661" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-1662"><a href="#cb135-1662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1663"><a href="#cb135-1663" aria-hidden="true" tabindex="-1"></a><span class="fu">### Expected mean squares</span></span>
<span id="cb135-1664"><a href="#cb135-1664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1665"><a href="#cb135-1665" aria-hidden="true" tabindex="-1"></a>Goal → In order to make inferences based on the analysis of variance approach, we need to know the expected value of each of the mean squares.</span>
<span id="cb135-1666"><a href="#cb135-1666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1667"><a href="#cb135-1667" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-1668"><a href="#cb135-1668" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb135-1669"><a href="#cb135-1669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1670"><a href="#cb135-1670" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The expected value of a mean square is the mean of its sampling distribution and tells us what is being estimated by the mean square.</span>
<span id="cb135-1671"><a href="#cb135-1671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1672"><a href="#cb135-1672" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It can be shown that:</span>
<span id="cb135-1673"><a href="#cb135-1673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1674"><a href="#cb135-1674" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1675"><a href="#cb135-1675" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1676"><a href="#cb135-1676" aria-hidden="true" tabindex="-1"></a>  E(MSE) &amp;= \sigma^2 <span class="sc">\\</span></span>
<span id="cb135-1677"><a href="#cb135-1677" aria-hidden="true" tabindex="-1"></a>  E(MSR) &amp;= \sigma^2 + \beta_1^2 \sum (X_i - \bar{X})^2</span>
<span id="cb135-1678"><a href="#cb135-1678" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1679"><a href="#cb135-1679" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1680"><a href="#cb135-1680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1681"><a href="#cb135-1681" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note that the first result goes with earlier statement that $MSE$ is an unbiased estimator of $\sigma^2$.</span>
<span id="cb135-1682"><a href="#cb135-1682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1683"><a href="#cb135-1683" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Important implications</span>
<span id="cb135-1684"><a href="#cb135-1684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1685"><a href="#cb135-1685" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>The mean of the sampling distribution of $MSE$ is $\sigma^2$ *whether or not* $Y$ and $X$ are linearly related (i.e. whether or not $\beta_1 = 0$).</span>
<span id="cb135-1686"><a href="#cb135-1686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1687"><a href="#cb135-1687" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>The mean of the sampling distribution of $MSR$ is also $\sigma^2$ when $\beta_1 = 0$.</span>
<span id="cb135-1688"><a href="#cb135-1688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1689"><a href="#cb135-1689" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Thus, when $\beta_1 = 0$, the sampling distributions of $MSE$ and $MSR$ are located identically and $MSE$ and $MSR$ will tend to be relatively close to each other.</span>
<span id="cb135-1690"><a href="#cb135-1690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1691"><a href="#cb135-1691" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>But, when $\beta_1 \ne 0$, the mean of the sampling distribution of $MSR$ will be greater than $\sigma^2$ (because $\beta_1^2 \sum (X_i - \bar{X})^2$ then must be positive) and therefore located to the right of that of $MSE$. So, $MSR$ will tend to be larger than $MSE$.</span>
<span id="cb135-1692"><a href="#cb135-1692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1693"><a href="#cb135-1693" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>These results suggest that a comparison of $MSR$ and $MSE$ is useful for testing whether or not $\beta_1 = 0$.</span>
<span id="cb135-1694"><a href="#cb135-1694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1695"><a href="#cb135-1695" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb135-1696"><a href="#cb135-1696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1697"><a href="#cb135-1697" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/placeholder.png)</span>{width="50%"}</span>
<span id="cb135-1698"><a href="#cb135-1698" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-1699"><a href="#cb135-1699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1700"><a href="#cb135-1700" aria-hidden="true" tabindex="-1"></a><span class="fu">## $F$ test of $\beta_1 = 0$ vs $\beta_1 \ne 0$</span></span>
<span id="cb135-1701"><a href="#cb135-1701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1702"><a href="#cb135-1702" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-1703"><a href="#cb135-1703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1704"><a href="#cb135-1704" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The analysis of variance approach lets us perform very useful test for regression models (and other linear statistical models).</span>
<span id="cb135-1705"><a href="#cb135-1705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1706"><a href="#cb135-1706" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-1707"><a href="#cb135-1707" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results</span></span>
<span id="cb135-1708"><a href="#cb135-1708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1709"><a href="#cb135-1709" aria-hidden="true" tabindex="-1"></a>Test on slope</span>
<span id="cb135-1710"><a href="#cb135-1710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1711"><a href="#cb135-1711" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Hypotheses → For the SLR, ANOVA gives us a test for:</span>
<span id="cb135-1712"><a href="#cb135-1712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1713"><a href="#cb135-1713" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1714"><a href="#cb135-1714" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1715"><a href="#cb135-1715" aria-hidden="true" tabindex="-1"></a>  H_0 &amp;: \beta_1 = 0 <span class="sc">\\</span></span>
<span id="cb135-1716"><a href="#cb135-1716" aria-hidden="true" tabindex="-1"></a>  H_A &amp;: \beta_1 \ne 0</span>
<span id="cb135-1717"><a href="#cb135-1717" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1718"><a href="#cb135-1718" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1719"><a href="#cb135-1719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1720"><a href="#cb135-1720" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Test statistic → For ANOVA, the test statistic $F^*$ compares $MSR$ and $MSE$</span>
<span id="cb135-1721"><a href="#cb135-1721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1722"><a href="#cb135-1722" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1723"><a href="#cb135-1723" aria-hidden="true" tabindex="-1"></a>TS = F^* = \frac{MSR}{MSE}</span>
<span id="cb135-1724"><a href="#cb135-1724" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1725"><a href="#cb135-1725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1726"><a href="#cb135-1726" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>(see derivation) Under $H_0: \beta_1 = 0$ → $F^* \sim \text{F}\,_{(1, n-2)}$</span>
<span id="cb135-1727"><a href="#cb135-1727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1728"><a href="#cb135-1728" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Rejection region and p-value</span>
<span id="cb135-1729"><a href="#cb135-1729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1730"><a href="#cb135-1730" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$F^*$ values near 1 support $H_0$ and large $F^*$ values support $H_A$ (if the model is useful, we expect $MSR$ to be large compared to $MSE$) $\Longrightarrow$ Upper-tailed test.</span>
<span id="cb135-1731"><a href="#cb135-1731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1732"><a href="#cb135-1732" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1733"><a href="#cb135-1733" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1734"><a href="#cb135-1734" aria-hidden="true" tabindex="-1"></a>  RR &amp;= <span class="sc">\{</span>F^* &gt; F_{(1 - \alpha;\, 1, n - 2)}<span class="sc">\}</span> <span class="sc">\\</span></span>
<span id="cb135-1735"><a href="#cb135-1735" aria-hidden="true" tabindex="-1"></a>  p\text{-value} &amp;= P(F_{(1, n-2)} \ge F^*)</span>
<span id="cb135-1736"><a href="#cb135-1736" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1737"><a href="#cb135-1737" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1738"><a href="#cb135-1738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1739"><a href="#cb135-1739" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note → $F_{(1-\alpha;\,1,n-2)}$ is the $100 (1-\alpha)$ percentile of the appropriate $F$ distribution (different notation meaning than $t_{\alpha / 2}$ because not a symmetric distribution now).</span>
<span id="cb135-1740"><a href="#cb135-1740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1741"><a href="#cb135-1741" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Decision → Same rules as usual, now just with $F$-distribution</span>
<span id="cb135-1742"><a href="#cb135-1742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1743"><a href="#cb135-1743" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Reject $H_0$ and conclude $H_A$ if $\hspace{10pt}$ $TS \in RR \hspace{10pt} \Longleftrightarrow \hspace{10pt} p\text{-value} \le \alpha$; \hspace{20pt} Fail to reject $H_0$ if previous not true.</span>
<span id="cb135-1744"><a href="#cb135-1744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1745"><a href="#cb135-1745" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Conclusion / Interpretation</span>
<span id="cb135-1746"><a href="#cb135-1746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1747"><a href="#cb135-1747" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>At the $\alpha$ significance level, we <span class="sc">\&lt;</span> have / do not have <span class="sc">\&gt;</span> sufficient evidence of a significant linear relationship between <span class="sc">\&lt;</span> $Y$ context <span class="sc">\&gt;</span> and <span class="sc">\&lt;</span> $X$ context <span class="sc">\&gt;</span>.</span>
<span id="cb135-1748"><a href="#cb135-1748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1749"><a href="#cb135-1749" aria-hidden="true" tabindex="-1"></a>Equivalence of $F$ test and $t$ test</span>
<span id="cb135-1750"><a href="#cb135-1750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1751"><a href="#cb135-1751" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The $F$-test is algebraically equivalent to the *two-tailed* $t$ test → $F^* = (t^*)^2$</span>
<span id="cb135-1752"><a href="#cb135-1752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1753"><a href="#cb135-1753" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Same relationship for the critical values when defining the rejection region / p-value → $F_{(1-\alpha; \, 1, n-2)} = t_{\alpha/2, n-2}^2$.</span>
<span id="cb135-1754"><a href="#cb135-1754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1755"><a href="#cb135-1755" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Will get same conclusion either way, but the $t$ test is more flexible because it can be used for one-sided alternatives involving $\beta_1$, while the $F$ test cannot.</span>
<span id="cb135-1756"><a href="#cb135-1756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1757"><a href="#cb135-1757" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Derivation</span></span>
<span id="cb135-1758"><a href="#cb135-1758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1759"><a href="#cb135-1759" aria-hidden="true" tabindex="-1"></a>Sampling distribution of $F^*$</span>
<span id="cb135-1760"><a href="#cb135-1760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1761"><a href="#cb135-1761" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Goal → In order to be able to construct a statistical decision rule and examine its properties, we need to know the sampling distribution of $F^*$.</span>
<span id="cb135-1762"><a href="#cb135-1762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1763"><a href="#cb135-1763" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Derivation → Start by considering the sampling distribution of $F^*$ under $H_0: \beta_1 = 0$. We will use the following theorem:</span>
<span id="cb135-1764"><a href="#cb135-1764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1765"><a href="#cb135-1765" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Cochran's theorem** → Let $Y_1, \ldots, Y_{n}$ represent a random sample from the same normal distribution with mean $\mu$ and variance $\sigma^2$. Suppose $SSTO = \sum (Y_i - \bar{Y})^2$ is partitioned into $k$ sums of squares $SS_r$, each with degrees of freedom $df_r$. If $\displaystyle \sum_{r=1}^k df_{r} = n - 1$, then each of the $\frac{SS_r}{\sigma^2}$ terms are independent $\chi^2$ random variables with $df_r$ degrees of freedom.</span>
<span id="cb135-1766"><a href="#cb135-1766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1767"><a href="#cb135-1767" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/placeholder.png)</span>{width="50%"}</span>
<span id="cb135-1768"><a href="#cb135-1768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1769"><a href="#cb135-1769" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Under $H_A: \beta_1 \ne 0$</span>
<span id="cb135-1770"><a href="#cb135-1770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1771"><a href="#cb135-1771" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$F^* \sim \text{Non-central F}\,_{(1, n - 2)}$ with non-centrality parameter $\lambda$.</span>
<span id="cb135-1772"><a href="#cb135-1772" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Still $SSR \perp <span class="sc">\!\!\!</span> \perp SSE$ and $SSE / \sigma^2 \sim \chi^2_{n-2}$. But the condition that both $SSR / \sigma^2$ and $SSE / \sigma^2$ are $\chi^2$ random variables requires $\beta_1 = 0$.</span>
<span id="cb135-1773"><a href="#cb135-1773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1774"><a href="#cb135-1774" aria-hidden="true" tabindex="-1"></a>Equivalence of $F$ test and $t$ test</span>
<span id="cb135-1775"><a href="#cb135-1775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1776"><a href="#cb135-1776" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/placeholder.png)</span>{width="50%"}</span>
<span id="cb135-1777"><a href="#cb135-1777" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-1778"><a href="#cb135-1778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1779"><a href="#cb135-1779" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb135-1780"><a href="#cb135-1780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1781"><a href="#cb135-1781" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-1782"><a href="#cb135-1782" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-1783"><a href="#cb135-1783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1786"><a href="#cb135-1786" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1787"><a href="#cb135-1787" aria-hidden="true" tabindex="-1"></a><span class="co"># continuing previous anova table demo</span></span>
<span id="cb135-1788"><a href="#cb135-1788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1789"><a href="#cb135-1789" aria-hidden="true" tabindex="-1"></a><span class="co"># show anova table</span></span>
<span id="cb135-1790"><a href="#cb135-1790" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; looking for F value` and Pr(&gt;F)</span></span>
<span id="cb135-1791"><a href="#cb135-1791" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod) <span class="sc">%&gt;%</span> as.matrix</span>
<span id="cb135-1792"><a href="#cb135-1792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1793"><a href="#cb135-1793" aria-hidden="true" tabindex="-1"></a><span class="co"># equivalence of F test and two sided t-test</span></span>
<span id="cb135-1794"><a href="#cb135-1794" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">anova</span>(mod)[<span class="st">"x"</span>,<span class="st">"F value"</span>], <span class="fu">summary</span>(mod)<span class="sc">$</span>coefficients[<span class="st">"x"</span>,<span class="st">"t value"</span>]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-1795"><a href="#cb135-1795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1796"><a href="#cb135-1796" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1797"><a href="#cb135-1797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1798"><a href="#cb135-1798" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-1799"><a href="#cb135-1799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1802"><a href="#cb135-1802" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1803"><a href="#cb135-1803" aria-hidden="true" tabindex="-1"></a><span class="co"># continuing to recreate each value in the anova table output</span></span>
<span id="cb135-1804"><a href="#cb135-1804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1805"><a href="#cb135-1805" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate F and p-value</span></span>
<span id="cb135-1806"><a href="#cb135-1806" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; TS F* = MSR / MSE</span></span>
<span id="cb135-1807"><a href="#cb135-1807" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; p-value = P(F(df reg, df error) &gt; F*)</span></span>
<span id="cb135-1808"><a href="#cb135-1808" aria-hidden="true" tabindex="-1"></a>F_star <span class="ot">&lt;-</span> msr <span class="sc">/</span> mse</span>
<span id="cb135-1809"><a href="#cb135-1809" aria-hidden="true" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="fu">pf</span>(<span class="at">q =</span> F_star, <span class="at">df1 =</span> df_r, <span class="at">df2 =</span> df_e, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb135-1810"><a href="#cb135-1810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1811"><a href="#cb135-1811" aria-hidden="true" tabindex="-1"></a><span class="co"># compare results to relevant pieces of anova(lm())</span></span>
<span id="cb135-1812"><a href="#cb135-1812" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">anova</span>(mod_lm)[<span class="dv">1</span>,<span class="dv">4</span><span class="sc">:</span><span class="dv">5</span>], <span class="fu">c</span>(F_star, p_value))</span>
<span id="cb135-1813"><a href="#cb135-1813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1814"><a href="#cb135-1814" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1815"><a href="#cb135-1815" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-1816"><a href="#cb135-1816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1817"><a href="#cb135-1817" aria-hidden="true" tabindex="-1"></a><span class="fu">## General linear test approach</span></span>
<span id="cb135-1818"><a href="#cb135-1818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1819"><a href="#cb135-1819" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-1820"><a href="#cb135-1820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1821"><a href="#cb135-1821" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The ANOVA $F$ test above is an example of a **General Linear Test (GLT)** (also called a **global** or an **omnibus** test) for a statistical model, which is an approach that can be used for highly complex tests of linear statistical models, as well as for simple tests.</span>
<span id="cb135-1822"><a href="#cb135-1822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1823"><a href="#cb135-1823" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>For SLR, the global test (the significance of a model test), the ANVOA $F$ test, and the $t$ test for the linear impact are all equivalent.</span>
<span id="cb135-1824"><a href="#cb135-1824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1825"><a href="#cb135-1825" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It has three basic steps, which are described in more detail below:</span>
<span id="cb135-1826"><a href="#cb135-1826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1827"><a href="#cb135-1827" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>Fit the full model and obtain the error sum of squares $SSE(F)$.</span>
<span id="cb135-1828"><a href="#cb135-1828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1829"><a href="#cb135-1829" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>Fit the reduced model under Ho and obtain the error sum of squares $SSE(R)$.</span>
<span id="cb135-1830"><a href="#cb135-1830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1831"><a href="#cb135-1831" aria-hidden="true" tabindex="-1"></a><span class="ss">    3.  </span>Use test statistic / p-value to make decision.</span>
<span id="cb135-1832"><a href="#cb135-1832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1833"><a href="#cb135-1833" aria-hidden="true" tabindex="-1"></a>Full model</span>
<span id="cb135-1834"><a href="#cb135-1834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1835"><a href="#cb135-1835" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Start with the model considered to be appropriate for the data (or the model with all available predictors); this is called the **full / unrestricted model**.</span>
<span id="cb135-1836"><a href="#cb135-1836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1837"><a href="#cb135-1837" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>For SLR, the full model is just the normal error regression model:</span>
<span id="cb135-1838"><a href="#cb135-1838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1839"><a href="#cb135-1839" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1840"><a href="#cb135-1840" aria-hidden="true" tabindex="-1"></a>Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \hspace{20pt} \text{Full model}</span>
<span id="cb135-1841"><a href="#cb135-1841" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1842"><a href="#cb135-1842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1843"><a href="#cb135-1843" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We need to fit the full model and get the error sum of squares, denoted $SSE(F)$ (deviations of $Y_i$ and its estimated expected value $\hat{Y_i}$, which is the fitted regression line). For the full model, we have:</span>
<span id="cb135-1844"><a href="#cb135-1844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1845"><a href="#cb135-1845" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1846"><a href="#cb135-1846" aria-hidden="true" tabindex="-1"></a>SSE(F) = \sum (Y_i - \hat{Y_i})^2 = \sum <span class="co">[</span><span class="ot">Y_i - (\hat{\beta}_0  + \hat{\beta}_1 X_i)</span><span class="co">]</span>^2 = SSE</span>
<span id="cb135-1847"><a href="#cb135-1847" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1848"><a href="#cb135-1848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1849"><a href="#cb135-1849" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*With a SLR full model*, the error sum of squares is the usual $SSE$.</span>
<span id="cb135-1850"><a href="#cb135-1850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1851"><a href="#cb135-1851" aria-hidden="true" tabindex="-1"></a>Reduced model</span>
<span id="cb135-1852"><a href="#cb135-1852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1853"><a href="#cb135-1853" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Next we consider $H_0$. For SLR, we have:</span>
<span id="cb135-1854"><a href="#cb135-1854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1855"><a href="#cb135-1855" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1856"><a href="#cb135-1856" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1857"><a href="#cb135-1857" aria-hidden="true" tabindex="-1"></a>  H_0 &amp;: \beta_1 = 0 \hspace{20pt} \text{Reduced model is appropriate} <span class="sc">\\</span></span>
<span id="cb135-1858"><a href="#cb135-1858" aria-hidden="true" tabindex="-1"></a>  H_A &amp;: \beta_1 \ne 0 \hspace{20pt} \text{Full model is appropriate}</span>
<span id="cb135-1859"><a href="#cb135-1859" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1860"><a href="#cb135-1860" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1861"><a href="#cb135-1861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1862"><a href="#cb135-1862" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The model under $H_0$ is called the **reduced / restricted model**. When $\beta_1 = 0$, the full model reduces to:</span>
<span id="cb135-1863"><a href="#cb135-1863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1864"><a href="#cb135-1864" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1865"><a href="#cb135-1865" aria-hidden="true" tabindex="-1"></a>Y_i = \beta_0 + 0 \cdot X_i + \epsilon_i = \beta_0 + \epsilon_i \hspace{20pt} \text{Reduced model}</span>
<span id="cb135-1866"><a href="#cb135-1866" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1867"><a href="#cb135-1867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1868"><a href="#cb135-1868" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Then we fit the reduced model and again get the error sum of squares, now denoted $SSE(R)$.</span>
<span id="cb135-1869"><a href="#cb135-1869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1870"><a href="#cb135-1870" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>*For this particular (a SLR) reduced model*, it can easily be shown that the LSE and MLE estimator of $\beta_0$ is $\bar{Y}$. Thus the estimated expected value of each observation is $\hat{\beta}_0 = \bar{Y}$ and we can get the error sum of squares with:</span>
<span id="cb135-1871"><a href="#cb135-1871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1872"><a href="#cb135-1872" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1873"><a href="#cb135-1873" aria-hidden="true" tabindex="-1"></a>SSE(R) = \sum (Y_i - \hat{Y_i})^2 = \sum (Y_i - \hat{\beta}_0)^2 = \sum (Y_i - \bar{Y})^2 = SSTO</span>
<span id="cb135-1874"><a href="#cb135-1874" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1875"><a href="#cb135-1875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1876"><a href="#cb135-1876" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Thus, *for any intercept-only reducted model* $\Longrightarrow$ $SSE(R) = SSTO$.</span>
<span id="cb135-1877"><a href="#cb135-1877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1878"><a href="#cb135-1878" aria-hidden="true" tabindex="-1"></a>Test statistic and decision</span>
<span id="cb135-1879"><a href="#cb135-1879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1880"><a href="#cb135-1880" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Logic → Now we compare the two sum of squares from the full and reduced model using the fact that the reduced $SSE$ is always greater than or equal to the full $SSE$.</span>
<span id="cb135-1881"><a href="#cb135-1881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1882"><a href="#cb135-1882" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$SSE(R) \ge SSE(F)$ → More parameters in the model ALWAYS leads to a better fit (i.e. *less unexplained* variability = *more explained* variability) $\Longrightarrow$ Smaller are the deviations around the fitted regression function.</span>
<span id="cb135-1883"><a href="#cb135-1883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1884"><a href="#cb135-1884" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Comparison scenarios</span>
<span id="cb135-1885"><a href="#cb135-1885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1886"><a href="#cb135-1886" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>$SSE(F)$ are close $SSE(R)$</span>
<span id="cb135-1887"><a href="#cb135-1887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1888"><a href="#cb135-1888" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Using the full model does not account for much more unexplained variability than does the reduced model $\Longrightarrow$ Added parameters in the full model *do not* really help to reduce the unexplained variation $\Longrightarrow$ Reduced model is adequate and $H_0$ holds.</span>
<span id="cb135-1889"><a href="#cb135-1889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1890"><a href="#cb135-1890" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>$SSE(R) &lt;&lt; SSE(F)$</span>
<span id="cb135-1891"><a href="#cb135-1891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1892"><a href="#cb135-1892" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The additional parameters in the full model *do* help to substantially reduce the unexplained variability in $Y_i$, which means $H_A$ holds.</span>
<span id="cb135-1893"><a href="#cb135-1893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1894"><a href="#cb135-1894" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Test statistic is a function of the difference in two $SSE$s, relative to the full $SSE$:</span>
<span id="cb135-1895"><a href="#cb135-1895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1896"><a href="#cb135-1896" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1897"><a href="#cb135-1897" aria-hidden="true" tabindex="-1"></a>TS = F^* = \frac{SSE(R) - SSE(F)}{df_R - df_F} \Big/ \frac{SSE(F)}{df_F} = \frac{SSE(R) - SSE(F)}{df_R - df_F}  \Big/ MSE(F)</span>
<span id="cb135-1898"><a href="#cb135-1898" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1899"><a href="#cb135-1899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1900"><a href="#cb135-1900" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Under $H_0: \beta_1 = 0 \hspace{10pt} \text{Reduced model}$ → $F^* \sim \text{F}\,_{(df_R - df_F, df_F)}$</span>
<span id="cb135-1901"><a href="#cb135-1901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1902"><a href="#cb135-1902" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Rejection region and p-value</span>
<span id="cb135-1903"><a href="#cb135-1903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1904"><a href="#cb135-1904" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Again, we reject for large values of $F^*$ (large difference $SSE(R) - SSE(F)$ supports $H_A$).</span>
<span id="cb135-1905"><a href="#cb135-1905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1906"><a href="#cb135-1906" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1907"><a href="#cb135-1907" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1908"><a href="#cb135-1908" aria-hidden="true" tabindex="-1"></a>  RR &amp;= <span class="sc">\{</span>F^* &gt; F_{(1 - \alpha;\, df_R - df_F, \, df_F)}<span class="sc">\}</span> <span class="sc">\\</span></span>
<span id="cb135-1909"><a href="#cb135-1909" aria-hidden="true" tabindex="-1"></a>  p\text{-value} &amp;= P(F_{(df_R - df_F, \, df_F} \ge F^*)</span>
<span id="cb135-1910"><a href="#cb135-1910" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1911"><a href="#cb135-1911" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1912"><a href="#cb135-1912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1913"><a href="#cb135-1913" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For SLR (testing whether or not $\beta_1 = 0$), we have:</span>
<span id="cb135-1914"><a href="#cb135-1914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1915"><a href="#cb135-1915" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1916"><a href="#cb135-1916" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb135-1917"><a href="#cb135-1917" aria-hidden="true" tabindex="-1"></a>  SSE(R) &amp;= SSTO \hspace{20pt} SSE(F) = SSE <span class="sc">\\</span></span>
<span id="cb135-1918"><a href="#cb135-1918" aria-hidden="true" tabindex="-1"></a>  f_R &amp;= n - 1 \hspace{45pt} df_F = n - 2</span>
<span id="cb135-1919"><a href="#cb135-1919" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb135-1920"><a href="#cb135-1920" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1921"><a href="#cb135-1921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1922"><a href="#cb135-1922" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>So the test statistic becomes</span>
<span id="cb135-1923"><a href="#cb135-1923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1924"><a href="#cb135-1924" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1925"><a href="#cb135-1925" aria-hidden="true" tabindex="-1"></a>F^* = \frac{SSTO - SSE}{(n - 1) - (n - 2)} \Big/ \frac{SSE}{n - 2} = \frac{SSR}{1} \Big/ \frac{SSE}{n - 2} = \frac{MSR}{MSE}</span>
<span id="cb135-1926"><a href="#cb135-1926" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-1927"><a href="#cb135-1927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1928"><a href="#cb135-1928" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This is equivalent to the ANOVA $F$ test shown earlier.</span>
<span id="cb135-1929"><a href="#cb135-1929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1930"><a href="#cb135-1930" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-1931"><a href="#cb135-1931" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-1932"><a href="#cb135-1932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1935"><a href="#cb135-1935" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1936"><a href="#cb135-1936" aria-hidden="true" tabindex="-1"></a><span class="co"># using the same data as anova table demos</span></span>
<span id="cb135-1937"><a href="#cb135-1937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1938"><a href="#cb135-1938" aria-hidden="true" tabindex="-1"></a><span class="co"># fit full model</span></span>
<span id="cb135-1939"><a href="#cb135-1939" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; for SLR, full model is E(Y) = B0 + B1 X</span></span>
<span id="cb135-1940"><a href="#cb135-1940" aria-hidden="true" tabindex="-1"></a>mod_full <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb135-1941"><a href="#cb135-1941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1942"><a href="#cb135-1942" aria-hidden="true" tabindex="-1"></a><span class="co"># fit reduced model</span></span>
<span id="cb135-1943"><a href="#cb135-1943" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; for SLR, full model is E(Y) = B0</span></span>
<span id="cb135-1944"><a href="#cb135-1944" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; to fit an intercept-only model, specify 1 on the RHS</span></span>
<span id="cb135-1945"><a href="#cb135-1945" aria-hidden="true" tabindex="-1"></a>mod_reduced <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span>)</span>
<span id="cb135-1946"><a href="#cb135-1946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1947"><a href="#cb135-1947" aria-hidden="true" tabindex="-1"></a><span class="co"># perform general linear test of reduced vs full model</span></span>
<span id="cb135-1948"><a href="#cb135-1948" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; testing H0: beta_1 = 0 (reduced model) vs HA: beta_1 != 0 (full model)</span></span>
<span id="cb135-1949"><a href="#cb135-1949" aria-hidden="true" tabindex="-1"></a><span class="co"># function call</span></span>
<span id="cb135-1950"><a href="#cb135-1950" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; anova() on multiple lm objects &lt;==&gt; anova.lmlist() -&gt; this is the second main uses of this function</span></span>
<span id="cb135-1951"><a href="#cb135-1951" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; typically will supply models smallest to largest (this makes for a natural interpretation of the results); but it works regardless</span></span>
<span id="cb135-1952"><a href="#cb135-1952" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; models MUST BE nested AND fit on the same dataset in order for results to make statistical sense</span></span>
<span id="cb135-1953"><a href="#cb135-1953" aria-hidden="true" tabindex="-1"></a><span class="co"># results</span></span>
<span id="cb135-1954"><a href="#cb135-1954" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sequentially gives the change in dfs and SS from mod 1 to mod 2 (then from mod 2 to mod 3, and so on...)</span></span>
<span id="cb135-1955"><a href="#cb135-1955" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; so it is df_1 - df_2 and SS_1 - SS_2 ==&gt; if nested from smallest to largest model, results will all be positive and interpreted as "additional reductions"</span></span>
<span id="cb135-1956"><a href="#cb135-1956" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; by default, performs F test comparing models in the order specified (again sequentially)</span></span>
<span id="cb135-1957"><a href="#cb135-1957" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_reduced, mod_full, <span class="at">test =</span> <span class="st">"F"</span>) <span class="sc">%&gt;%</span> as.matrix</span>
<span id="cb135-1958"><a href="#cb135-1958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1959"><a href="#cb135-1959" aria-hidden="true" tabindex="-1"></a><span class="co"># demo with more than two models</span></span>
<span id="cb135-1960"><a href="#cb135-1960" aria-hidden="true" tabindex="-1"></a>mod_squared <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> <span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb135-1961"><a href="#cb135-1961" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_reduced, mod_full, mod_squared) <span class="sc">%&gt;%</span> as.matrix</span>
<span id="cb135-1962"><a href="#cb135-1962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1963"><a href="#cb135-1963" aria-hidden="true" tabindex="-1"></a><span class="co"># demo showing how the sequential comparison works</span></span>
<span id="cb135-1964"><a href="#cb135-1964" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; above compared mod 1 to mod 2 and then mod 2 to mod 3</span></span>
<span id="cb135-1965"><a href="#cb135-1965" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; now comparing mod 1 directly to mod 3</span></span>
<span id="cb135-1966"><a href="#cb135-1966" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_reduced, mod_squared) <span class="sc">%&gt;%</span> as.matrix</span>
<span id="cb135-1967"><a href="#cb135-1967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1968"><a href="#cb135-1968" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-1969"><a href="#cb135-1969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1970"><a href="#cb135-1970" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-1971"><a href="#cb135-1971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1974"><a href="#cb135-1974" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-1975"><a href="#cb135-1975" aria-hidden="true" tabindex="-1"></a><span class="co"># general linear test of reduced vs full model</span></span>
<span id="cb135-1976"><a href="#cb135-1976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1977"><a href="#cb135-1977" aria-hidden="true" tabindex="-1"></a><span class="co"># using the same data as anova table demos</span></span>
<span id="cb135-1978"><a href="#cb135-1978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1979"><a href="#cb135-1979" aria-hidden="true" tabindex="-1"></a><span class="co"># for full model -&gt;  get the corresponding SSE and df </span></span>
<span id="cb135-1980"><a href="#cb135-1980" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; for SLR, full model is E(Y) = B0 + B1 X</span></span>
<span id="cb135-1981"><a href="#cb135-1981" aria-hidden="true" tabindex="-1"></a>sse_f <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod_full)<span class="sc">^</span><span class="dv">2</span> <span class="sc">%&gt;%</span> sum</span>
<span id="cb135-1982"><a href="#cb135-1982" aria-hidden="true" tabindex="-1"></a>df_f <span class="ot">&lt;-</span> <span class="fu">df.residual</span>(mod_full)</span>
<span id="cb135-1983"><a href="#cb135-1983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1984"><a href="#cb135-1984" aria-hidden="true" tabindex="-1"></a><span class="co"># for reduced model -&gt; get the corresponding SSE and df</span></span>
<span id="cb135-1985"><a href="#cb135-1985" aria-hidden="true" tabindex="-1"></a>sse_r <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod_reduced)<span class="sc">^</span><span class="dv">2</span> <span class="sc">%&gt;%</span> sum</span>
<span id="cb135-1986"><a href="#cb135-1986" aria-hidden="true" tabindex="-1"></a>df_r <span class="ot">&lt;-</span> <span class="fu">df.residual</span>(mod_reduced)</span>
<span id="cb135-1987"><a href="#cb135-1987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1988"><a href="#cb135-1988" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate F stat and p-value</span></span>
<span id="cb135-1989"><a href="#cb135-1989" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; using the shortcut for second term: F* = [(SSE(R) - SSE(F)) / (df_R - df_F)] / MSE(F)</span></span>
<span id="cb135-1990"><a href="#cb135-1990" aria-hidden="true" tabindex="-1"></a>mse_f <span class="ot">&lt;-</span> <span class="fu">summary</span>(mod_full)<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb135-1991"><a href="#cb135-1991" aria-hidden="true" tabindex="-1"></a>F_star <span class="ot">&lt;-</span> ((sse_r <span class="sc">-</span> sse_f) <span class="sc">/</span> (df_r <span class="sc">-</span> df_f)) <span class="sc">/</span> mse_f</span>
<span id="cb135-1992"><a href="#cb135-1992" aria-hidden="true" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="fu">pf</span>(<span class="at">q =</span> F_star, <span class="at">df1 =</span> df_r <span class="sc">-</span> df_f, <span class="at">df2 =</span> df_f, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb135-1993"><a href="#cb135-1993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1994"><a href="#cb135-1994" aria-hidden="true" tabindex="-1"></a><span class="co"># combine (organize) into anova table layout for comparison</span></span>
<span id="cb135-1995"><a href="#cb135-1995" aria-hidden="true" tabindex="-1"></a>at <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">data =</span> <span class="fu">c</span>(<span class="fu">c</span>(df_r, df_f), <span class="fu">c</span>(sse_r, sse_f), <span class="fu">c</span>(<span class="cn">NA</span>, df_r <span class="sc">-</span> df_f), <span class="fu">c</span>(<span class="cn">NA</span>, sse_r <span class="sc">-</span> sse_f), <span class="fu">c</span>(<span class="cn">NA</span>, F_star), <span class="fu">c</span>(<span class="cn">NA</span>, p_value)), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">FALSE</span>)</span>
<span id="cb135-1996"><a href="#cb135-1996" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(at) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"df_E Original"</span>, <span class="st">"SSE Original"</span>, <span class="st">"Change df"</span>, <span class="st">"Change SSE"</span>, <span class="st">"F*"</span>, <span class="st">"p-value"</span>)</span>
<span id="cb135-1997"><a href="#cb135-1997" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(at) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Mod 1 - Reduced"</span>, <span class="st">"Mod 2 - Full"</span>)</span>
<span id="cb135-1998"><a href="#cb135-1998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-1999"><a href="#cb135-1999" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to results from anova(reduced mod, full model)</span></span>
<span id="cb135-2000"><a href="#cb135-2000" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">anova</span>(mod_reduced, mod_full), at)</span>
<span id="cb135-2001"><a href="#cb135-2001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2002"><a href="#cb135-2002" aria-hidden="true" tabindex="-1"></a><span class="co"># for SLR ==&gt; equivalent to F test on beta 1</span></span>
<span id="cb135-2003"><a href="#cb135-2003" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">anova</span>(mod_reduced, mod_full)[<span class="dv">2</span>, <span class="st">"F"</span>], <span class="fu">anova</span>(mod_full)[<span class="st">"x"</span>, <span class="st">"F value"</span>])</span>
<span id="cb135-2004"><a href="#cb135-2004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2005"><a href="#cb135-2005" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-2006"><a href="#cb135-2006" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-2007"><a href="#cb135-2007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2008"><a href="#cb135-2008" aria-hidden="true" tabindex="-1"></a><span class="fu">## Descriptive measures of linear association between $X$ and $Y$</span></span>
<span id="cb135-2009"><a href="#cb135-2009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2010"><a href="#cb135-2010" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-2011"><a href="#cb135-2011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2012"><a href="#cb135-2012" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There is no *one single measure* to completely describe the usefulness of a regression model for a particular application.</span>
<span id="cb135-2013"><a href="#cb135-2013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2014"><a href="#cb135-2014" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If the goal is estimation of parameters and means and predicting new observations, usefulness of estimates or predictions depends upon the width of the interval and the user's needs for precision. This can vary from one application to another.</span>
<span id="cb135-2015"><a href="#cb135-2015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2016"><a href="#cb135-2016" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Rather than making inferences, goals could be to describe the degree of linear association between $Y$ and $X$. Again the usefulness of which measure and its value depend on the application.</span>
<span id="cb135-2017"><a href="#cb135-2017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2018"><a href="#cb135-2018" aria-hidden="true" tabindex="-1"></a><span class="fu">### Coefficient of determination</span></span>
<span id="cb135-2019"><a href="#cb135-2019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2020"><a href="#cb135-2020" aria-hidden="true" tabindex="-1"></a>Overview</span>
<span id="cb135-2021"><a href="#cb135-2021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2022"><a href="#cb135-2022" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A very common measure because of its simplicity is the coefficient of determination $R^2$, which is a measure of the effect of $X$ in reducing the uncertainty in predicting $Y$. This reduction in sum of squares ($SSTO - SSE = SSR$) gets expressed as a proportion:</span>
<span id="cb135-2023"><a href="#cb135-2023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2024"><a href="#cb135-2024" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-2025"><a href="#cb135-2025" aria-hidden="true" tabindex="-1"></a>R^2 = \frac{SSR}{SSTO} = 1-\frac{SSE}{SSTO}, \hspace{20pt} \text{range:} \hspace{10pt} 0 \le R^2 \le 1</span>
<span id="cb135-2026"><a href="#cb135-2026" aria-hidden="true" tabindex="-1"></a>$$ Interpretation</span>
<span id="cb135-2027"><a href="#cb135-2027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2028"><a href="#cb135-2028" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\&lt;</span> $R^2 *100$ \&gt;% of the variation in \&lt; $Y$ context \&gt; can be explained by the *linear* relationship between <span class="sc">\&lt;</span> $Y$ context <span class="sc">\&gt;</span> and <span class="sc">\&lt;</span> $X$ context <span class="sc">\&gt;</span>.</span>
<span id="cb135-2029"><a href="#cb135-2029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2030"><a href="#cb135-2030" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>So, the larger $R^2$ is, the more the total variation of $Y$ is reduced by introducing the predictor variable $X$ $\Longleftrightarrow$ greater degree of linear association between $Y$ and $X$.</span>
<span id="cb135-2031"><a href="#cb135-2031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2032"><a href="#cb135-2032" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Practically, this indicates the quality of the fit by measuring the proportion of variability explained by the fitted model.</span>
<span id="cb135-2033"><a href="#cb135-2033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2034"><a href="#cb135-2034" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Limiting values</span>
<span id="cb135-2035"><a href="#cb135-2035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2036"><a href="#cb135-2036" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When the fitted regression line is horizontal ($\hat{\beta}_1 = 0$ and $\hat{Y_i} = \bar{Y}$) $\Longrightarrow$ $SSE = SSTO$ and $R^2 = 0$.</span>
<span id="cb135-2037"><a href="#cb135-2037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2038"><a href="#cb135-2038" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When there is a perfect fit (all of the points lie on the fitted regression line) $\Longrightarrow$ $SSE = 0$ and $R^2 = 1$.</span>
<span id="cb135-2039"><a href="#cb135-2039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2040"><a href="#cb135-2040" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In practice, unlikely to be exactly equal to either of these. Also note that context of data (scientific field of the application) has a big impact on general values of $R^2$ and consequently what is interpreted as "strong".</span>
<span id="cb135-2041"><a href="#cb135-2041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2042"><a href="#cb135-2042" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If $R^2$ is small, we can consider adding other independent variables that can explain a significant portion of the remaining unexplained variability in the model.</span>
<span id="cb135-2043"><a href="#cb135-2043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2044"><a href="#cb135-2044" aria-hidden="true" tabindex="-1"></a>Limitations of $R^2$</span>
<span id="cb135-2045"><a href="#cb135-2045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2046"><a href="#cb135-2046" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Usefulness in prediction → A high coefficient of determination does not necessarily indicate that useful (precise) predictions can be made.</span>
<span id="cb135-2047"><a href="#cb135-2047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2048"><a href="#cb135-2048" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>This is because $R^2$ measures only a relative reduction from $SSTO$ and provides no information about absolute precision for estimating a mean response or predicting a new observation.</span>
<span id="cb135-2049"><a href="#cb135-2049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2050"><a href="#cb135-2050" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Quality of fit → A high coefficient of determination does not necessarily indicate that the estimated regression line is a good fit and similarly an $R^2$ near zero does not necessarily indicate that $Y$ and $X$ are not related.</span>
<span id="cb135-2051"><a href="#cb135-2051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2052"><a href="#cb135-2052" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>This is because $R^2$ measures the degree of *linear* association between $Y$ and $X$, whereas the actual regression relation may be curvilinear. So make sure to look at the scatterplot.</span>
<span id="cb135-2053"><a href="#cb135-2053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2054"><a href="#cb135-2054" aria-hidden="true" tabindex="-1"></a><span class="al">![](files/images/r2-limitations.png)</span>{width="50%"}</span>
<span id="cb135-2055"><a href="#cb135-2055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2056"><a href="#cb135-2056" aria-hidden="true" tabindex="-1"></a>Inflating $R^2$</span>
<span id="cb135-2057"><a href="#cb135-2057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2058"><a href="#cb135-2058" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$X$ level spacing → The value taken by $R^2$ in a given sample tends to be affected by the spacing of the $X$ observations: Wider spacing in $X_i$ $\Longrightarrow$ higher $R^2$. Here's why:</span>
<span id="cb135-2059"><a href="#cb135-2059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2060"><a href="#cb135-2060" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Wider spacing (larger spread) in $X_i$ in the sample when $\hat{\beta}_1 \ne 0$ $\Longrightarrow$ larger spread of the observed $Y_i$ around $\bar{Y}$ $\Longrightarrow$ Larger $SSTO$.</span>
<span id="cb135-2061"><a href="#cb135-2061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2062"><a href="#cb135-2062" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>And since $SSE$ is unaffected ($V(Y_i) = \sigma^2$ for all $X_i$), $SSR$ has to increase. Then we can see from either representation $R_2 = SSR/ SSTO = 1 - SSE / SSTO$, that $R^2$ will increase.</span>
<span id="cb135-2063"><a href="#cb135-2063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2064"><a href="#cb135-2064" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Overfitting → $R^2$ can be artificially inflated by including additional model terms (adding extra predictors).</span>
<span id="cb135-2065"><a href="#cb135-2065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2066"><a href="#cb135-2066" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>This is because $SSR$ always increases with more predictors, even if they are completely unrelated to the response variable.</span>
<span id="cb135-2067"><a href="#cb135-2067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2068"><a href="#cb135-2068" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Later $R^2_{adj}$ will be discussed which corrects for the inclusion of extra predictors.</span>
<span id="cb135-2069"><a href="#cb135-2069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2070"><a href="#cb135-2070" aria-hidden="true" tabindex="-1"></a>Demo</span>
<span id="cb135-2071"><a href="#cb135-2071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2072"><a href="#cb135-2072" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb135-2073"><a href="#cb135-2073" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R functions</span></span>
<span id="cb135-2074"><a href="#cb135-2074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2077"><a href="#cb135-2077" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-2078"><a href="#cb135-2078" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb135-2079"><a href="#cb135-2079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2080"><a href="#cb135-2080" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items</span></span>
<span id="cb135-2081"><a href="#cb135-2081" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span id="cb135-2082"><a href="#cb135-2082" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>; beta_0 <span class="ot">&lt;-</span> <span class="dv">2</span>; beta_1 <span class="ot">&lt;-</span> <span class="dv">5</span>; sigma <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb135-2083"><a href="#cb135-2083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2084"><a href="#cb135-2084" aria-hidden="true" tabindex="-1"></a><span class="co"># generate data</span></span>
<span id="cb135-2085"><a href="#cb135-2085" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">15</span>)</span>
<span id="cb135-2086"><a href="#cb135-2086" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x, <span class="at">sd =</span> sigma)</span>
<span id="cb135-2087"><a href="#cb135-2087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2088"><a href="#cb135-2088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2089"><a href="#cb135-2089" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-2090"><a href="#cb135-2090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2093"><a href="#cb135-2093" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-2094"><a href="#cb135-2094" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb135-2095"><a href="#cb135-2095" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb135-2096"><a href="#cb135-2096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2097"><a href="#cb135-2097" aria-hidden="true" tabindex="-1"></a><span class="co"># display summary</span></span>
<span id="cb135-2098"><a href="#cb135-2098" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; looking for Multiple R-squared</span></span>
<span id="cb135-2099"><a href="#cb135-2099" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb135-2100"><a href="#cb135-2100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2101"><a href="#cb135-2101" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-2102"><a href="#cb135-2102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2105"><a href="#cb135-2105" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-2106"><a href="#cb135-2106" aria-hidden="true" tabindex="-1"></a><span class="co">#| class.source = "fold-hide"</span></span>
<span id="cb135-2107"><a href="#cb135-2107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2108"><a href="#cb135-2108" aria-hidden="true" tabindex="-1"></a><span class="co"># plot x and y with regression line</span></span>
<span id="cb135-2109"><a href="#cb135-2109" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; add annotation for R^2 value</span></span>
<span id="cb135-2110"><a href="#cb135-2110" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb135-2111"><a href="#cb135-2111" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb135-2112"><a href="#cb135-2112" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="dv">14</span>, <span class="at">y =</span> <span class="dv">30</span>, <span class="at">labels =</span> <span class="fu">bquote</span>(R<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="st">" = "</span> <span class="sc">*</span> .(<span class="fu">round</span>(<span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared,<span class="dv">3</span>))), <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb135-2113"><a href="#cb135-2113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2114"><a href="#cb135-2114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-2115"><a href="#cb135-2115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2116"><a href="#cb135-2116" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Manual</span></span>
<span id="cb135-2117"><a href="#cb135-2117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2120"><a href="#cb135-2120" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-2121"><a href="#cb135-2121" aria-hidden="true" tabindex="-1"></a><span class="co"># get anova table for model</span></span>
<span id="cb135-2122"><a href="#cb135-2122" aria-hidden="true" tabindex="-1"></a>at <span class="ot">&lt;-</span> <span class="fu">anova</span>(mod)</span>
<span id="cb135-2123"><a href="#cb135-2123" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(at)</span>
<span id="cb135-2124"><a href="#cb135-2124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2125"><a href="#cb135-2125" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate R^2 from sums of squares from anova table</span></span>
<span id="cb135-2126"><a href="#cb135-2126" aria-hidden="true" tabindex="-1"></a><span class="co"># R^2 = SSR / SSTO = SSR / (SSR + SSE) = 1 - SSE / SSTO</span></span>
<span id="cb135-2127"><a href="#cb135-2127" aria-hidden="true" tabindex="-1"></a>ssr <span class="ot">&lt;-</span> at[<span class="st">"x"</span>, <span class="st">"Sum Sq"</span>]</span>
<span id="cb135-2128"><a href="#cb135-2128" aria-hidden="true" tabindex="-1"></a>sse <span class="ot">&lt;-</span> at[<span class="st">"Residuals"</span>, <span class="st">"Sum Sq"</span>]</span>
<span id="cb135-2129"><a href="#cb135-2129" aria-hidden="true" tabindex="-1"></a>r_squared <span class="ot">&lt;-</span> ssr <span class="sc">/</span> (ssr <span class="sc">+</span> sse)</span>
<span id="cb135-2130"><a href="#cb135-2130" aria-hidden="true" tabindex="-1"></a>r_squared <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> sse <span class="sc">/</span> (ssr <span class="sc">+</span> sse)</span>
<span id="cb135-2131"><a href="#cb135-2131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2132"><a href="#cb135-2132" aria-hidden="true" tabindex="-1"></a><span class="co"># compare results from summary(lm())</span></span>
<span id="cb135-2133"><a href="#cb135-2133" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared, r_squared)</span>
<span id="cb135-2134"><a href="#cb135-2134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2135"><a href="#cb135-2135" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-2136"><a href="#cb135-2136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2137"><a href="#cb135-2137" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Properties</span></span>
<span id="cb135-2138"><a href="#cb135-2138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2141"><a href="#cb135-2141" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-2142"><a href="#cb135-2142" aria-hidden="true" tabindex="-1"></a><span class="co"># demo to show how more spacing of X levels increases R^2 value</span></span>
<span id="cb135-2143"><a href="#cb135-2143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2144"><a href="#cb135-2144" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize items</span></span>
<span id="cb135-2145"><a href="#cb135-2145" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; sample size, population parameters and error variance</span></span>
<span id="cb135-2146"><a href="#cb135-2146" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>; beta_0 <span class="ot">&lt;-</span> <span class="dv">2</span>; beta_1 <span class="ot">&lt;-</span> <span class="dv">3</span>; sigma <span class="ot">&lt;-</span> <span class="dv">5</span> </span>
<span id="cb135-2147"><a href="#cb135-2147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2148"><a href="#cb135-2148" aria-hidden="true" tabindex="-1"></a><span class="co"># generate two datasets</span></span>
<span id="cb135-2149"><a href="#cb135-2149" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; generate common error terms, so the only difference is the spacing of the X levels</span></span>
<span id="cb135-2150"><a href="#cb135-2150" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; generate two X vectors, one with larger spread of X values</span></span>
<span id="cb135-2151"><a href="#cb135-2151" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; calculate Y</span></span>
<span id="cb135-2152"><a href="#cb135-2152" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; add indicator for spread and then combine into one dataframe</span></span>
<span id="cb135-2153"><a href="#cb135-2153" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb135-2154"><a href="#cb135-2154" aria-hidden="true" tabindex="-1"></a>data_samples <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">8</span>, <span class="at">max =</span> <span class="dv">12</span>),</span>
<span id="cb135-2155"><a href="#cb135-2155" aria-hidden="true" tabindex="-1"></a>                     <span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> <span class="dv">2</span>, <span class="at">max =</span> <span class="dv">16</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2156"><a href="#cb135-2156" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(\(x) <span class="fu">data.frame</span>(<span class="at">x =</span> x,</span>
<span id="cb135-2157"><a href="#cb135-2157" aria-hidden="true" tabindex="-1"></a>                      <span class="at">y =</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x <span class="sc">+</span> epsilon)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2158"><a href="#cb135-2158" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map2</span>(<span class="fu">c</span>(<span class="st">"smaller"</span>, <span class="st">"larger"</span>), \(df, spread) <span class="fu">mutate</span>(df, <span class="at">spread =</span> spread)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2159"><a href="#cb135-2159" aria-hidden="true" tabindex="-1"></a>  bind_rows</span>
<span id="cb135-2160"><a href="#cb135-2160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2161"><a href="#cb135-2161" aria-hidden="true" tabindex="-1"></a><span class="co"># confirm same error terms</span></span>
<span id="cb135-2162"><a href="#cb135-2162" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; calculate epsilon as Y - E(Y) and then add observation number column to sort by</span></span>
<span id="cb135-2163"><a href="#cb135-2163" aria-hidden="true" tabindex="-1"></a>data_samples <span class="sc">%&gt;%</span> </span>
<span id="cb135-2164"><a href="#cb135-2164" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">epsilon =</span> y <span class="sc">-</span> (beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2165"><a href="#cb135-2165" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">observation =</span> <span class="dv">1</span><span class="sc">:</span>n, <span class="at">.by =</span> spread) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2166"><a href="#cb135-2166" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(observation) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2167"><a href="#cb135-2167" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="at">n =</span> <span class="dv">6</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2168"><a href="#cb135-2168" aria-hidden="true" tabindex="-1"></a>  display_nice</span>
<span id="cb135-2169"><a href="#cb135-2169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2170"><a href="#cb135-2170" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate R^2 for each spread dataset</span></span>
<span id="cb135-2171"><a href="#cb135-2171" aria-hidden="true" tabindex="-1"></a>data_samples <span class="sc">%&gt;%</span> </span>
<span id="cb135-2172"><a href="#cb135-2172" aria-hidden="true" tabindex="-1"></a>  <span class="fu">split</span>(.<span class="sc">$</span>spread) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2173"><a href="#cb135-2173" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map_dbl</span>(\(df) <span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> df))<span class="sc">$</span>r.squared) <span class="sc">%&gt;%</span> </span>
<span id="cb135-2174"><a href="#cb135-2174" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(<span class="dv">3</span>)</span>
<span id="cb135-2175"><a href="#cb135-2175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2176"><a href="#cb135-2176" aria-hidden="true" tabindex="-1"></a><span class="co"># create plot of both sets of points and regression line</span></span>
<span id="cb135-2177"><a href="#cb135-2177" aria-hidden="true" tabindex="-1"></a><span class="co"># -&gt; add reference line for Y-bar for each dataset (to show how SSTO is calculated)</span></span>
<span id="cb135-2178"><a href="#cb135-2178" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x,</span>
<span id="cb135-2179"><a href="#cb135-2179" aria-hidden="true" tabindex="-1"></a>           <span class="at">y =</span> y,</span>
<span id="cb135-2180"><a href="#cb135-2180" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> spread),</span>
<span id="cb135-2181"><a href="#cb135-2181" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> data_samples) <span class="sc">+</span> </span>
<span id="cb135-2182"><a href="#cb135-2182" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb135-2183"><a href="#cb135-2183" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb135-2184"><a href="#cb135-2184" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> x,</span>
<span id="cb135-2185"><a href="#cb135-2185" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">FALSE</span>,</span>
<span id="cb135-2186"><a href="#cb135-2186" aria-hidden="true" tabindex="-1"></a>              <span class="at">fullrange =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> </span>
<span id="cb135-2187"><a href="#cb135-2187" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept =</span> y_bar,</span>
<span id="cb135-2188"><a href="#cb135-2188" aria-hidden="true" tabindex="-1"></a>                 <span class="at">color =</span> spread),</span>
<span id="cb135-2189"><a href="#cb135-2189" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> <span class="fu">summarize</span>(data_samples, <span class="at">y_bar =</span> <span class="fu">mean</span>(y), <span class="at">.by =</span> spread),</span>
<span id="cb135-2190"><a href="#cb135-2190" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>)</span>
<span id="cb135-2191"><a href="#cb135-2191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2192"><a href="#cb135-2192" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-2193"><a href="#cb135-2193" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb135-2194"><a href="#cb135-2194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2195"><a href="#cb135-2195" aria-hidden="true" tabindex="-1"></a><span class="fu">### Coefficient of correlation</span></span>
<span id="cb135-2196"><a href="#cb135-2196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2197"><a href="#cb135-2197" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A measure of linear association between $Y$ and $X$ when both $Y$ and $X$ are *random* is the coefficient of correlation. This is the signed square root of $R^2$:</span>
<span id="cb135-2198"><a href="#cb135-2198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2199"><a href="#cb135-2199" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-2200"><a href="#cb135-2200" aria-hidden="true" tabindex="-1"></a>r = \pm \sqrt{R^2}</span>
<span id="cb135-2201"><a href="#cb135-2201" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb135-2202"><a href="#cb135-2202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2203"><a href="#cb135-2203" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A plus or minus sign is attached to this measure according to whether the slope of the fitted regression line is positive or negative. Thus, $-1 \le r \le 1$.</span>
<span id="cb135-2204"><a href="#cb135-2204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2205"><a href="#cb135-2205" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>ONLY in SLR can the coefficient of determination $R^2$ be computed as the square of the correlation coefficient $r^2$.</span>
<span id="cb135-2206"><a href="#cb135-2206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2209"><a href="#cb135-2209" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb135-2210"><a href="#cb135-2210" aria-hidden="true" tabindex="-1"></a><span class="co"># continuing previous example</span></span>
<span id="cb135-2211"><a href="#cb135-2211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2212"><a href="#cb135-2212" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate correlation</span></span>
<span id="cb135-2213"><a href="#cb135-2213" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">cor</span>(x, y)</span>
<span id="cb135-2214"><a href="#cb135-2214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2215"><a href="#cb135-2215" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to squared-correlation to R^2</span></span>
<span id="cb135-2216"><a href="#cb135-2216" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(<span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared, r<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb135-2217"><a href="#cb135-2217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2218"><a href="#cb135-2218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb135-2219"><a href="#cb135-2219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2220"><a href="#cb135-2220" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note → Regression models do not contain a parameter to be estimated by $R^2$ or $r$. These are simply *descriptive measures* of the *degree of linear association* between $Y$ and $X$ in the sample observations that *may, or may not, be useful* in any instance.</span>
<span id="cb135-2221"><a href="#cb135-2221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2222"><a href="#cb135-2222" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- come back and add math 321 stuff about correlation? like the formula?? --&gt;</span></span>
<span id="cb135-2223"><a href="#cb135-2223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2224"><a href="#cb135-2224" aria-hidden="true" tabindex="-1"></a><span class="fu">## Considerations in applying regression analysis</span></span>
<span id="cb135-2225"><a href="#cb135-2225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2226"><a href="#cb135-2226" aria-hidden="true" tabindex="-1"></a>Reminders when implementing regression models</span>
<span id="cb135-2227"><a href="#cb135-2227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2228"><a href="#cb135-2228" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Frequently, regression analysis is used to make inferences for the future (e.g. a school board wants to predict future enrollments by using a regression model containing several demographic variables as predictor variables). In these situations, the validity of the regression application depends on whether basic conditions in the future will be similar to those at the time the regression analysis is based on.</span>
<span id="cb135-2229"><a href="#cb135-2229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2230"><a href="#cb135-2230" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>In predicting new observations on $Y$, the predictor variable $X$ itself often has to be predicted. Therefore, predictions are dependent upon the correctness of the population projection (i.e. they are conditional predictions).</span>
<span id="cb135-2231"><a href="#cb135-2231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2232"><a href="#cb135-2232" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Be careful of extrapolation. We cannot be sure that the regression function that fits the past data is appropriate over a wider range of the predictor variable.</span>
<span id="cb135-2233"><a href="#cb135-2233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2234"><a href="#cb135-2234" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>A statistical test that concludes $\beta_1 \ne 0$ does not establish a cause-and-effect relation between the predictor and response variables. With nonexperimental data, both the $X$ and $Y$ variables may be simultaneously influenced by other variables not in the regression model. On the other hand, the existence of a regression relation in controlled experiments is often good evidence of a cause-and-effect relation.</span>
<span id="cb135-2235"><a href="#cb135-2235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2236"><a href="#cb135-2236" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>We frequently wish to estimate several mean responses or predict several new observations for different levels of the predictor variable; this causes some special problems to arise. The confidence coefficients for the limits for estimating a mean response and for the prediction limits for a new observation only for a *single level* of $X$ for a given sample.</span>
<span id="cb135-2237"><a href="#cb135-2237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2238"><a href="#cb135-2238" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>When observations on the predictor variable $X$ are subject to measurement errors, the resulting parameter estimates are generally no longer unbiased.</span>
<span id="cb135-2239"><a href="#cb135-2239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-2240"><a href="#cb135-2240" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- skipping 2.1 normal correlation models, definitely want to come back to this --&gt;</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>